{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zaenal-abidin-syah/machine-translation-transformer/blob/main/MT_id_to_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "321fd634-3a3b-4c8a-a90b-25e57c17eba7",
      "metadata": {
        "id": "321fd634-3a3b-4c8a-a90b-25e57c17eba7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OovmRSBuAUz",
        "outputId": "5be22b8a-a364-48d1-a285-56ae0d27fa07"
      },
      "id": "3OovmRSBuAUz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a96133-9965-4f34-bcec-86c88c436e17",
      "metadata": {
        "id": "95a96133-9965-4f34-bcec-86c88c436e17"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b142b0-c40b-4918-bec3-2493b9be47b7",
      "metadata": {
        "id": "63b142b0-c40b-4918-bec3-2493b9be47b7"
      },
      "outputs": [],
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "  def __init__(self, d_model : int, vocab_size):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
        "  def forward(self, x):\n",
        "    return self.embedding(x) * math.sqrt(self.d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fee0738b-9255-42ef-bf96-1364cff5ddc8",
      "metadata": {
        "id": "fee0738b-9255-42ef-bf96-1364cff5ddc8"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbeddings(nn.Module):\n",
        "  def __init__(self, d_model: int, seq_len: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.seq_len = seq_len\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # create matrixof shape (seq_len, d_model)\n",
        "    pe = torch.zeros(self.seq_len, self.d_model)\n",
        "    # create matrixof shape (seq_len, 1)\n",
        "    position = torch.arange(0, self.seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0)/ d_model))\n",
        "\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
        "    self.register_buffer('pe', pe)\n",
        "  def forward(self, x):\n",
        "    x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
        "    return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c5d9bd4-213e-4e94-83d1-4d640ba57763",
      "metadata": {
        "id": "0c5d9bd4-213e-4e94-83d1-4d640ba57763"
      },
      "outputs": [],
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "  def __init__(self, eps: float = 10 ** -6):\n",
        "    super().__init__()\n",
        "    self.eps = eps\n",
        "    self.alpha = nn.Parameter(torch.ones(1)) # Multiplied\n",
        "    self.bias = nn.Parameter(torch.zeros(1)) # added\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    std = x.std(dim=-1, keepdim=True)\n",
        "    return self.alpha * (x - mean) / (std + self.eps) + self.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4e06e9f-2789-42b8-9e55-8a6db08ee5fb",
      "metadata": {
        "id": "c4e06e9f-2789-42b8-9e55-8a6db08ee5fb"
      },
      "outputs": [],
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "  def __init__(self, d_model: int, d_ff: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.linear_1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = self.linear_2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9edec950-ea3c-400f-a2e6-2e71a7ec555a",
      "metadata": {
        "id": "9edec950-ea3c-400f-a2e6-2e71a7ec555a"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "  def __init__(self, d_model: int, h: int, dropout: float):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.h = h\n",
        "    assert self.d_model % h == 0, \"d_model is not divisible by h\"\n",
        "\n",
        "    self.d_k = self.d_model // self.h\n",
        "    self.w_q = nn.Linear(self.d_model, self.d_model)\n",
        "    self.w_k = nn.Linear(self.d_model, self.d_model)\n",
        "    self.w_v = nn.Linear(self.d_model, self.d_model)\n",
        "\n",
        "    self.w_o = nn.Linear(self.d_model, self.d_model)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  @staticmethod\n",
        "  def attention(query, key, value, mask, dropout: nn.Dropout):\n",
        "    d_k = query.shape[-1]\n",
        "\n",
        "    # (batch, h, seq_len, d_k)\n",
        "    attention_score = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "      attention_score.masked_fill_(mask==0, -1e9)\n",
        "    attention_score = attention_score.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "      attention_score = dropout(attention_score)\n",
        "    return (attention_score @ value), attention_score\n",
        "  def forward(self, q, k, v, mask):\n",
        "    query = self.w_q(q)\n",
        "    key = self.w_k(k)\n",
        "    value = self.w_v(v)\n",
        "\n",
        "    query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1,2)\n",
        "    key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1,2)\n",
        "    value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1,2)\n",
        "\n",
        "    x, self.attention_score = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "    x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "    return self.w_o(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce51ce7-8f16-4e0e-81f5-9f4c261c28c4",
      "metadata": {
        "id": "bce51ce7-8f16-4e0e-81f5-9f4c261c28c4"
      },
      "outputs": [],
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self, dropout: float):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.norm = LayerNormalization()\n",
        "  def forward(self, x, sublayer):\n",
        "    return x + self.dropout(sublayer(self.norm(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e908619-f907-4907-b173-5ffc606f7741",
      "metadata": {
        "id": "2e908619-f907-4907-b173-5ffc606f7741"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, self_attention_block: MultiHeadAttentionBlock, feedforward_block: FeedForwardBlock, dropout: float):\n",
        "    super().__init__()\n",
        "    self.self_attention_block = self_attention_block\n",
        "    self.feedforward_block = feedforward_block\n",
        "    self.residual_connection = nn.ModuleList([ResidualConnection(dropout) for _ in range(2)])\n",
        "  def forward(self, x, src_mask):\n",
        "    x = self.residual_connection[0](x, lambda x : self.self_attention_block(x,x,x, src_mask))\n",
        "    x = self.residual_connection[1](x, self.feedforward_block)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89948ec-5652-4f9e-8dfb-ea0b65b7d4ad",
      "metadata": {
        "id": "e89948ec-5652-4f9e-8dfb-ea0b65b7d4ad"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, layers: nn.ModuleList):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNormalization()\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2614a566-df69-4e9c-883f-8ee2a3f160a0",
      "metadata": {
        "id": "2614a566-df69-4e9c-883f-8ee2a3f160a0"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, feedforward_block: FeedForwardBlock, dropout: float):\n",
        "    super().__init__()\n",
        "    self.self_attention_block = self_attention_block\n",
        "    self.cross_attention_block = cross_attention_block\n",
        "    self.feedforward_block = feedforward_block\n",
        "    self.residual_connection = nn.ModuleList([ResidualConnection(dropout) for _ in range(3)])\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    x = self.residual_connection[0](x, lambda x : self.self_attention_block(x, x, x, tgt_mask))\n",
        "    x = self.residual_connection[1](x, lambda x : self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "    x = self.residual_connection[2](x, self.feedforward_block)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138a64e6-e5bb-4629-a071-59fac1f4da87",
      "metadata": {
        "id": "138a64e6-e5bb-4629-a071-59fac1f4da87"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, layers: nn.ModuleList):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNormalization()\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8c2f210-dc16-4b05-a39f-d281f3499b15",
      "metadata": {
        "id": "b8c2f210-dc16-4b05-a39f-d281f3499b15"
      },
      "outputs": [],
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "  def __init__(self, d_model: int, vocab_size: int):\n",
        "    super().__init__()\n",
        "    self.projection = nn.Linear(d_model, vocab_size)\n",
        "  def forward(self, x):\n",
        "    return torch.log_softmax(self.projection(x), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb8174f-0dce-481f-87db-37f64d4cba00",
      "metadata": {
        "id": "8eb8174f-0dce-481f-87db-37f64d4cba00"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "  def __init__(self,\n",
        "    encoder: Encoder,\n",
        "    decoder: Decoder,\n",
        "    src_embedding: InputEmbeddings,\n",
        "    tgt_embedding: InputEmbeddings,\n",
        "    src_position: PositionalEmbeddings,\n",
        "    tgt_position: PositionalEmbeddings,\n",
        "    projection_layer: ProjectionLayer):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embedding = src_embedding\n",
        "    self.tgt_embedding = tgt_embedding\n",
        "    self.src_position = src_position\n",
        "    self.tgt_position = tgt_position\n",
        "    self.projection_layer = projection_layer\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    src = self.src_embedding(src)\n",
        "    src = self.src_position(src)\n",
        "    return self.encoder(src, src_mask)\n",
        "\n",
        "  def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "    tgt = self.tgt_embedding(tgt)\n",
        "    tgt = self.tgt_position(tgt)\n",
        "    return self.decoder(tgt, encoder_output, src_mask, tgt_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e20010a-019d-45f7-93a1-d374b7cb703c",
      "metadata": {
        "id": "1e20010a-019d-45f7-93a1-d374b7cb703c"
      },
      "outputs": [],
      "source": [
        "def build_transformer(\n",
        "  src_vocab_size: int,\n",
        "  tgt_vocab_size: int,\n",
        "  src_seq_len: int,\n",
        "  tgt_seq_len: int,\n",
        "  d_model: int = 128,\n",
        "  N: int = 2,\n",
        "  h: int=4,\n",
        "  dropout: float=0.1,\n",
        "  d_ff: int = 2048\n",
        ")-> Transformer:\n",
        "  # create embeddings layer\n",
        "  src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "  tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "\n",
        "  # create positional embedding\n",
        "  src_pos = PositionalEmbeddings(d_model, src_seq_len, dropout)\n",
        "  tgt_pos = PositionalEmbeddings(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "  # create encoder blocks\n",
        "  encoder_blocks = []\n",
        "  for _ in range(N):\n",
        "    encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "    feedforward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "    encoder_block = EncoderBlock(encoder_self_attention_block, feedforward_block, dropout)\n",
        "    encoder_blocks.append(encoder_block)\n",
        "\n",
        "  # create decoder blocks\n",
        "  decoder_blocks = []\n",
        "  for _ in range(N):\n",
        "    decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "    decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "    feedforward_block = FeedForwardBlock(d_model, d_ff, dropout)\n",
        "    decoder_block = DecoderBlock(decoder_self_attention_block, decoder_cross_attention_block, feedforward_block, dropout)\n",
        "    decoder_blocks.append(decoder_block)\n",
        "\n",
        "  # create encoder and decoder\n",
        "  encoder = Encoder(nn.ModuleList(encoder_blocks))\n",
        "  decoder = Decoder(nn.ModuleList(decoder_blocks))\n",
        "\n",
        "  # projection\n",
        "  projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "  # create transformer\n",
        "  transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "  for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "  return transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ec6b56",
      "metadata": {
        "id": "55ec6b56"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7d0d82",
      "metadata": {
        "id": "1f7d0d82"
      },
      "outputs": [],
      "source": [
        "def get_config(model_name, preload=None, folder='.', epoch=10):\n",
        "  return {\n",
        "    \"model_name\": model_name,\n",
        "    \"batch_size\": 32,\n",
        "    \"num_epochs\": epoch,\n",
        "    \"lr\": 10**-4,\n",
        "    \"seq_len\": 80,\n",
        "    \"d_model\": 64,\n",
        "    \"lang_src\": \"indonesian\",\n",
        "    \"lang_tgt\": \"english\",\n",
        "    \"model_folder\": f\"{folder}/weights_{model_name}\",\n",
        "    \"model_basename\": \"tmodel_\",\n",
        "    \"preload\": preload,\n",
        "    \"tokenizer_file\": folder + \"/tokenizer_{0}.json\",\n",
        "    \"experiment_name\": f\"{folder}/runs_{model_name}/tmodel\"\n",
        "  }\n",
        "\n",
        "def get_weights_file_path(config, epoch: str):\n",
        "  model_folder = config[\"model_folder\"]\n",
        "  model_basename = config[\"model_basename\"]\n",
        "  model_filename = f\"{model_basename}{epoch}.pt\"\n",
        "  return str(Path(\".\") / model_folder / model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER_PATH = '/content/drive/MyDrive/Machine_translation'"
      ],
      "metadata": {
        "id": "ojf6Oq0gu9G-"
      },
      "id": "ojf6Oq0gu9G-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d74d32a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d74d32a",
        "outputId": "47c9f872-cc06-4e0c-da65-2fc4399275ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'model_name': 'model_1',\n",
              "  'batch_size': 32,\n",
              "  'num_epochs': 10,\n",
              "  'lr': 0.0001,\n",
              "  'seq_len': 80,\n",
              "  'd_model': 64,\n",
              "  'lang_src': 'indonesian',\n",
              "  'lang_tgt': 'english',\n",
              "  'model_folder': '/content/drive/MyDrive/Machine_translation/weights_model_1',\n",
              "  'model_basename': 'tmodel_',\n",
              "  'preload': None,\n",
              "  'tokenizer_file': '/content/drive/MyDrive/Machine_translation/tokenizer_{0}.json',\n",
              "  'experiment_name': '/content/drive/MyDrive/Machine_translation/runs_model_1/tmodel'},\n",
              " {'model_name': 'model_2',\n",
              "  'batch_size': 32,\n",
              "  'num_epochs': 10,\n",
              "  'lr': 0.0001,\n",
              "  'seq_len': 80,\n",
              "  'd_model': 64,\n",
              "  'lang_src': 'indonesian',\n",
              "  'lang_tgt': 'english',\n",
              "  'model_folder': '/content/drive/MyDrive/Machine_translation/weights_model_2',\n",
              "  'model_basename': 'tmodel_',\n",
              "  'preload': None,\n",
              "  'tokenizer_file': '/content/drive/MyDrive/Machine_translation/tokenizer_{0}.json',\n",
              "  'experiment_name': '/content/drive/MyDrive/Machine_translation/runs_model_2/tmodel'},\n",
              " {'model_name': 'model_3',\n",
              "  'batch_size': 32,\n",
              "  'num_epochs': 10,\n",
              "  'lr': 0.0001,\n",
              "  'seq_len': 80,\n",
              "  'd_model': 64,\n",
              "  'lang_src': 'indonesian',\n",
              "  'lang_tgt': 'english',\n",
              "  'model_folder': '/content/drive/MyDrive/Machine_translation/weights_model_3',\n",
              "  'model_basename': 'tmodel_',\n",
              "  'preload': None,\n",
              "  'tokenizer_file': '/content/drive/MyDrive/Machine_translation/tokenizer_{0}.json',\n",
              "  'experiment_name': '/content/drive/MyDrive/Machine_translation/runs_model_3/tmodel'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "preload = [None, None, None]\n",
        "configs =[ get_config(f\"model_{i}\", folder=FOLDER_PATH, preload=preload[i-1]) for i in range(1, 4)]\n",
        "configs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee588f80",
      "metadata": {
        "id": "ee588f80"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masking"
      ],
      "metadata": {
        "id": "QXYMdwFZKktt"
      },
      "id": "QXYMdwFZKktt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74dd05ad",
      "metadata": {
        "id": "74dd05ad"
      },
      "outputs": [],
      "source": [
        "def causal_mask(size):\n",
        "  mask = torch.triu(torch.ones(1, size, size), diagonal=1).type(torch.int)\n",
        "  return mask == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Dataset"
      ],
      "metadata": {
        "id": "pQrUoBpvKnaJ"
      },
      "id": "pQrUoBpvKnaJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4545a33",
      "metadata": {
        "id": "b4545a33"
      },
      "outputs": [],
      "source": [
        "class BilingualDataset(Dataset):\n",
        "  def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
        "    self.ds = ds\n",
        "    self.tokenizer_src = tokenizer_src\n",
        "    self.tokenizer_tgt = tokenizer_tgt\n",
        "    self.src_lang = src_lang\n",
        "    self.tgt_lang = tgt_lang\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "    # print(\"tokenizer type:\", type(tokenizer_src))\n",
        "    # for t in [\"[SOS]\",\"[EOS]\",\"[PAD]\",\"[UNK]\"]:\n",
        "    #   val = tokenizer_src.token_to_id(t)\n",
        "    #   print(f\"{t!r} ->\", val, \" type:\", type(val))\n",
        "    # # kalau ada method get_vocab:\n",
        "    # if hasattr(tokenizer_src, \"get_vocab\"):\n",
        "    #   print(\"vocab sample:\", list(list(tokenizer_src.get_vocab().items())[:20]))\n",
        "    # elif hasattr(tokenizer_src, \"get_vocab_size\"):\n",
        "    #   print(\"vocab size:\", tokenizer_src.get_vocab_size())\n",
        "    # else:\n",
        "    #   print(\"No get_vocab method available on tokenizer object.\")\n",
        "\n",
        "    # self.sos_token = torch.Tensor([tokenizer_src.token_to_id([\"[SOS]\"])], dtype=torch.int64)\n",
        "    # self.eos_token = torch.Tensor([tokenizer_src.token_to_id([\"[EOS]\"])], dtype=torch.int64)\n",
        "    # self.pad_token = torch.Tensor([tokenizer_src.token_to_id([\"[PAD]\"])], dtype=torch.int64)\n",
        "\n",
        "    self.sos_token = torch.tensor([tokenizer_src.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "    self.eos_token = torch.tensor([tokenizer_src.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "    self.pad_token = torch.tensor([tokenizer_src.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    print(\"apakah ada masalah di sos eos dan pad token?\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.ds)\n",
        "  def __getitem__(self, index):\n",
        "    src_target_pair = self.ds[index]\n",
        "    src_text = src_target_pair[self.src_lang]\n",
        "    tgt_text = src_target_pair[self.tgt_lang]\n",
        "\n",
        "    enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
        "    dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "    enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2\n",
        "    dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1\n",
        "\n",
        "    if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "      raise ValueError(\"Sentence is to long\")\n",
        "\n",
        "    # Add sos and eos to source text\n",
        "    encoder_input = torch.cat(\n",
        "      [\n",
        "        self.sos_token,\n",
        "        torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
        "        self.eos_token,\n",
        "        torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64)\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    # add sos to decoder input\n",
        "    decoder_input = torch.cat(\n",
        "      [\n",
        "        self.sos_token,\n",
        "        torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "        torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    # add eos  to the label (what we expect as output from decoder)\n",
        "    label = torch.cat(\n",
        "      [\n",
        "        torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "        self.eos_token,\n",
        "        torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64)\n",
        "      ]\n",
        "    )\n",
        "\n",
        "    assert encoder_input.size(0) == self.seq_len\n",
        "    assert decoder_input.size(0) == self.seq_len\n",
        "    assert label.size(0) == self.seq_len\n",
        "    return {\n",
        "      \"encoder_input\": encoder_input,\n",
        "      \"decoder_input\": decoder_input,\n",
        "      \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(),\n",
        "      \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)),\n",
        "      \"label\": label,\n",
        "      \"src_text\": src_text,\n",
        "      \"tgt_text\": tgt_text\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c16c51f4-f00f-4bbe-9744-161064b8bd9f",
      "metadata": {
        "id": "c16c51f4-f00f-4bbe-9744-161064b8bd9f"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606493b9-1d5e-417d-8614-b5678dbc05b2",
      "metadata": {
        "id": "606493b9-1d5e-417d-8614-b5678dbc05b2"
      },
      "outputs": [],
      "source": [
        "# !pip install datasets tokenizers\n",
        "# !pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75fb0c00-1790-4c5b-98b1-dd9cafac924e",
      "metadata": {
        "id": "75fb0c00-1790-4c5b-98b1-dd9cafac924e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# from config import get_config, get_weights_file_path\n",
        "# from dataset import BilingualDataset, causal_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Greedy decode"
      ],
      "metadata": {
        "id": "z46cmi92LKs_"
      },
      "id": "z46cmi92LKs_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EIPnnXDMztWu",
      "metadata": {
        "id": "EIPnnXDMztWu"
      },
      "outputs": [],
      "source": [
        "# def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "#   sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
        "#   eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
        "\n",
        "#   encoder_output = model.encode(source, source_mask)\n",
        "\n",
        "#   decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "#   while True:\n",
        "#     if decoder_input.size(1) == max_len:\n",
        "#       break\n",
        "#     decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "\n",
        "#     out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "#     prob = model.projection_layer(out[:, -1])\n",
        "\n",
        "#     _, next_word = torch.max(prob, dim = 1)\n",
        "#     decoder_input = torch.cat([decoder_input, torch.empty(1,1).type_as(source).fill_(next_word.item()).to(device)], dim=1)\n",
        "#     if next_word == eos_idx:\n",
        "#       break\n",
        "#   return decoder_input.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def greedy_decode_batch(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
        "    eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
        "\n",
        "    batch_size = source.size(0)\n",
        "    encoder_output = model.encode(source, source_mask)\n",
        "\n",
        "    # start token untuk seluruh batch\n",
        "    decoder_input = torch.full((batch_size, 1), sos_idx, dtype=source.dtype, device=device)\n",
        "\n",
        "    # track which sequences sudah selesai (muncul EOS)\n",
        "    finished = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
        "\n",
        "    for _step in range(max_len - 1):  # already punya SOS, jadi max_len-1 langkah tambah\n",
        "        tgt_len = decoder_input.size(1)\n",
        "        decoder_mask = causal_mask(tgt_len).type_as(source_mask).to(device)\n",
        "\n",
        "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "        # out shape asumsi: (batch_size, tgt_len, hidden)\n",
        "        logits = model.projection_layer(out[:, -1, :])  # ambil logits token terakhir -> (batch_size, vocab_size)\n",
        "\n",
        "        # pilih token dengan probabilitas tertinggi per batch item (greedy)\n",
        "        next_word = torch.argmax(logits, dim=-1)  # (batch_size,)\n",
        "\n",
        "        # jika sudah finished sebelumnya, tetap isi dengan EOS supaya tidak berubah\n",
        "        next_word = torch.where(finished, torch.full_like(next_word, eos_idx), next_word)\n",
        "\n",
        "        # append ke decoder_input\n",
        "        decoder_input = torch.cat([decoder_input, next_word.unsqueeze(1)], dim=1)  # (batch_size, tgt_len+1)\n",
        "\n",
        "        # update finished flags\n",
        "        finished = finished | (next_word == eos_idx)\n",
        "\n",
        "        # kalau semua selesai, stop lebih awal\n",
        "        if finished.all():\n",
        "            break\n",
        "\n",
        "    return decoder_input  # (batch_size, decoded_len)"
      ],
      "metadata": {
        "id": "bQIeEA-lqJPg"
      },
      "id": "bQIeEA-lqJPg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zvqf-vAmqJAn"
      },
      "id": "zvqf-vAmqJAn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## validation"
      ],
      "metadata": {
        "id": "NPQsMw-LLNzF"
      },
      "id": "NPQsMw-LLNzF"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvKqgE36mhsw",
        "outputId": "6db7b5f8-a246-4fd5-cdd5-a914edd1c9a7"
      },
      "id": "rvKqgE36mhsw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/345.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/114.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47Gj1OVWzuYl",
      "metadata": {
        "id": "47Gj1OVWzuYl"
      },
      "outputs": [],
      "source": [
        "# def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples=5):\n",
        "#   model.eval()\n",
        "#   count = 0\n",
        "\n",
        "#   preds = []\n",
        "#   refs = []\n",
        "#   # expected = []\n",
        "#   # predicted = []\n",
        "\n",
        "#   console_width = 80\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     for batch in validation_ds:\n",
        "#       count += 1\n",
        "#       encoder_input = batch[\"encoder_input\"].to(device)\n",
        "#       encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "#       assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "\n",
        "#       model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "#       source_text = batch[\"src_text\"][0]\n",
        "#       target_text = batch[\"tgt_text\"][0]\n",
        "#       model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "#       # source_texts.append(source_text)\n",
        "#       # expected.append(target_text)\n",
        "#       # predicted.append(model_out_text)\n",
        "#       preds.append(model_out_text)\n",
        "#       refs.append(target_text)\n",
        "\n",
        "#       print_msg(\"-\" * console_width)\n",
        "#       print_msg(f\"Source: {source_text}\")\n",
        "#       print_msg(f\"Target: {target_text}\")\n",
        "#       print_msg(f\"Predicted: {model_out_text}\")\n",
        "#       if count == num_examples:\n",
        "#         break\n",
        "\n",
        "#   print(\"hitung blue\")\n",
        "#   if writer:\n",
        "#     bleu_metric = load(\"bleu\")\n",
        "#     result = bleu_metric.compute(predictions=preds, references=refs)\n",
        "#     print(result)\n",
        "#   #   # torchmetrics CharErrorRate, BLUE, WordErrorRate, etc can be used here\n",
        "#   #   pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from evaluate import load  # make sure `evaluate` package tersedia\n",
        "\n",
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_state, writer, num_examples=5):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    refs = []\n",
        "\n",
        "    console_width = 80\n",
        "\n",
        "    sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
        "    eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "\n",
        "            # decode batch-wise (mengembalikan tensor (batch_size, decoded_len))\n",
        "            model_out = greedy_decode_batch(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "            # model_out: torch.LongTensor, shape (batch_size, seq_len)\n",
        "\n",
        "            # convert to python lists of token ids and trim SOS/EOS\n",
        "            seqs = model_out.detach().cpu().numpy().tolist()\n",
        "            cleaned = []\n",
        "            for seq in seqs:\n",
        "                # drop leading SOS if present\n",
        "                if len(seq) > 0 and seq[0] == sos_idx:\n",
        "                    seq = seq[1:]\n",
        "                # cut at EOS (exclude EOS from decoded ids)\n",
        "                if eos_idx in seq:\n",
        "                    seq = seq[:seq.index(eos_idx)]\n",
        "                cleaned.append(seq)\n",
        "\n",
        "            # decode to text: prefer batch_decode if available\n",
        "            if hasattr(tokenizer_tgt, \"batch_decode\"):\n",
        "                # some tokenizers expect list[int] per example\n",
        "                model_out_texts = tokenizer_tgt.batch_decode(cleaned, skip_special_tokens=True)\n",
        "            else:\n",
        "                model_out_texts = [tokenizer_tgt.decode(ids, skip_special_tokens=True) for ids in cleaned]\n",
        "\n",
        "            batch_size = encoder_input.size(0)\n",
        "            for i in range(batch_size):\n",
        "                src_text = batch[\"src_text\"][i]\n",
        "                tgt_text = batch[\"tgt_text\"][i]\n",
        "                pred_text = model_out_texts[i]\n",
        "\n",
        "                preds.append(pred_text)\n",
        "                refs.append(tgt_text)\n",
        "\n",
        "                # only print up to num_examples total\n",
        "                if len(preds) <= num_examples:\n",
        "                    print_msg(\"-\" * console_width)\n",
        "                    print_msg(f\"Source: {src_text}\")\n",
        "                    print_msg(f\"Target: {tgt_text}\")\n",
        "                    print_msg(f\"Predicted: {pred_text}\")\n",
        "\n",
        "            if len(preds) >= num_examples:\n",
        "                break\n",
        "\n",
        "    # compute BLEU (or other metric)\n",
        "    try:\n",
        "        bleu_metric = load(\"bleu\")\n",
        "        # note: some evaluate BLEU implementations expect references as list[list[str]]\n",
        "        # if that API is required in your env, wrap refs: [[r] for r in refs]\n",
        "        result = bleu_metric.compute(predictions=preds, references=refs)\n",
        "        print(\"BLEU:\", result)\n",
        "        # if you have a writer (tensorboard) log it\n",
        "        if writer:\n",
        "            # adjust the key/name according to your writer usage\n",
        "            if isinstance(result, dict):\n",
        "                # try to log a numeric value if present\n",
        "                if \"bleu\" in result:\n",
        "                    writer.add_scalar(\"val/bleu\", result[\"bleu\"], global_state.get(\"step\", 0) if global_state else 0)\n",
        "            else:\n",
        "                # result might be a single numeric\n",
        "                writer.add_scalar(\"val/bleu\", float(result), global_state.get(\"step\", 0) if global_state else 0)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not compute BLEU metric: {e}\")\n",
        "\n",
        "    return {\"preds\": preds, \"refs\": refs}\n"
      ],
      "metadata": {
        "id": "k1evlVa0qc1j"
      },
      "id": "k1evlVa0qc1j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get dataset"
      ],
      "metadata": {
        "id": "n5ycJigtLZVQ"
      },
      "id": "n5ycJigtLZVQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d185fb9",
      "metadata": {
        "id": "3d185fb9"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset as HFDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab51204",
      "metadata": {
        "id": "1ab51204"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import html"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "qpiPIQeWLcda"
      },
      "id": "qpiPIQeWLcda"
    },
    {
      "cell_type": "code",
      "source": [
        "import contractions"
      ],
      "metadata": {
        "id": "buGkFbQ7kMm4"
      },
      "id": "buGkFbQ7kMm4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5da6bc",
      "metadata": {
        "id": "7b5da6bc"
      },
      "outputs": [],
      "source": [
        "EMOJI_PATTERN = re.compile(\n",
        "    \"[\"\n",
        "    \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    \"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "    \"\\U00002700-\\U000027BF\"\n",
        "    \"\\U000024C2-\\U0001F251\"\n",
        "    \"]+\",\n",
        "    flags=re.UNICODE\n",
        ")\n",
        "\n",
        "RE_EMAIL = re.compile(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}\\b', flags=re.UNICODE)\n",
        "RE_URL = re.compile(\n",
        "    r'((http|https):\\/\\/[^\\s]+)|(www\\.[^\\s]+)|(\\b[\\w-]+\\.(com|net|org|edu|id|gov|io|co|biz|info|me)(\\/[^\\s]*)?)',\n",
        "    flags=re.IGNORECASE\n",
        ")\n",
        "RE_HANDLE = re.compile(r'@\\w+')\n",
        "RE_HTML_TAG = re.compile(r'<[^>]+>')\n",
        "RE_HTML_ENTITY = re.compile(r'&[a-zA-Z]+;')\n",
        "RE_MUSIC_NOTES = re.compile(r'[\\u266B\\u266A\\u2669\\u266C♫♪]+')\n",
        "# RE_WORD_BRACKET = re.compile(r'[\\[\\{\\(]*[.][\\]\\}\\)]')\n",
        "RE_WORD_BRACKET = re.compile(r'[\\[\\{\\(][^\\]\\}\\)]*[\\]\\}\\)]', flags=re.UNICODE)\n",
        "\n",
        "\n",
        "def preprocess_text(\n",
        "    text,\n",
        "    lowercase=True,\n",
        "    remove_emails=True,\n",
        "    remove_urls=True,\n",
        "    remove_word_bracket=True,\n",
        "    remove_music_notes=True,\n",
        "    remove_html=True,\n",
        "    remove_handles=True,\n",
        "    contraction=False,\n",
        "    remove_emoji=True,\n",
        "    remove_ascii_punct=True\n",
        "):\n",
        "    \"\"\"\n",
        "    Bersihkan 1 string text. Semua opsional bisa dimatikan sesuai kebutuhan.\n",
        "    \"\"\"\n",
        "    if text is None:\n",
        "        return text\n",
        "    # 1) unescape HTML entities seperti &lt;i&gt; -> <i>\n",
        "    text = html.unescape(text)\n",
        "\n",
        "    # 2) lowercase\n",
        "    if lowercase:\n",
        "        text = text.lower()\n",
        "        # print(\"lowercase : \",text)\n",
        "\n",
        "    if contraction:\n",
        "      text = contractions.fix(text)\n",
        "\n",
        "    # 3) hapus tag HTML\n",
        "    if remove_html:\n",
        "        text = RE_HTML_TAG.sub(' ', text)\n",
        "        # print(\"remove html : \",text)\n",
        "\n",
        "\n",
        "    # 4) hapus email/url/handle\n",
        "    if remove_emails:\n",
        "        text = RE_EMAIL.sub(' ', text)\n",
        "        # print(\"remove email : \",text)\n",
        "    if remove_urls:\n",
        "        text = RE_URL.sub(' ', text)\n",
        "        # print(\"remove url : \",text)\n",
        "    if remove_word_bracket:\n",
        "        text = RE_WORD_BRACKET.sub(' ', text)\n",
        "        # print(\"remove word bracket : \",text)\n",
        "    if remove_handles:\n",
        "        text = RE_HANDLE.sub(' ', text)\n",
        "        # print(\"remove handle : \",text)\n",
        "\n",
        "    # 5) hapus simbol musik\n",
        "    if remove_music_notes:\n",
        "        text = RE_MUSIC_NOTES.sub(' ', text)\n",
        "        # print(\"remove music notes : \",text)\n",
        "\n",
        "    # 6) hapus emoji\n",
        "    if remove_emoji:\n",
        "        text = EMOJI_PATTERN.sub('', text)\n",
        "        # print(\"remove emoji : \",text)\n",
        "\n",
        "    # 11) hapus leftover HTML entities seperti &lt;\n",
        "    text = RE_HTML_ENTITY.sub(' ', text)\n",
        "    # print(\"remove html entity : \",text)\n",
        "    # 12) hapus punctuation ascii (jika diinginkan)\n",
        "    if remove_ascii_punct:\n",
        "        text = re.sub(r'--', '', text)\n",
        "        remove = \".,\\'\\\"-$?!\"\n",
        "        # bikin versi custom string.punctuation\n",
        "        custom_punct = string.punctuation.translate(str.maketrans('', '', remove))\n",
        "        text = text.translate(str.maketrans('', '', custom_punct))\n",
        "        # print(\"remove ascii punct : \",text)\n",
        "\n",
        "    # 13) collapse multiple spaces dan trim\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data from paralel text"
      ],
      "metadata": {
        "id": "z2F4l_IxLlrq"
      },
      "id": "z2F4l_IxLlrq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ea4b96",
      "metadata": {
        "id": "e3ea4b96"
      },
      "outputs": [],
      "source": [
        "def read_paralel_text(file_lang_src, file_lang_tgt, lang_src, lang_tgt, max_len):\n",
        "  with open(file_lang_src, \"r\", encoding=\"utf-8\") as f_src, open(file_lang_tgt, \"r\", encoding=\"utf-8\") as f_tgt:\n",
        "    data = 0\n",
        "    pairs = []\n",
        "    id = 0\n",
        "    max_len = max_len - 20\n",
        "    max_length = 0\n",
        "\n",
        "    for src_lines, tgt_lines in zip(f_src, f_tgt):\n",
        "      data += 1\n",
        "      src_lines, tgt_lines = src_lines.strip(), tgt_lines.strip()\n",
        "      # Preprocess\n",
        "      src_lines, tgt_lines = preprocess_text(src_lines), preprocess_text(tgt_lines, contraction=True)\n",
        "\n",
        "      max_length = max(max_length, len(src_lines.split()), len(tgt_lines.split()))\n",
        "      if len(src_lines.split()) > max_len or len(tgt_lines.split()) > max_len:\n",
        "        continue\n",
        "      elif len(src_lines) == 0 or len(tgt_lines) == 0:\n",
        "        continue\n",
        "      else:\n",
        "        pairs.append({\n",
        "            lang_src : src_lines,\n",
        "            lang_tgt : tgt_lines,\n",
        "            \"id\" : id\n",
        "          })\n",
        "        id += 1\n",
        "    print(\"Jumlah data : \", data)\n",
        "    print(\"max word : \", max_length)\n",
        "    print(\"Jumlah data yang dihapus : \", data - id)\n",
        "    # print(\"max word : \", max_word)\n",
        "  ds = HFDataset.from_list(pairs)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c44190",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2c44190",
        "outputId": "c61321d9-26c9-4539-f08e-f23c64dd0d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah data :  165059\n",
            "max word :  521\n",
            "Jumlah data yang dihapus :  7704\n"
          ]
        }
      ],
      "source": [
        "ID = f\"{FOLDER_PATH}/TED2020.en-id.id\"\n",
        "EN = f\"{FOLDER_PATH}/TED2020.en-id.en\"\n",
        "\n",
        "dataset = read_paralel_text(ID, EN, \"indonesian\", \"english\", 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### save and load dataset"
      ],
      "metadata": {
        "id": "FjBV9IQ1Lvqw"
      },
      "id": "FjBV9IQ1Lvqw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf49421a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "941f465fb52d4b5eb8064069d7b3f9a6",
            "c9e06bde7c79406ba24787fd5eae800b",
            "9d46513ce3f54085ae1f8ea8cf7b1778",
            "14d96473e8b044cc8f5385fd945025e1",
            "49ac0f5e57ca45478ecac8b573340fc6",
            "f38b2bd1d5f4420ebfe370a1d4e20b8d",
            "2e2a10b35e9a4bd59de5e1228ee50032",
            "d91cfabe1ac544c7ba69afddabb5e42e",
            "96c1e0aa430243a18f482abe3aefceea",
            "219b6dd80f044de9adef5babc717b837",
            "4b718acda65248e9b1e63f54c0108ea2"
          ]
        },
        "id": "bf49421a",
        "outputId": "87f91116-f895-4fbf-947e-3e529c309ed6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/157355 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "941f465fb52d4b5eb8064069d7b3f9a6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset.save_to_disk(f\"{FOLDER_PATH}/data/dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "301bd90f",
      "metadata": {
        "id": "301bd90f"
      },
      "outputs": [],
      "source": [
        "dataset = HFDataset.load_from_disk(f\"{FOLDER_PATH}/data/dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Tokenizer"
      ],
      "metadata": {
        "id": "VMUhvM2aMJXw"
      },
      "id": "VMUhvM2aMJXw"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_sentences(ds, lang):\n",
        "  for item in ds:\n",
        "    yield item[lang]\n",
        "\n",
        "def get_or_build_tokenizer(config, ds, lang):\n",
        "  tokenizer_path = Path(config[\"tokenizer_file\"].format(lang)).expanduser().resolve()\n",
        "  print(\"path tokenizer : \", tokenizer_path)\n",
        "  if not Path.exists(tokenizer_path):\n",
        "    print(\"tokenizer file tidak ada?\")\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token='[UNK]'))\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
        "    tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "    tokenizer.save(str(tokenizer_path))\n",
        "  else:\n",
        "    print(\"tokenizer file ada\")\n",
        "    tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "hQv1X4s0MRp7"
      },
      "id": "hQv1X4s0MRp7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### build or get tokenizer"
      ],
      "metadata": {
        "id": "omuPtGVIL3aj"
      },
      "id": "omuPtGVIL3aj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6305c5c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6305c5c2",
        "outputId": "4aef3eb8-6f2f-4264-c83e-80baec54d4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path tokenizer :  /content/drive/MyDrive/Machine_translation/tokenizer_indonesian.json\n",
            "tokenizer file ada\n",
            "path tokenizer :  /content/drive/MyDrive/Machine_translation/tokenizer_english.json\n",
            "tokenizer file ada\n"
          ]
        }
      ],
      "source": [
        "config = configs[0]\n",
        "tokenizer_src = get_or_build_tokenizer(config, dataset, config['lang_src'])\n",
        "tokenizer_tgt = get_or_build_tokenizer(config, dataset, config['lang_tgt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split data"
      ],
      "metadata": {
        "id": "uyxUD4-kMZE9"
      },
      "id": "uyxUD4-kMZE9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd7fc0c",
      "metadata": {
        "id": "afd7fc0c"
      },
      "outputs": [],
      "source": [
        "split_ds = dataset.train_test_split(test_size=0.2, shuffle=True)\n",
        "train_ds_raw = split_ds[\"train\"]\n",
        "val_ds_raw = split_ds[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save and load split dataset"
      ],
      "metadata": {
        "id": "6hENdX9cMcu-"
      },
      "id": "6hENdX9cMcu-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a26665f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "d6c07d5cec9244ca92a0b478e8d3871a",
            "9b3d185029b1436daf6a6e67252bd7ad",
            "6e02ee085e754a9c8e7815d398977616",
            "4505d6f989b24c02b1ea4f38b99d808b",
            "7d2a47fa3d29426396d001f7a7d57b38",
            "946e5278e0e74094b7fce3f0a6c186ab",
            "19066ef69c14429596a8c6c7ab731d93",
            "f6be4784c209428987fe9cf5c6ce3605",
            "341fbc17c2524c9f8dd9dbec0572d63d",
            "77485e6f7bea41d58837bcf78c369de9",
            "cb65d884ec5a449f8ee87c6d56faf4be",
            "2ed3fa28c8144f3fa70723b4ae80cc32",
            "2bd8bd8965eb4be1bddbd1f103830743",
            "b6e9fbe0e5fc4efbbb87bdb35a49d845",
            "7bd40ff1b3d04924ad626c7df0557b9c",
            "1f8f7d1fa0064e9f96616930b0df4850",
            "704ddb1d77024f128b16c81c54b2992e",
            "06d73ed400804ed0b34e9ccf5f48264e",
            "ea4b8239e8424c0c8f066968eca7f776",
            "17a40afbe4fc400889c83382b4247bff",
            "149eb6874c45413298ae84fe91132cef",
            "5e6dcbd0d8d34dafb7cc5fee10ab235d"
          ]
        },
        "id": "3a26665f",
        "outputId": "082bdb23-2ef5-4ad2-be9f-9671839c5eea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/125884 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6c07d5cec9244ca92a0b478e8d3871a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/31471 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ed3fa28c8144f3fa70723b4ae80cc32"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_ds_raw.save_to_disk(f\"{FOLDER_PATH}/data/train-dataset\")\n",
        "val_ds_raw.save_to_disk(f\"{FOLDER_PATH}/data/val-dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_raw = HFDataset.load_from_disk(f\"{FOLDER_PATH}/data/train-dataset\")\n",
        "val_ds_raw = HFDataset.load_from_disk(f\"{FOLDER_PATH}/data/val-dataset\")"
      ],
      "metadata": {
        "id": "qLYmtd1XzC9p"
      },
      "id": "qLYmtd1XzC9p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bagging(Bootsrap Aggregating )"
      ],
      "metadata": {
        "id": "Jc_-GqpiMjqx"
      },
      "id": "Jc_-GqpiMjqx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84286c21",
      "metadata": {
        "id": "84286c21"
      },
      "outputs": [],
      "source": [
        "def bagging(dataset, model_name, folder='.'):\n",
        "  data_size = len(dataset)\n",
        "  indices = torch.randint(0, data_size, (data_size,))\n",
        "  indices_path = Path(f\"{folder}/data/indices_{model_name}.idx\").expanduser().resolve()\n",
        "  # save indices to file json\n",
        "  if not Path.exists(indices_path):\n",
        "    with open(indices_path, \"w\") as f:\n",
        "      for idx in indices:\n",
        "        f.write(f\"{idx}\\n\")\n",
        "  subset_path = Path(f\"{folder}/data/subset_{model_name}\").expanduser().resolve()\n",
        "  # print(\"path subset : \", subset_path)\n",
        "  if Path.exists(subset_path):\n",
        "    print(f\"Loading subset for {model_name} from disk.\")\n",
        "    subset = HFDataset.load_from_disk(str(subset_path))\n",
        "  else:\n",
        "    print(f\"Creating and saving subset for {model_name}.\")\n",
        "    with open(indices_path, \"r\") as f:\n",
        "      indices = f.read().split()\n",
        "      indices = [int(i) for i in indices]\n",
        "    subset = dataset.select(indices)\n",
        "    subset.save_to_disk(str(subset_path))\n",
        "  return subset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build or load subset bagging dataset models"
      ],
      "metadata": {
        "id": "7gvpdofoMsZk"
      },
      "id": "7gvpdofoMsZk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4deca1db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4deca1db",
        "outputId": "77f3fefc-6b39-47f1-b5f7-ba93c500b3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading subset for model_1 from disk.\n",
            "Loading subset for model_2 from disk.\n",
            "Loading subset for model_3 from disk.\n"
          ]
        }
      ],
      "source": [
        "for config in configs:\n",
        "  subset = bagging(train_ds_raw, config['model_name'], folder=FOLDER_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Dataloader"
      ],
      "metadata": {
        "id": "gjgveNnMM4ki"
      },
      "id": "gjgveNnMM4ki"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e263b0b8-223d-475d-8c9c-01e6cfdc0ea0",
      "metadata": {
        "id": "e263b0b8-223d-475d-8c9c-01e6cfdc0ea0"
      },
      "outputs": [],
      "source": [
        "def get_ds(config, subset, tokenizer_src, tokenizer_tgt, test=False):\n",
        "  dataset = BilingualDataset(subset, tokenizer_src, tokenizer_tgt, config[\"lang_src\"], config[\"lang_tgt\"], config[\"seq_len\"])\n",
        "\n",
        "  max_len_src = 0\n",
        "  max_len_tgt = 0\n",
        "\n",
        "  for item in subset:\n",
        "    src_ids = tokenizer_src.encode(item[config[\"lang_src\"]]).ids\n",
        "    tgt_ids = tokenizer_tgt.encode(item[config[\"lang_tgt\"]]).ids\n",
        "\n",
        "    max_len_src = max(max_len_src, len(src_ids))\n",
        "    max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "\n",
        "  print(\"max length of source sentence\", max_len_src)\n",
        "  print(\"max length of target sentence\", max_len_tgt)\n",
        "  batch_size = 1 if test else config[\"batch_size\"]\n",
        "  dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "  # val_dataloader = DataLoader(val_ds, batch_size=1)\n",
        "  return dataloader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "UAVmd43FM-bj"
      },
      "id": "UAVmd43FM-bj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e701fd66",
      "metadata": {
        "id": "e701fd66"
      },
      "outputs": [],
      "source": [
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "  model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config[\"seq_len\"])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fVDVn8hiSxFp",
      "metadata": {
        "id": "fVDVn8hiSxFp"
      },
      "outputs": [],
      "source": [
        "def train_model(config, train_subset, val_dataloader, tokenizer_src, tokenizer_tgt):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"using device : \", device)\n",
        "\n",
        "  Path(config[\"model_folder\"]).mkdir(parents=True, exist_ok=True)\n",
        "  train_dataloader = get_ds(config, train_subset, tokenizer_src, tokenizer_tgt)\n",
        "  model = get_model(config=config, vocab_src_len=tokenizer_src.get_vocab_size(), vocab_tgt_len=tokenizer_tgt.get_vocab_size()).to(device=device)\n",
        "\n",
        "  # tensorboard\n",
        "  writer = SummaryWriter(config[\"experiment_name\"])\n",
        "\n",
        "  optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"], eps=1e-9)\n",
        "\n",
        "  initial_epoch = 0\n",
        "  global_step = 0\n",
        "  if config[\"preload\"]:\n",
        "    model_filename = get_weights_file_path(config, config[\"preload\"])\n",
        "    print(f\"Preloading model {model_filename}\")\n",
        "    state = torch.load(model_filename)\n",
        "    model.load_state_dict(state[\"model_state_dict\"])\n",
        "    initial_epoch = state[\"epoch\"] + 1\n",
        "    optimizer.load_state_dict(state[\"optimizer_state_dict\"])\n",
        "    global_step = state[\"global_step\"]\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_tgt.token_to_id('[PAD]'), label_smoothing=0.1).to(device=device)\n",
        "  for epoch in range(initial_epoch, config[\"num_epochs\"]):\n",
        "    batch_iterator = tqdm(train_dataloader, desc=f\"Processing  epoch {epoch:02d}\")\n",
        "    for batch in batch_iterator:\n",
        "      model.train()\n",
        "      encoder_input = batch[\"encoder_input\"].to(device)\n",
        "      decoder_input = batch[\"decoder_input\"].to(device)\n",
        "      encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "      decoder_mask = batch[\"decoder_mask\"].to(device)\n",
        "\n",
        "      encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "      decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # type: ignore\n",
        "      proj_output = model.projection_layer(decoder_output)\n",
        "\n",
        "      label = batch[\"label\"].to(device)\n",
        "\n",
        "      loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "\n",
        "      batch_iterator.set_postfix({\"Loss\" : f\"{loss.item():6.3f}\"})\n",
        "\n",
        "      # log loss\n",
        "      writer.add_scalar(\"train loss\", loss.item(), global_step)\n",
        "      writer.flush()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config[\"seq_len\"], device, lambda msg: batch_iterator.write(msg), global_step, writer)\n",
        "\n",
        "      global_step += 1\n",
        "\n",
        "    run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config[\"seq_len\"], device, lambda msg: batch_iterator.write(msg), global_step, writer, num_examples=3)\n",
        "\n",
        "\n",
        "    model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n",
        "    torch.save(\n",
        "      {\n",
        "      \"epoch\": epoch,\n",
        "      \"model_state_dict\": model.state_dict(),\n",
        "      \"optimizer_state_dict\" : optimizer.state_dict(),\n",
        "      \"global_step\": global_step\n",
        "    },\n",
        "    model_filename\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load tokenizer"
      ],
      "metadata": {
        "id": "wIxVwYxsNKHF"
      },
      "id": "wIxVwYxsNKHF"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate"
      ],
      "metadata": {
        "id": "Rxz3ev2tTnHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dea59a-7224-41af-fc45-01c83ed3d118"
      },
      "id": "Rxz3ev2tTnHz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load"
      ],
      "metadata": {
        "id": "erK09SYVTtW-"
      },
      "id": "erK09SYVTtW-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73d181ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73d181ad",
        "outputId": "57c3bbd9-2cc7-46d6-988e-6e1e1f81f77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path tokenizer :  /content/drive/MyDrive/Machine_translation/tokenizer_indonesian.json\n",
            "tokenizer file ada\n",
            "path tokenizer :  /content/drive/MyDrive/Machine_translation/tokenizer_english.json\n",
            "tokenizer file ada\n"
          ]
        }
      ],
      "source": [
        "config = configs[0]\n",
        "tokenizer_src = get_or_build_tokenizer(config, dataset, config['lang_src'])\n",
        "tokenizer_tgt = get_or_build_tokenizer(config, dataset, config['lang_tgt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## build validation dataloader"
      ],
      "metadata": {
        "id": "4T3SelJVNOBW"
      },
      "id": "4T3SelJVNOBW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79cec621",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79cec621",
        "outputId": "0a0405a0-c3df-41a1-a6ab-8820e9af9643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apakah ada masalah di sos eos dan pad token?\n",
            "max length of source sentence 56\n",
            "max length of target sentence 61\n"
          ]
        }
      ],
      "source": [
        "val_dataloader = get_ds(config, val_ds_raw, tokenizer_src, tokenizer_tgt, test=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FOLDER_PATH = '/content/drive/MyDrive/machine_translation'\n",
        "# preloads = [\"03\", \"03\", \"03\"]\n",
        "# configs =[ get_config(f\"model_{i}\", folder=FOLDER_PATH) for i in range(1, 4)]"
      ],
      "metadata": {
        "id": "u6A-TyOX26tn"
      },
      "id": "u6A-TyOX26tn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train per model"
      ],
      "metadata": {
        "id": "rD1EsW2GNTKZ"
      },
      "id": "rD1EsW2GNTKZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2e13bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "efa3ddc00d7c4325a409bb409ffc3c12",
            "2d84d81f798f45dba65f0bcca9a54bbf",
            "dc739d7360824d44908d95d794d27b86",
            "451f48c1d47148ababfca818b199e69a",
            "50fe10a1a07f46078f7115b0c1142d96",
            "d46c2497b84a400aa2888bdc3ae54681",
            "e53ed29f94a04e998c9ff3c313ac82f3",
            "ec588b6e405a4f5bb25a325d3e99e104",
            "574d2ec3bf124e5291985294d8ca1146",
            "d3976d62e12f427da50f00d62a74df2a",
            "face92b06fc346aaa70ce74051fa696e",
            "df971cc326f84c8a822df91a28956423",
            "b0b7aeb52d554cc7a6cb820c60d4b288",
            "9aff6177ccf74b90a99f3093bbbcf2a8",
            "daf7cd7b82474946b0e6cfdd9321be64",
            "fb4bbfd263d64ae282e91cd32ad2f779",
            "5374945b401340eb9c1cbefcdb0fd2dd",
            "d590737f28d044faa1a0854af3a0c8f7",
            "e2014b7620bb48a5a79990f9ca9632bd",
            "7a979acbc9bb4e019c1d9725cb077d4d",
            "2e02bd36533449efbd6caa5f39ad7a57",
            "0c3f1fc2112f472e9b8f13f28eb30608",
            "04b0ee43fd214d2ebaf048188dc44cc1",
            "1ad6e80ffda1434082dd65475d0c3163",
            "449275bb4b314f3c90dafd07a4a1782c",
            "b0ab696e79e24492a4d8a40ece46f606",
            "d7dc3fa7b7a84b928e54d26b7912054e",
            "dca1a67dc1524115b41269232407bda7",
            "9707a2c99c65486db4c51c14078b6920",
            "f43aac02414a4f8c80c95149b29cf55f",
            "d44f1b0643d44ca99f5146b7927588cb",
            "096d4aac5c024b3cafe82d9418293293",
            "d9b900d677664d4ea8b7ecc2b20476ce"
          ]
        },
        "id": "ab2e13bf",
        "outputId": "f1ecfdcb-4672-42c9-8d63-e0418d931cdc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading subset for model_1 from disk.\n",
            "using device :  cuda\n",
            "apakah ada masalah di sos eos dan pad token?\n",
            "max length of source sentence 58\n",
            "max length of target sentence 61\n",
            "Preloading model /content/drive/MyDrive/Machine_translation/weights_model_1/tmodel_24.pt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 25: 100%|██████████| 3934/3934 [05:00<00:00, 13.08it/s, Loss=2.625]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: lalu semuanya berulang dan berulang lagi seperti itu, cara kerja yang sama yang diterapkan pada kompleks militer dan industri masa lalu.\n",
            "Target: and it goes around and around and around, the same way that the military-industrial complex worked a long time ago.\n",
            "Predicted: and then it is all over and over and over again , the same way , the same way that works in the same complex and industrial industry .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: meskipun tikus digunakan di lab untuk mendukung kehidupan manusia, namun tikus juga dianggap hama.\n",
            "Target: and even though they are used in labs to promote human lives, they are also considered pests.\n",
            "Predicted: even though rats are used in the lab to support the human lives , but they also are considered of pests .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: inilah toko tempat saya berbelanja beberapa di antaranya karena mereka harus tahu.\n",
            "Target: so these are the stores that i shop in some of them because they need to know.\n",
            "Predicted: this is a store where i had a lot of them in trouble because they have to know .\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efa3ddc00d7c4325a409bb409ffc3c12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df971cc326f84c8a822df91a28956423",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04b0ee43fd214d2ebaf048188dc44cc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading extra modules: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU: {'bleu': 0.1348131581635488, 'precisions': [0.5142857142857142, 0.208955223880597, 0.09375, 0.03278688524590164], 'brevity_penalty': 1.0, 'length_ratio': 1.1864406779661016, 'translation_length': 70, 'reference_length': 59}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 26: 100%|██████████| 3934/3934 [04:59<00:00, 13.13it/s, Loss=2.837]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: tapi, keju dapat memberikan semua kebaikan susu dengan lebih sedikit laktosa.\n",
            "Target: cheese, however, could provide all of milk’s advantages with much less lactose.\n",
            "Predicted: but cheese can give all the milk ’ s milk , with more aggregates .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu ini menjadi kontes 24-jam.\n",
            "Target: it turned into a 24-hour contest.\n",
            "Predicted: then it became a 24 - hour event .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah pandangan cina tentang negara - sangat, sangat berbeda dengan kita.\n",
            "Target: this is the chinese view of the state very, very different to ours.\n",
            "Predicted: this is a chinese view of very , very different from us .\n",
            "BLEU: {'bleu': 0.19323686456636058, 'precisions': [0.5675675675675675, 0.2647058823529412, 0.16129032258064516, 0.07142857142857142], 'brevity_penalty': 0.9473808953395987, 'length_ratio': 0.9487179487179487, 'translation_length': 37, 'reference_length': 39}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 27: 100%|██████████| 3934/3934 [04:57<00:00, 13.23it/s, Loss=2.813]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: itu menunjukkan jika kedua ujungnya dinyalakan bersamaan, maka sumbu akan terbakar tepat 30 detik.\n",
            "Target: that means that if you lit it from both ends simultaneously, it would burn out in precisely 30 seconds.\n",
            "Predicted: it is showing that if the two end is on the same , then the axis will burn at 30 seconds .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan anda cukup dekat di depan, agak ke tengah, saya rasa.\n",
            "Target: and you are going to be quite near the front, vaguely central, i think.\n",
            "Predicted: and you are pretty close to the front , a bit to the middle , i think .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: revolusi industri dan prometheus telah memberikan kita kemampuan untuk menyinari dunia.\n",
            "Target: the industrial revolution and prometheus has given us this, the ability to light up the world.\n",
            "Predicted: the industrial and ukrainian words gave us the ability to light up to the world .\n",
            "BLEU: {'bleu': 0.21252530842899356, 'precisions': [0.5535714285714286, 0.32075471698113206, 0.18, 0.06382978723404255], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 56, 'reference_length': 56}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 28: 100%|██████████| 3934/3934 [04:58<00:00, 13.17it/s, Loss=2.650]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: dan inilah saat di mana kami melihat perbedaan antara gagak dan hewan lainnya. sebagai contoh, tupai akan muncul, mencari kacang, pergi.\n",
            "Target: this is where we see the difference between crows and other animals.\n",
            "Predicted: and this is when we look at the difference between the crows and other animals , as an example , allows them to appear , find peanut , go away .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: faktanya, banyak yang kita ketahui berasal dari penelitian mekanisme gatal pada tikus.\n",
            "Target: in fact, much of what we do know comes from studying the mechanics of itching in mice.\n",
            "Predicted: in fact , many of the things we know from an itch on the rat mechanism in rats .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: masalah sesungguhnya dengan aorta atas pada penderita sindrom marfan adalah kurangnya gaya tarik.\n",
            "Target: the only real problem with the ascending aorta in people with marfan syndrome is that it lacks some tensile strength.\n",
            "Predicted: the real problem with the aorta to a with a discomfort is a lack of a aesthetic loop .\n",
            "BLEU: {'bleu': 0.12315515352504065, 'precisions': [0.43478260869565216, 0.16666666666666666, 0.09523809523809523, 0.03333333333333333], 'brevity_penalty': 1.0, 'length_ratio': 1.3018867924528301, 'translation_length': 69, 'reference_length': 53}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 29: 100%|██████████| 3934/3934 [04:59<00:00, 13.14it/s, Loss=2.815]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: kenapa? karena semuanya gagal.\n",
            "Target: why? because they fail.\n",
            "Predicted: why ? because they are not going to fail .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mungkin hal paling penting yang kami lihat adalah anak-anak mengajari orang tua mereka.\n",
            "Target: probably the most important thing we see is children teaching parents.\n",
            "Predicted: perhaps the most important thing we see is that children teach their parents .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mesin yang dapat bekerja dan membius pasiennya tidak peduli kondisi apa yang disediakan rumah sakitnya.\n",
            "Target: the prototype for the universal anesthesia machine a machine that would work and anesthetize his patients no matter the circumstances that his hospital had to offer.\n",
            "Predicted: and so the machine that finds her patients do not care about what the circumstances is putting their car in the feeling .\n",
            "BLEU: {'bleu': 0.24375770616696524, 'precisions': [0.5319148936170213, 0.29545454545454547, 0.17073170731707318, 0.13157894736842105], 'brevity_penalty': 1.0, 'length_ratio': 1.0444444444444445, 'translation_length': 47, 'reference_length': 45}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 30: 100%|██████████| 3934/3934 [04:58<00:00, 13.16it/s, Loss=2.649]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: terlihat seperti bentuk hitam.\n",
            "Target: looks like a black shape. so, where is that?\n",
            "Predicted: it looks like black .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kami bisa melihat pemandangan kota yang mana yang membuat orang bahagia.\n",
            "Target: we are able to see which are the urban scenes that make people happy.\n",
            "Predicted: we can see a city that made a happy environment .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: terima kasih,\n",
            "Target: thank you.\n",
            "Predicted: thank you .\n",
            "BLEU: {'bleu': 0.0, 'precisions': [0.631578947368421, 0.1875, 0.07692307692307693, 0.0], 'brevity_penalty': 0.560488043568919, 'length_ratio': 0.6333333333333333, 'translation_length': 19, 'reference_length': 30}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 31: 100%|██████████| 3934/3934 [04:58<00:00, 13.19it/s, Loss=2.654]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: mari kita pastikan gagasan soal sukses ini betul2 merupakan ide kita.\n",
            "Target: let us make sure our ideas of success are truly our own.\n",
            "Predicted: let us make sure that this idea of success is the idea of our ideas .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: menurut kami, kami dapat membuat sebuah filter oleh publik.\n",
            "Target: we think that we can actually create a crowdsourced filter.\n",
            "Predicted: we think we can make a filter by a crowd .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: di bawah cahaya bulan, sekumpulan anak muda menyusup masuk ke hutan, di sanalah mereka terkena ramuan pengubah pikiran, yang mengubah kisah percintaan, dan bersinggungan dengan makhluk dari dunia lain.\n",
            "Target: by the light of the moon, a group of youths sneak into the woods, where they take mind-altering substances, switch it up romantically, and brush up against creatures from another dimension.\n",
            "Predicted: under the light of the moon , a group of young people from their to the forest , which is where they are exposed to love , which changes in love and come to come into contact with another world .\n",
            "BLEU: {'bleu': 0.21613029761356062, 'precisions': [0.5147058823529411, 0.24615384615384617, 0.14516129032258066, 0.11864406779661017], 'brevity_penalty': 1.0, 'length_ratio': 1.1333333333333333, 'translation_length': 68, 'reference_length': 60}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 32: 100%|██████████| 3934/3934 [04:57<00:00, 13.22it/s, Loss=2.728]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: dengan memberi gambar yang tepat ke tangan yang tepat di saat yang tepat, kita dapat menciptakan perbedaan.\n",
            "Target: by putting the right images in the right hands at the right time, we can truly create an impact.\n",
            "Predicted: by giving a good image to the right hand at the right time , we can create a difference .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: cepat atau lambat, semua manusia tidak peduli budaya, bahasa, bangsa, akan sampai pada tingkat akhir perkembangan politik dan sosial ini.\n",
            "Target: sooner or later, all of humanity, regardless of culture, language, nationality, will arrive at this final stage of political and social development.\n",
            "Predicted: sooner or later , everybody do not care about culture , language , will be until at the end of political development and social progress .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sebenarnya ia memotret dirinya sendiri, yang diambil dengan apa yang disebut kamera jebakan.\n",
            "Target: he is actually taking his own picture, shot with what is called a camera trap.\n",
            "Predicted: it actually takes herself to self , which is taken to what is called a trap camera .\n",
            "BLEU: {'bleu': 0.2505302403855415, 'precisions': [0.59375, 0.3114754098360656, 0.1896551724137931, 0.12727272727272726], 'brevity_penalty': 0.9692332344763441, 'length_ratio': 0.9696969696969697, 'translation_length': 64, 'reference_length': 66}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 33: 100%|██████████| 3934/3934 [04:59<00:00, 13.15it/s, Loss=2.686]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: dan alasan saya tertarik pada airnya air yang mengalir melalui tambang menjadi asam dan akan mulai membawa, melarutkan mineral dari tambang itu.\n",
            "Target: and the reason i was interested in getting water is because water which goes through mines becomes kind of acidic and will start picking up, dissolving the minerals from the mine.\n",
            "Predicted: and the reason i am interested in the water that flows through the quarry , and it starts to bring , the mineral of the mine .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan di sayap kiri, liberal, membicarakan tentang ekonomi, selalu tentang perbedaan pendapatan.\n",
            "Target: and on the left, liberals, you are talking about economics, it is always about income inequality.\n",
            "Predicted: and on the left wing , liberal , talk about economics , always about income differences .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya memutuskan saya ingin \"membuat bintang.\"\n",
            "Target: i decided i wanted to make a star.\n",
            "Predicted: i decided i wanted to do \" make a star .\"\n",
            "BLEU: {'bleu': 0.25376472445668774, 'precisions': [0.6607142857142857, 0.37735849056603776, 0.24, 0.10638297872340426], 'brevity_penalty': 0.898397321348071, 'length_ratio': 0.9032258064516129, 'translation_length': 56, 'reference_length': 62}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 34: 100%|██████████| 3934/3934 [04:58<00:00, 13.19it/s, Loss=2.423]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: seperti yang lainnya, mereka bilang, \"wah, makasih dok! asik! saya jadi punya gambar baru.\n",
            "Target: we gathered up our materials, and we went out of the room and counted to a half hour.\n",
            "Predicted: like others , they say , \" whoa , look , look at a comet ! i am making a new picture .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ada banyak hal yang membuat kita tertawa, bukan?\n",
            "Target: there is so much, we laugh, right?\n",
            "Predicted: there is a lot of things that make us laugh , right ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: karena itu artinya, kalau kita mengubah cerita kita, kita bisa mengubah hidup kita.\n",
            "Target: because what it means is that if we can change our stories, then we can change our lives.\n",
            "Predicted: because that means , if we change our story , we can change our lives .\n",
            "BLEU: {'bleu': 0.1863058590268166, 'precisions': [0.4423076923076923, 0.22448979591836735, 0.13043478260869565, 0.09302325581395349], 'brevity_penalty': 1.0, 'length_ratio': 1.04, 'translation_length': 52, 'reference_length': 50}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n",
            "Loading subset for model_2 from disk.\n",
            "using device :  cuda\n",
            "apakah ada masalah di sos eos dan pad token?\n",
            "max length of source sentence 63\n",
            "max length of target sentence 76\n",
            "Preloading model /content/drive/MyDrive/Machine_translation/weights_model_2/tmodel_24.pt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 25: 100%|██████████| 3934/3934 [05:00<00:00, 13.09it/s, Loss=2.873]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: bukan berarti anda harus menyediakan waktu lagi untuk melihat lebih.\n",
            "Target: that does not mean you need to spend any more time to see more.\n",
            "Predicted: it does not mean you have to provide time anymore .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan jika anda melihat faktor lain, perbedaan lain, budak saat itu bernilai sekitar $40.000 dalam uang sekarang.\n",
            "Target: and if you look at another factor, another contrast, a slave back then is worth about $40,000 in today's money.\n",
            "Predicted: and if you look at other factors , another slave , that is about 40 , 000 in money today .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: silahkan saja mengawasi saya kalau itu membantu.\n",
            "Target: feel free to survey me if that helps.\n",
            "Predicted: just watch me watch me if that helps .\n",
            "BLEU: {'bleu': 0.24516554701575355, 'precisions': [0.6341463414634146, 0.3157894736842105, 0.22857142857142856, 0.15625], 'brevity_penalty': 0.8430477266690626, 'length_ratio': 0.8541666666666666, 'translation_length': 41, 'reference_length': 48}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 26: 100%|██████████| 3934/3934 [05:03<00:00, 12.98it/s, Loss=2.727]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: kini hampir semua organisasi mencoba mengirimkan pesan pada dunia luar, pada kumpulan pemirsa yang tersebar, kini menggunakan perubahan ini.\n",
            "Target: now most organizations that are trying to send messages to the outside world, to the distributed collection of the audience, are now used to this change.\n",
            "Predicted: now almost all organizations try to send a message out of the world , in the audience of spread , now using this change .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mari kita lihat betapa ampuhnya rangsangan ini.\n",
            "Target: let us see how powerful just one of these essentials can be.\n",
            "Predicted: let us look at how the power is stimulation .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka tidak akan menggunakannya, atau setidak-tidaknya mereka tidak akan menggunakannya sebagai kelambu, mungkin dijadikan jaring untuk memancing ikan.\"\n",
            "Target: they are not going to use them, or at least they are not going to use them as bed nets, maybe as fishing nets.\"\n",
            "Predicted: they will not use it , or at least at least they will use it as a net , maybe be used to fish fish on fish .\"\n",
            "BLEU: {'bleu': 0.09938717229271701, 'precisions': [0.53125, 0.21311475409836064, 0.06896551724137931, 0.01818181818181818], 'brevity_penalty': 0.9105103613800342, 'length_ratio': 0.9142857142857143, 'translation_length': 64, 'reference_length': 70}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 27: 100%|██████████| 3934/3934 [05:00<00:00, 13.09it/s, Loss=2.673]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: saya akan menunjukkan maksud saya.\n",
            "Target: so i will show you what i mean.\n",
            "Predicted: i am going to show you what i mean .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi pada satu sisi kita melihat reaksi otoritarian.\n",
            "Target: so it is in part that you get an authoritarian reaction.\n",
            "Predicted: so on one hand we see the reaction .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: beberapa orang melihat cakrawala di mana zombie lewat, mereka memperbesar orang tersebut dan anda melihat wajahnya, dan anda tahu apa yang mereka pikir \"apa yang benar-benar membedakan saya dengan zombie?\"\n",
            "Target: some person, looking at the horizon at some zombie going by, and they zoom in on the person and you see the person's face, and you know what they are thinking \"what is really the difference between that zombie and me?\n",
            "Predicted: some people see the horizon where the zombie goes through , they zoom in on the person and you see the face , and you know what they think \" what are they really lying around me when i think of a zombie ?\"\n",
            "BLEU: {'bleu': 0.3474629633659188, 'precisions': [0.625, 0.3770491803278688, 0.29310344827586204, 0.2545454545454545], 'brevity_penalty': 0.9542066659691884, 'length_ratio': 0.9552238805970149, 'translation_length': 64, 'reference_length': 67}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 28: 100%|██████████| 3934/3934 [05:00<00:00, 13.11it/s, Loss=2.821]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: 21 adalah angka yang terdekat.\n",
            "Target: 21 is the closest.\n",
            "Predicted: 21 are the nearest .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya berpikir bahwa ini adalah hubungan dua budaya, di mana untaian-untaian dari budaya berbeda saling terkait.\n",
            "Target: i like to think of it as a mesh of civilizations, in which the strands of different cultures are intertwined.\n",
            "Predicted: i think that this is a two cultural connection , where the strands of different cultures , but combined with different cultures .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: apa yang dapat anda lakukan untuk menyelamatkan atau menolong lebah dan untuk memikirkan keberlanjutan dari kota di masa depan?\n",
            "Target: what can you do to save the bees or to help them or to think of sustainable cities in the future?\n",
            "Predicted: what can you do to save or help bees and do to think about sustainability from the future ?\n",
            "BLEU: {'bleu': 0.2413465734210354, 'precisions': [0.574468085106383, 0.2727272727272727, 0.1951219512195122, 0.13157894736842105], 'brevity_penalty': 0.9583394886604754, 'length_ratio': 0.9591836734693877, 'translation_length': 47, 'reference_length': 49}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 29: 100%|██████████| 3934/3934 [04:59<00:00, 13.13it/s, Loss=2.617]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: program tersebut memberikan dampak yang nyata di sebuah negara seperti ethiopia, dan karena itulah mengapa angka kematian anak di negara tersebut turun 25 dari tahun 2000 ke tahun 2008.\n",
            "Target: that is having real impact in a country like ethiopia, and it is why you see their child mortality numbers coming down 25 percent from 2000 to 2008.\n",
            "Predicted: it gives us a real impact on a country like ethiopia , and because that is why children ' s death rates have fallen in 25 years in 2008 .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itu adalah keseluruhan dari hidupnya, segala sesuatu yang telah terjadi hal-hal buruk, hal-hal baik.\n",
            "Target: it is the sum total of his life, all the things that had happened the bad things, the good things.\n",
            "Predicted: that is the whole of his life , everything that has happened to be bad things , fine .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: melalui udara. tiap harinya, ada dua miliar penumpang pesawat komersial.\n",
            "Target: today we have two billion commercial airline passengers.\n",
            "Predicted: in the air . every day , there are two billion commercial cars .\n",
            "BLEU: {'bleu': 0.19667407473040635, 'precisions': [0.5079365079365079, 0.2833333333333333, 0.14035087719298245, 0.07407407407407407], 'brevity_penalty': 1.0, 'length_ratio': 1.0161290322580645, 'translation_length': 63, 'reference_length': 62}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 30: 100%|██████████| 3934/3934 [05:00<00:00, 13.09it/s, Loss=2.520]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: dan negatif alpha adalah kemiringan dari garis yang saya tunjukkan sebelumnya.\n",
            "Target: and negative alpha is the slope of that line i showed you before.\n",
            "Predicted: and the negative alpha is the slope of the line i have shown here .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: semua video game berisi kekerasan.\n",
            "Target: all video games are violent.\n",
            "Predicted: all games have a game of violence .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: hal lain dari ini adalah dengan terus menerus diberitahu bahwa anda memiliki talenta, terpilih dan lahir untuk memerintah memiliki kerugian yang cukup besar bagi masyarakat.\n",
            "Target: the flipside of this is that constantly being told that you are gifted, chosen and born to rule has distinct societal downsides.\n",
            "Predicted: another thing about this is to constantly be informing that you have talent , and born to tell us to do a huge cost of cost to do a society .\n",
            "BLEU: {'bleu': 0.1568451895571709, 'precisions': [0.4444444444444444, 0.19607843137254902, 0.10416666666666667, 0.06666666666666667], 'brevity_penalty': 1.0, 'length_ratio': 1.2272727272727273, 'translation_length': 54, 'reference_length': 44}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 31: 100%|██████████| 3934/3934 [04:59<00:00, 13.14it/s, Loss=2.580]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: sekarang, untuk mencoba menjelaskan ini dalam pengertian yang sebenarnya, saya ingin membicarakan salah satu tugas yang mungkin anda temui di banyak game.\n",
            "Target: now, to try and explain this in sort of real terms, i want to talk about a kind of task that might fall to you in so many games.\n",
            "Predicted: now , to try to explain this in the real definition , i want to talk about one of the tasks you might ever see in a lot of video games you might see in many games .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itulah perkiraanku.\n",
            "Target: no, that is what i thought.\n",
            "Predicted: that is the stigma .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: memilih keluarga adalah tentang memilih secara sadar siapa dan apa yang anda inginkan bukannya sekadar mengupayakan kecocokan atau menghabiskan waktu dengan siapapun yang kebetulan memilih anda.\n",
            "Target: picking your family is about consciously choosing who and what you want rather than just making it work or killing time with whoever happens to be choosing you.\n",
            "Predicted: choosing your family is about choosing who choose who and what you want to be the right to get your match or spend time by anyone who does not choose you .\n",
            "BLEU: {'bleu': 0.24737669312847343, 'precisions': [0.5866666666666667, 0.3194444444444444, 0.18840579710144928, 0.10606060606060606], 'brevity_penalty': 1.0, 'length_ratio': 1.0869565217391304, 'translation_length': 75, 'reference_length': 69}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 32: 100%|██████████| 3934/3934 [05:02<00:00, 13.01it/s, Loss=2.587]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: \"mahasiswa menganggap lingkungan mereka beragam bila satu orang berasal dari missouri dan yang satunya dari pakistan tanpa mempertimbangkan orang tua keduanya sama-sama dokter atau bankir.\n",
            "Target: \"students think that their environment is diverse if one comes from missouri and another from pakistan never mind that all of their parents are doctors or bankers.\"\n",
            "Predicted: \" students think of their environment , if one person came from missouri to a pakistan without taking into account of both men or a banker or a bankers .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pertama, kelanjutan nasib roma sebagai penguasa di dunia.\n",
            "Target: the first is the continuation of rome as a power in the world.\n",
            "Predicted: first , the grand continuity of rome as the rulers in the world .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lebih dari setengahnya mengalami cedera otak berkelanjutan.\n",
            "Target: more than half of these women have been exposed to repeated brain injuries.\n",
            "Predicted: over half of the brain has a sustainable brain injury .\n",
            "BLEU: {'bleu': 0.11608378699144206, 'precisions': [0.509090909090909, 0.25, 0.08163265306122448, 0.021739130434782608], 'brevity_penalty': 0.9469154662674888, 'length_ratio': 0.9482758620689655, 'translation_length': 55, 'reference_length': 58}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 33: 100%|██████████| 3934/3934 [05:02<00:00, 13.01it/s, Loss=2.580]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: bank dunia,\n",
            "Target: the world bank.\n",
            "Predicted: the world bank , we have the world bank .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: seperti terjebak dalam gelembung yang tak seorang pun mau memecahkannya.\n",
            "Target: it is like we are stuck in these bubbles that nobody wants to burst.\n",
            "Predicted: like being stuck in a bubble that nobody wants to figure it out .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lagipula, tidak ada seorang pun yang mendukung kapitalisme kroni.\n",
            "Target: after all, no one is actually in favor of crony capitalism.\n",
            "Predicted: after all , no one who is supportive of capitalism in crony capitalism .\n",
            "BLEU: {'bleu': 0.29989984326599584, 'precisions': [0.631578947368421, 0.37142857142857144, 0.25, 0.13793103448275862], 'brevity_penalty': 1.0, 'length_ratio': 1.1875, 'translation_length': 38, 'reference_length': 32}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 34: 100%|██████████| 3934/3934 [04:59<00:00, 13.12it/s, Loss=2.795]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: lalu kami menari. kami menyuruh semua orang menari.\n",
            "Target: and then we had dancing. we had everyone dance.\n",
            "Predicted: we dance . we told everyone dancing .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ia mendapatkan seragam perawat, dan setiap malam ia menyelinap untuk duduk di sebelah saya.\n",
            "Target: she acquired a nurse's uniform, and she snuck in every night to sit by my side.\n",
            "Predicted: she got a uniform for nurses , and every night he would sneak on to the next night i was .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan saya ingat kengerian saya saat melihat hewan betina kecil ini dengan bisul tumor besar berbau busuk ini di dalam mulutnya yang telah menghancurkan seluruh rahang bawahnya.\n",
            "Target: and i remember the horror of seeing this little female devil with this huge ulcerating, foul-smelling tumor inside her mouth that had actually cracked off her entire lower jaw.\n",
            "Predicted: and i remember the horror of my emotions when i saw this small female body with its great blood , this bed in his mouth that had destroyed all its way down the tree .\n",
            "BLEU: {'bleu': 0.14549009475340655, 'precisions': [0.484375, 0.19672131147540983, 0.08620689655172414, 0.05454545454545454], 'brevity_penalty': 1.0, 'length_ratio': 1.0666666666666667, 'translation_length': 64, 'reference_length': 60}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n",
            "Loading subset for model_3 from disk.\n",
            "using device :  cuda\n",
            "apakah ada masalah di sos eos dan pad token?\n",
            "max length of source sentence 59\n",
            "max length of target sentence 64\n",
            "Preloading model /content/drive/MyDrive/Machine_translation/weights_model_3/tmodel_24.pt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 25: 100%|██████████| 3934/3934 [05:01<00:00, 13.05it/s, Loss=2.575]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: mari kita bedakan dengan pembangunan,\n",
            "Target: let us contrast that for a minute to development.\n",
            "Predicted: let us just get the slider with , ok .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan amerika serikat hanya memiliki 2.000 dolar, pada saat itu.\n",
            "Target: and united states only had some, one, two thousand dollars at that time.\n",
            "Predicted: and the united states only has 2 , 000 dollars , at that time .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mari kita lihat lagi dirigen super yang lain, seorang dirigen super dari jerman, herbert von karajan, silakan.\n",
            "Target: let us see another super-conductor, a german super-conductor. herbert von karajan, please.\n",
            "Predicted: let us see again the other conductor , a super conductor from germany , eduardo ' s , alex , please come ahead .\n",
            "BLEU: {'bleu': 0.12274394526913653, 'precisions': [0.4489795918367347, 0.21739130434782608, 0.09302325581395349, 0.025], 'brevity_penalty': 1.0, 'length_ratio': 1.1666666666666667, 'translation_length': 49, 'reference_length': 42}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 26: 100%|██████████| 3934/3934 [05:00<00:00, 13.07it/s, Loss=2.870]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: aku tak begitu tahu apapun tentangmu.\n",
            "Target: i did not really know anything really about you.\n",
            "Predicted: i do not know anything like anything .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita tidak bagus dalam mengelola uang.\n",
            "Target: we are not doing a great job managing money.\n",
            "Predicted: we are not good at managing money .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: di sini ketika saya berkata \"lebih aman\", maksud saya tak hanya untuk para tahanan, tetapi juga untuk tim penilai.\n",
            "Target: and here when i say \"safer,\" i mean safer not only for the inmates, but safer also for correctional staff.\n",
            "Predicted: here when i say \" is safer ,\" i mean not just for prisoners , but also for the judges , but for the of the judges .\n",
            "BLEU: {'bleu': 0.2735015309798121, 'precisions': [0.6444444444444445, 0.38095238095238093, 0.20512820512820512, 0.1111111111111111], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 45, 'reference_length': 45}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing  epoch 27: 100%|██████████| 3934/3934 [04:58<00:00, 13.17it/s, Loss=2.807]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: dengan kata lain, ada ruang bagi dia untuk bermimpi dengan saya.\n",
            "Target: in other words, there was space for him to dream with me.\n",
            "Predicted: in other words , there is a space for him to dream .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: apakah anda tahu bahwa bila anda melaporkan pajak sendiri, secara statistik anda lebih mungkin melaporkannya dengan benar daripada bila menyuruh penasehat pajak melakukannya untuk anda?\n",
            "Target: did you know that if you file your tax returns yourself, you are statistically more likely to be filing them correctly than if you get a tax adviser to do it for you?\n",
            "Predicted: do you know that if you report your own tax , your statistics might be more likely to start by imagining it by if you are a tax lottery tickets for you ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: membawa sebuah bola. dan dia menyadari saat dia menarik keretanya, bolanya bergulir ke bagian belakang kereta.\n",
            "Target: he noticed that when he pulled the wagon, the ball went to the back of the wagon.\n",
            "Predicted: he took a ball . and he noticed that when he was pulling the train , the vaulter was a subway .\n",
            "BLEU: {'bleu': 0.2907755844832122, 'precisions': [0.6323529411764706, 0.36923076923076925, 0.22580645161290322, 0.13559322033898305], 'brevity_penalty': 1.0, 'length_ratio': 1.0, 'translation_length': 68, 'reference_length': 68}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 28: 100%|██████████| 3934/3934 [05:02<00:00, 13.00it/s, Loss=2.533]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: mereka telah mengalahkan amerika serikat sebagai pasar mobil terbesar. mereka telah mengalahkan jerman sebagai eksporter terbesar. dan mereka telah mulai melakukan tes dna pada anak-anak untuk menetapkan karier mereka.\n",
            "Target: they have overtaken the you.s. as the world's biggest car market, they have overtaken germany as the largest exporter, and they have started doing dna tests on kids to choose their careers.\n",
            "Predicted: they have been overcome the united states as the largest car market , they have been overcome germany as the largest , and they have started doing dna tests on their own career .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita yakin manusia terhubung bisa ciptakan masa depan apapun yang terbayangkan.\n",
            "Target: we believed that human beings connected could create any future we could imagine.\n",
            "Predicted: we believe that humans are connected to any future that is then the resolution .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: terima kasih banyak.\n",
            "Target: thank you very much.\n",
            "Predicted: thank you very much .\n",
            "BLEU: {'bleu': 0.3641836032001534, 'precisions': [0.6666666666666666, 0.43137254901960786, 0.3125, 0.24444444444444444], 'brevity_penalty': 0.9459594689067654, 'length_ratio': 0.9473684210526315, 'translation_length': 54, 'reference_length': 57}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 29: 100%|██████████| 3934/3934 [05:01<00:00, 13.06it/s, Loss=2.626]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: semua yang saya lakukan, terutama secara profesional hidup saya telah dibentuk oleh karya 7 tahun saya sebagai pemuda di afrika.\n",
            "Target: everything i do, and everything i do professionally my life has been shaped by seven years of work as a young man in africa.\n",
            "Predicted: all of my mind , especially my life professional has been shaped by my seven years as a young man in africa .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ketika anda sampai di dalam, anda masuk area yang merupakan favorit saya.\n",
            "Target: again, when you get to the back, you get into an area that is really my favorite place.\n",
            "Predicted: when you get to the inside , you go into a very favorite area of my favorite area .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: yang kami coba lakukan, seperti cara di ted ini, adalah mengelola semua informasi biologis berdasarkan fungsi desain dan rekayasanya.\n",
            "Target: and what we are trying to do, in a tedesque way, is to organize all biological information by design and engineering function.\n",
            "Predicted: what we are trying to do , like in this ted , is to manage all biological information based on design and change the change .\n",
            "BLEU: {'bleu': 0.32940193084994046, 'precisions': [0.6764705882352942, 0.4307692307692308, 0.27419354838709675, 0.1864406779661017], 'brevity_penalty': 0.9428731438548749, 'length_ratio': 0.9444444444444444, 'translation_length': 68, 'reference_length': 72}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 30: 100%|██████████| 3934/3934 [05:02<00:00, 13.02it/s, Loss=2.583]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: mereka melihat ekonomi uang yang tidak dapat mereka masuki sewaktu menjadi petani.\n",
            "Target: they see a cash economy that they were not able to participate in back in the subsistence farm.\n",
            "Predicted: they saw the economic economy that they could not be part of being developed .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bagi bibi, kakek, dan ayah saya, kami selalu membuat dua pemakaman. satu untuk tubuh mereka, tetapi jauh sebelum itu, satu untuk mimpi mereka.\n",
            "Target: for my aunt, my grandfather, my father, we always held two funerals one for their bodies, but, years before that, one for their dreams.\n",
            "Predicted: to my aunt , my father and my father , we always made two funeral .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: misha glenny hadirin, anonymous, sekelompok peretas yang memiliki kepentingan politik yang muncul di tahun 2011.\n",
            "Target: misha glenny anonymous, ladies and gentlemen a sophisticated group of politically motivated hackers who have emerged in 2011.\n",
            "Predicted: the of ladies and gentlemen , anonymous and lots of hackers that have a political interest in 2011 .\n",
            "BLEU: {'bleu': 0.14964534132214227, 'precisions': [0.6, 0.2765957446808511, 0.20454545454545456, 0.07317073170731707], 'brevity_penalty': 0.6703200460356393, 'length_ratio': 0.7142857142857143, 'translation_length': 50, 'reference_length': 70}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 31: 100%|██████████| 3934/3934 [05:03<00:00, 12.95it/s, Loss=2.634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: kami meminta orang untuk membangun beberapa origami.\n",
            "Target: we asked people to build some origami.\n",
            "Predicted: we asked people to build some origami .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi tidak mustahil bahwa, suatu saat nanti, video online akan secara dramatis mempercepat kemajuan ilmiah.\n",
            "Target: so it is not far-fetched to say that, at some point, online video is going to dramatically accelerate scientific advance.\n",
            "Predicted: so it is not impossible , one time , online video will be dramatically dramatically accelerating scientific progress .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita juga memiliki jutaan lampu jalan yang ada di seluruh dunia.\n",
            "Target: and then you have these millions of street lamps deployed around the world.\n",
            "Predicted: we also have millions of roads that we have all over the world .\n",
            "BLEU: {'bleu': 0.3056532846137952, 'precisions': [0.6097560975609756, 0.39473684210526316, 0.2857142857142857, 0.1875], 'brevity_penalty': 0.9070470321236944, 'length_ratio': 0.9111111111111111, 'translation_length': 41, 'reference_length': 45}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 32: 100%|██████████| 3934/3934 [05:00<00:00, 13.09it/s, Loss=2.514]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: saya ellen, dan saya sangat terobsesi dengan pangan.\n",
            "Target: i am ellen and i am totally obsessed with food.\n",
            "Predicted: i was ellen , and i was obsessed with food .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini akan menjadi lebih rumit daripada itu.\n",
            "Target: it is going to be much more complicated than that.\n",
            "Predicted: it will be more complicated than that .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah bulan ketika korea utara setuju untuk melucuti fasilitas nuklir mereka.\n",
            "Target: now, this was a month when north korea agreed to dismantle its nuclear facilities.\n",
            "Predicted: this is the moon when north korea ' s . inside of their nuclear facility .\n",
            "BLEU: {'bleu': 0.23741074263374584, 'precisions': [0.6, 0.3125, 0.20689655172413793, 0.11538461538461539], 'brevity_penalty': 0.9178564384568926, 'length_ratio': 0.9210526315789473, 'translation_length': 35, 'reference_length': 38}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 33: 100%|██████████| 3934/3934 [05:01<00:00, 13.03it/s, Loss=2.552]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: kita melakukan interogasi kecil-kecilan saat kita bertemu orang lain untuk membuat rangkuman riwayat hidup mereka di dalam pikiran kita.\n",
            "Target: we do this little interrogation when we meet people to make a mental resume for them.\n",
            "Predicted: we did a little interrogation we looked at the little while we met other people to run their gate , their lives in our minds .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tetapi, saya mengambil risiko setelah sadar bahwa kesempatan tak terduga sering kali datang setelah mengambil risiko, bukan tipe risiko berbahaya yang sudah saya teliti, tetapi risiko yang baik, risiko yang positif.\n",
            "Target: but i took risks realizing that unforeseen opportunities often come from risk-taking not the hazardous, negative type that i studied, but the good ones, the positive risks.\n",
            "Predicted: but i took a risk after realizing that unexpected opportunity often came after to visit , not the risks that i had been looking at the dangerous risk of having already been studied , good risks , positive risk - positive risk .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya akan mulai dengan ini dua tahun yang lalu, seorang panitia acara menelpon saya karena saya ikut dalam suatu ceramah waktu menelpon, dia bilang\n",
            "Target: so, i will start with this a couple years ago, an event planner called me because i was going to do a speaking event.\n",
            "Predicted: i am going to start with this two years ago , a special election event said , because i was taking me in a talk at a talk about , and he said , \" he said .\n",
            "BLEU: {'bleu': 0.0, 'precisions': [0.42990654205607476, 0.14423076923076922, 0.039603960396039604, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.4266666666666667, 'translation_length': 107, 'reference_length': 75}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing  epoch 34: 100%|██████████| 3934/3934 [05:01<00:00, 13.06it/s, Loss=2.619]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: saya berbicara tentang ini sebelumnya, dan seseorang yang brilian menghubungi saya dan berkata, \"oke, apa yang dapat anda lakukan?\"\n",
            "Target: i spoke about this before, and a brilliant person got in touch with me and said, \"okay, what can you do?\"\n",
            "Predicted: i talked about this before , and somebody who was brilliant to call me and said , \" okay , what can you do ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka menolak dominasi kelompok atau individu. bahkan kepada atasan atau pakar.\n",
            "Target: they do not let one group or one individual dominate, even if it is the boss, even if it is the expert.\n",
            "Predicted: they refuse to be improved groups or an individual .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itu menurun manjadi 12 sampai 15 persen saja.\n",
            "Target: that is down to about 12 to 15 percent.\n",
            "Predicted: that is down the wage of 12 percent until it is 15 percent .\n",
            "BLEU: {'bleu': 0.32200784691820383, 'precisions': [0.62, 0.425531914893617, 0.36363636363636365, 0.2926829268292683], 'brevity_penalty': 0.7866278610665535, 'length_ratio': 0.8064516129032258, 'translation_length': 50, 'reference_length': 62}\n",
            "Could not compute BLEU metric: 'int' object has no attribute 'get'\n"
          ]
        }
      ],
      "source": [
        "FOLDER_PATH = '/content/drive/MyDrive/Machine_translation'\n",
        "# epoch = [10, 15, 20]\n",
        "preload = [\"24\", \"24\", \"24\"]\n",
        "# for ep in range(13, 31):\n",
        "  # preload = [f\"{ep-2}\", f\"{ep-2}\", f\"{ep-2}\"]\n",
        "  # print(preload)\n",
        "configs =[ get_config(f\"model_{i}\", folder=FOLDER_PATH, preload=preload[i-1], epoch=35) for i in range(1, 4)]\n",
        "for config in configs:\n",
        "  subset = bagging(train_ds_raw, config['model_name'], folder=FOLDER_PATH)\n",
        "  train_model(config, subset, val_dataloader, tokenizer_src, tokenizer_tgt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w61hZb3LzYV_",
      "metadata": {
        "id": "w61hZb3LzYV_"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea63682b-b618-4c68-a63d-5a8f11c8ca17",
      "metadata": {
        "id": "ea63682b-b618-4c68-a63d-5a8f11c8ca17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96642141-2d91-4b5f-bbd2-cdc8b88424be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device :  cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using device : \", device)\n",
        "models = {}\n",
        "preload = [\"34\", \"34\", \"34\"]\n",
        "configs =[ get_config(f\"model_{i}\", folder=FOLDER_PATH, preload=preload[i-1]) for i in range(1, 4)]\n",
        "for config in configs:\n",
        "  model = get_model(config=config, vocab_src_len=tokenizer_src.get_vocab_size(), vocab_tgt_len=tokenizer_tgt.get_vocab_size()).to(device=device)\n",
        "  model_filename = get_weights_file_path(config, config[\"preload\"])\n",
        "  state = torch.load(model_filename) # use GPU\n",
        "  # state = torch.load(model_filename, map_location=torch.device('cpu')) # use cpu\n",
        "  model.load_state_dict(state[\"model_state_dict\"])\n",
        "  model_name = config['model_name']\n",
        "  models[model_name] = model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "salr0K5VifBD"
      },
      "id": "salr0K5VifBD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vfD8T7UIie8D"
      },
      "id": "vfD8T7UIie8D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VF2XmBFLie4C"
      },
      "id": "VF2XmBFLie4C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = get_ds(config, val_ds_raw, tokenizer_src, tokenizer_tgt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yq2txH1tibE3",
        "outputId": "642b3c9a-c0b7-4efd-bbe3-473d4465868a"
      },
      "id": "yq2txH1tibE3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apakah ada masalah di sos eos dan pad token?\n",
            "max length of source sentence 56\n",
            "max length of target sentence 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run validation"
      ],
      "metadata": {
        "id": "98jf2YgCOGnJ"
      },
      "id": "98jf2YgCOGnJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1cebc61-20d8-4f6a-a8c3-394e724ddce8",
      "metadata": {
        "id": "a1cebc61-20d8-4f6a-a8c3-394e724ddce8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82b9b6dc-fc0f-42d5-99e5-ec9f17c4f33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Source: tetapi bisakah lebih cepat? berapa nyawa yang bisa terselamatkan?\n",
            "Target: but how much faster could we go, how many lives could we save?\n",
            "Predicted: but can it be faster ? how many lives can be saved ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itu seperti ada gempa haiti setiap delapan hari.\n",
            "Target: that is a haiti earthquake every eight days.\n",
            "Predicted: it was like there in haiti every eight days .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mengapa? ternyata pria memproduksi sperma yang sangat banyak.\n",
            "Target: why? turns out that men make a lot of sperm.\n",
            "Predicted: why ? well , it turns out that a guy produces a lot of sperm .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan agar seimbang, saya percaya kita harus berada pada seluruh area tersebut tidak hanya melakukan 50 sit-up.\n",
            "Target: and to be balanced, i believe we have to attend to all of those areas not just do 50 stomach crunches.\n",
            "Predicted: and to be balanced , i believe we should be in all of these areas are not just doing 50 years .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan saya memiliki empat pengamatan yang ingin saya bagikan kepada anda hari ini.\n",
            "Target: and i have four observations i would like to share with you today.\n",
            "Predicted: and i have four quick observation i want to share with you today .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: beberapa tahun lalu mereka mengadakan protes.\n",
            "Target: years ago they held a protest.\n",
            "Predicted: a few years ago they had a protest .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi poin utamanya, adalah, jika kita ingin menyalurkan banyak uang demi kebaikan yang kecil, 100 tahun dari sekarang, seorang belanda yang cukup kaya?\n",
            "Target: and so the real point, of course, is to say, do we want to spend a lot of money helping a little, 100 years from now, a fairly rich dutch guy?\n",
            "Predicted: so the main point is , if we want to deliver many money to be good for good good good at this time , 100 years from now , a fairly rich dutch guy ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya memulai monolog vagina karena saya khawatir akan vagina.\n",
            "Target: i began \"the vagina monologues\" because i was worried about vaginas.\n",
            "Predicted: i started on the vagina of vagina because i worried about vaginas .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi, saya berlari-lari di dalam dingin yang membekukan, dan i memotret sebanyak mungkin orang yang saya bisa, di bulan februari 2 tahun yang lalu.\n",
            "Target: so i ran out in the freezing cold, and i photographed every single person that i knew that i could get to in february of about two years ago.\n",
            "Predicted: so i ran in the cold , and i took photographs , and i took as many people i could , in february two years ago .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bumi adalah tempat belajar memaafkan.\n",
            "Target: earth is forgiveness school.\n",
            "Predicted: earth is a place to forgive .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan ini akan mencegah penggunaan ulang jarum suntik 20 atau 30 kali.\n",
            "Target: and that will stop reusing a syringe 20 or 30 times.\n",
            "Predicted: and it will prevent 20 - use needle or 30 times .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: aku akan membunuh ayah.\n",
            "Target: i am going to kill dad.\n",
            "Predicted: i will kill my father .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: artinya bahwa kami ingin lebih banyak orang sehat dan terdidik\n",
            "Target: and what that means is we want to have more people who are healthy and educated.\n",
            "Predicted: that means that we want to be more healthy and everyday people .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kami memutuskan untuk menyediakan vasektomi bagi semua pria namun khususnya, bagi pria amerika di bagian depan antrian, tepat di depan kediaman duta besar saat dia .\n",
            "Target: we decided to provide vasectomy to all men, but in particular, american men to the front of the queue, right up to the ambassador's residence during his vin d'honneur.\n",
            "Predicted: we decided to provide full of inspiration for all men but especially , for the american ' s top - line men , right in front of the while he was .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: betapa mengagumkan bahwa jauh lebih mengerikan yang terlihat di kenyataan daripada di tv.\n",
            "Target: and it was amazing how much harder it was to believe in real life than it was on tv.\n",
            "Predicted: how amazing is that much more terrifying that seems to be seen in the tv than on tv .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini merupakan hari perjalanan ibrahim.\n",
            "Target: it was abraham path day.\n",
            "Predicted: this is a day of abraham .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: satu dari tiga pria kulit hitam antara 18 hingga 30 tahun berada di penjara, dalam masa percobaan, atau pembebasan bersyarat.\n",
            "Target: one out of three black men between the ages of 18 and 30 is in jail, in prison, on probation or parole.\n",
            "Predicted: one of the black male between 18 to 30 years in prison , in the course of an experiment , or the release of the portion of the food .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ternyata bayi-bayi, bayi dari gagak kaledonian, diasuh.\n",
            "Target: well it turns out that the babies, the new caledonian crow babies, are fledglings.\n",
            "Predicted: turns out babies , babies of crows , guys from , academic costumes .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: juga saya sangat yakin bahwa banyak bantuan saat ini tidak lebih baik daripada bantuan secara langsung pada orang miskin.\n",
            "Target: i am also absolutely certain that a lot of aid today is not better than giving directly to the poor.\n",
            "Predicted: and i am also sure that many help of these days are not better than help with the aid .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: proses ini diikuti dengan mengatupnya pita-pita suara secara tiba-tiba sehingga menutup rongga yang diapitnya, yang disebut glotis.\n",
            "Target: this is followed almost immediately by the sudden closure of the vocal chords and the opening between them, which is called the glottis.\n",
            "Predicted: this process was followed by band - tubes suddenly closed so that closed the stereotypes , called the closure of the glottis .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi, kita hanya akan melihat bintang-bintang di dalam kotak kecil itu, walaupun kita telah melihat semuanya.\n",
            "Target: so, we are only going to look at the stars inside that small square, although we have looked at all of them.\n",
            "Predicted: so we are just going to look at the stars in the small boxes , even though we have seen everything .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini menjijikkan.\n",
            "Target: it is disgusting.\n",
            "Predicted: this is disgusting .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini merupakan konsep yang bertentangan.\n",
            "Target: that seems like a pretty counterintuitive thought.\n",
            "Predicted: it is a self - negating concept .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan sekarang ,lagi-lagi ada 10 jutaan hubungan ini yang menunjukkan pada kita jaringan hubungan grafik sosial dan bagaimana mereka berhubungan pada konten.\n",
            "Target: and there are, again, now tens of millions of these links that give us the connective tissue of social graphs and how they relate to content.\n",
            "Predicted: and now , again , there are 10 million of these connections that show us the social graph of social graph relationships and how they connect to content .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan kita punya 600 milyar dolar.\n",
            "Target: and we have got 600 billion dollars.\n",
            "Predicted: and we have 600 billion dollars .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: satu juta pon per hari terdengar banyak namun jumlah itu kecil dibandingkan benda yang masih bisa dipakai yang dibuang setiap tahunnya di seluruh dunia kurang dari satu persen.\n",
            "Target: now a million pounds a day sounds like a lot of stuff, but it is a tiny drop of the durable goods that are disposed each and every year around the world well less than one percent.\n",
            "Predicted: one million pounds per day sounds a lot , but that is a small number of things that can be used to be washed away every year around the world , less than one percent .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: garis itu hanya bergerak pada tiga arah horizontal, vertikal, atau melintang.\n",
            "Target: the lines only go in three directions they are horizontal, they are vertical, or they are 45 degrees.\n",
            "Predicted: the line is just moving on three horizontal direction , vertical or horizontal horizontal layers .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini nadir.\n",
            "Target: this is nadir.\n",
            "Predicted: this is look at you .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi tim saya dan saya sendiri yakin kami bisa membawanya ke pasaran dua atau tiga tahun lagi.\n",
            "Target: but my team and i are confident that we can take this to market within the next two to three years.\n",
            "Predicted: but my team and i am sure we can take it to the market or three years .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi \"dapatkah robot mengubah rasa empati manusia?\"\n",
            "Target: it is \"can robots change people's empathy?\"\n",
            "Predicted: but \" can the robot change human empathy ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itu sampai akhir 1980an, ketika laboratorium teknik baru muncul, yang bisa menyalin dna dari jaringan kecil atau contoh cairan dan memecah kode genetik individu.\n",
            "Target: that was until the late 1980s, when a new laboratory technique came on the scene, which could copy dna from a small tissue or fluid sample and decode the genetics of individuals.\n",
            "Predicted: that was until the late 1980s , when new engineering lab had emerged , which could copy dna from small tissue or fluid liquid code of individual code .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: semua yang digital tidak otomatis menjadi milik umum.\n",
            "Target: everything digital is not just automatically public.\n",
            "Predicted: all digital digital worlds are not common .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: yang anda lihat di sini adalah negara memonitor para individu, orang-orang yang, seperti anda, ingin mengubah negara mereka dan negara mencatat semuanya.\n",
            "Target: and what you see there is the state following individuals, people that, like you, wanted to change their country, and they jotted everything down.\n",
            "Predicted: what you see here is a monitoring world war , people who , like you , like , you want to change their countries and post those countries of records all .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah bagian dari keberadaan kita.\n",
            "Target: these are the terms of our existence.\n",
            "Predicted: this is part of our existence .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ada argumen bahwa pengetahuan luas mary tentang penglihatan warna memungkinkan mary mencapai kondisi mental yang sama dengan melihat warna secara nyata.\n",
            "Target: some argue that her extensive knowledge of color vision would have allowed her to create the same mental state produced by actually seeing the color.\n",
            "Predicted: there is a argument that mary ' s vast majority of color vision allow mary to reach the same mental state to see color real color .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tetapi semakin kontroversial topiknya dan semakin mengecewakan debatnya, semakin penting untuk ilmuwan untuk mempertahankan objektivitas kami dan reputasi integritas kami.\n",
            "Target: but the more controversial the subject and the more frustrating the debate, the more critical it is for scientists to preserve our objectivity and our reputation for integrity.\n",
            "Predicted: but the more controversial topics and the debate has been down to the debate , the more important to keep our scientists intertwined to hold our integrity and our reputation .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya ingin anda sesaat membayangkan.\n",
            "Target: i want you to imagine, for a moment, two children.\n",
            "Predicted: i want you to just imagine .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda menyaksikan cuplikan dari \"sputnik,\" film dokumenter kelima saya yang baru saja selesai.\n",
            "Target: you are watching snippets from \"sputnik,\" my fifth documentary feature, which is just about completed.\n",
            "Predicted: you see a screenshot from \" my five - british documentary film just finished .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: terima kasih.\n",
            "Target: thank you.\n",
            "Predicted: thank you .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sekarang, jika anda melihat harga tanah yang ada di dekatnya, anda sebenarnya dapat membelinya, memangkas semaknya untuk meningkatkan sudut pandang pengemudi, lalu menjualnya lagi.\n",
            "Target: now, if you look at what that adjacent property is worth, you could actually buy the property, cut down the shrubbery to improve the sight line, and then sell it off again.\n",
            "Predicted: now , if you look at the prices that are nearby , you can actually buy , cut off the bush for the cutting edge of the driver ' s perspective , and sell it again .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: menurut saya dari dulu sudah salah. karena saya selalu meyakini kreativitas itu hasil kolaborasi. dan mungkin juga sifatnya sangat interaktif.\n",
            "Target: i think it is always been wrong, because i think always creativity has been highly collaborative, and it is probably been largely interactive.\n",
            "Predicted: i think of the time , because i have always believed that creativity results together , and maybe also the nature of collaboration .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita berpikir itu adalah jalan pintas.\n",
            "Target: we think it is shortcut.\n",
            "Predicted: we think that is a shortcut .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi jika kita menggunakan ide itu, kita bisa menggunakan makanan sebagai perangkat yang sangat kuat untuk membentuk dunia yang lebih baik.\n",
            "Target: but if we take that idea, we can use food as a really powerful tool to shape the world better.\n",
            "Predicted: but if we use that idea , we can use food as a very strong device to shape the world a better way of creating a better world .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini putra saya tamer. anda dapat lihat dia sangat menyenangi kunjungan matematis kami ke alhambra.\n",
            "Target: this is my son tamer. you can see he is really enjoying our mathematical trip to the alhambra.\n",
            "Predicted: this is my son . you can see him very mathematical visit our alhambra .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah bentuk awal dari terhubungnya teknologi.\n",
            "Target: it is one of our earliest forms of connective technology.\n",
            "Predicted: this is the starting form of a thriving technology .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: nah, inilah mereka.\n",
            "Target: well, this is what they are.\n",
            "Predicted: now , this is what they are .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: terkadang anda mengira bahwa anak-anak akan senang, tapi mereka terkadang malah takut.\n",
            "Target: sometimes you would think that maybe kids would enjoy it, but sometimes they get a little freaked out.\n",
            "Predicted: sometimes you think that kids will be happy , but they sometimes be scared .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tidak akan berhasil.\n",
            "Target: it does not work.\n",
            "Predicted: it is not going to work .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sekarang, apa yang lebih parah dari pembatasan adalah orang dewasa sering meremehkan kemampuan anak-anak.\n",
            "Target: now, what is even worse than restriction, is that adults often underestimate kids' abilities.\n",
            "Predicted: now , what is worse than some irony is that adults are often underestimated the ability of children .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mikroskopi, tes standar dari who, memiliki tingkat keandalan 40 hingga 60 persen.\n",
            "Target: microscopy, the standard who procedure, reaches from 40 to 60 percent reliability.\n",
            "Predicted: microscopy , the standard test test from the world health organization , has a rate 40 to 60 percent .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya setuju bahwa sebenarnya baik untuk mempelajari kata-kata baru untuk emosi, tapi saya pikir kita perlu untuk lebih jauh lagi.\n",
            "Target: so i agree absolutely that it does us good to learn new words for emotions, but i think we need to go further.\n",
            "Predicted: i agree that actually is good to study new words for emotions , but i think we need to be much more .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan joshua tetap diam saat mereka melampiaskan kemarahannya.\n",
            "Target: and joshua remains silent as they vented their rage against him.\n",
            "Predicted: and joshua remained silent as they were extended to anger .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah dua teks yang mengandung beberapa simbol.\n",
            "Target: here are two texts that contain some symbols on them.\n",
            "Predicted: this is two textbooks that contains some symbols .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mengunjungi rumah-rumah zabbaleen sungguh penuh kejutan.\n",
            "Target: visiting the homes of the zabbaleen is also full of surprises.\n",
            "Predicted: traveling from the zabbaleen was really full of surprises .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya senang mengoperasinya.\n",
            "Target: i would love to operate on her.\n",
            "Predicted: i love a bedtime fraction .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: yang satu orang menawarkan pendidikan menengah gratis untuk semua, tidak hanya 30 masyarakat.\n",
            "Target: one guy offered free secondary school education to all, not just 30 percent.\n",
            "Predicted: one person offers free to all the time , not only 30 societies .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi di sini kita lihat selama 50 tahun terakhir, biaya perawatan kesehatan naik dari sekitar lima persen di jerman menjadi sekitar 11 persen saat ini.\n",
            "Target: so here we see that over the last 50 years, health care expense has grown from about five percent in germany to about 11 percent now.\n",
            "Predicted: so here we see over the last 50 years , the cost of the health care spending on about five percent in germany , and it is about 11 percent of the time .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: yayasan oak dan national geographic juga telah menjadi penyumbang terbesar dari hal ini\n",
            "Target: the oak foundation and national geographic have been big funders of this as well.\n",
            "Predicted: the costa rica , it is also been a big contributor to this .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: para pelaku melihatnya juga.\n",
            "Target: the perpetrators saw them too.\n",
            "Predicted: people have seen them as well .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini berarti, melatih kembali semua pembimbing ini.\n",
            "Target: this means, certainly, to retrain all health staff.\n",
            "Predicted: this means that train again , we trained all the volunteers .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tetapi yang terpenting adalah ada jalan, ketika ada lebih banyak perempuan di meja, bahwa ada upaya untuk mengembangkan pemahaman.\n",
            "Target: but the bottom line is that there is a way, when there are more women at the table, that there is an attempt to develop some understanding.\n",
            "Predicted: but the most important thing is there is a way , when there is more women on the table , that there is a efforts to develop understanding .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: namun di dalam gedung ini ada ruang bawah tanah bertingkat.\n",
            "Target: but it goes down below ground many stories.\n",
            "Predicted: but in this building is under a concentrated space - level space .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lebih dari 99 persen obat kanker tidak mencapai tumornya, karena tak ada transportasi dan peralatan untuk membawa mereka ke lokasi tujuannya.\n",
            "Target: over 99 percent of cancer drugs never make it to the tumor because they lack transportation and tools to take them to the location they are aiming for.\n",
            "Predicted: over 99 percent of the cancer drug does not reach the tumor , because there is no transportation and the equipment to bring them to the destination .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jika mereka menemukan air, mereka akan memanjat, berenang di atasnya.\n",
            "Target: if they come to water, they will climb in, swim across it.\n",
            "Predicted: if they found water , they would climb , they would climb on the top .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: putri saya memberikan saya sebuah anekdot yang cukup bagus tentang hal ini.\n",
            "Target: my daughter gave me a rather nice anecdote on this.\n",
            "Predicted: my daughter gave me a pretty good anecdote about this .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan akhirnya, kita harus merangkul keterbukaan.\n",
            "Target: and ultimately, we have to embrace transparency.\n",
            "Predicted: and finally , we have to embrace openness .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itulah apa yang mereka yakini tentang amerika yang membuat mereka naik bis selama 8 jam, berdiri di bawah matahari di washington pada pertengahan agustus.\n",
            "Target: it is what they believed about america that got them to travel in a bus for eight hours to stand in the sun in washington in the middle of august.\n",
            "Predicted: that is what they believe about the united states that made them up for eight hours , stood under the sun in washington in august of august .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jauhkan anak-anak dari toko seperti ini.\n",
            "Target: keep kids out of stores that look like this.\n",
            "Predicted: the kids are from the shops like this .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pada saat itu, james somerset mengalami peralihan hukum.\n",
            "Target: at that moment, james somerset underwent a legal transubstantiation.\n",
            "Predicted: at that moment , james somerset had a legal transition .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: perdagangan yang kuat berlanjut di laut, terutama untuk porselen biru dan putih, yang menggabungkan tembikar putih mongol tiongkok dan pewarna biru mongol iran.\n",
            "Target: robust trade continued at sea, especially in blue-and-white porcelain, which combined white pottery from mongol china with blue dye from mongol iran.\n",
            "Predicted: strong trade that continued in seawater , especially for the blue and white , which joined the of china and the mongols ’ s white cloud and blue caribbean waters .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: golf membantu orang menjalin pertalian.\n",
            "Target: golf helps people bond.\n",
            "Predicted: golf helps people make up web - based services .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi kami tetap harus mencari cara membantunya mengatasi emosi besar ini sambil mengajarinya kemampuan dasar seperti membaca dan matematika.\n",
            "Target: but yet we had to figure out a way to help him with these big emotions all while teaching him core skills of reading and math.\n",
            "Predicted: but we still have to find a way to help her overcome these big emotion - like - making emotions as well as reading and math .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ah tentu saja, silahkan.\n",
            "Target: ah sure, please.\n",
            "Predicted: ah , of course , please .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: para wanita tidak akan membagi teknologi ini dengan para pria.\n",
            "Target: this technology, the women will not share with the men.\n",
            "Predicted: women are not going to share this technology with men .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: adikmu punya bayi. bagaimana denganmu?\"\n",
            "Target: what about you?\"\n",
            "Predicted: your sister has a baby . what do you have got a baby ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ahli saraf membongkar ide ini di artikel.\n",
            "Target: the neuroscientist was debunking this idea in the article.\n",
            "Predicted: neuroscientists take this idea on an article .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dia menjadi seorang solois, dia memiliki karir yang mengagumkan\n",
            "Target: she was eventually auditioned for the royal ballet school.\n",
            "Predicted: he became a , he had a wonderful career .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda mungkin pernah mendengar tentang gambaran al-quran tentang surga adalah 72 perawan. saya berjanji akan kembali ke soal perawan tersebut.\n",
            "Target: you may have heard about the koran's idea of paradise being 72 virgins, and i promise i will come back to those virgins.\n",
            "Predicted: you may have heard about the koran from the koran on 72 virgins , and i promise would return to the one of the virgin .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini mereka sedang berburu monyet, dengan anak panah berujung racun curare.\n",
            "Target: this was on a monkey hunt, hunting with curare-tipped darts.\n",
            "Predicted: this is they are hunting , monkeys with a poison of .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: namun hal ini dapat dilakukan dengan cepat.\n",
            "Target: but if you do this, it is quick.\n",
            "Predicted: but this can be done quickly .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bagaimana kami dapat mengambil ide menipu indra pengecap anda dan melompat menjadi sesuatu yang dapat kita lakukan sehingga dapat mengganggu teknologi makanan?\n",
            "Target: how can we take this idea of tricking your tastebuds and leapfrog it into something that we can do today that could be a disruptive food technology?\n",
            "Predicted: how can we take the idea of the taste of the and jump into something that we can do so that can disrupt food technology ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita suka inovasi.\n",
            "Target: we love innovation.\n",
            "Predicted: we like innovation .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sampai tahun lalu, saya tidak pernah memelihara lebah sebelumnya, tapi national geographic meminta saya untuk memotret sebuah cerita tentangnya, dan saya memutuskan, untuk dapat mengambil gambar-gambar yang menarik, saya harus mulai memelihara lebah-lebah sendiri.\n",
            "Target: until last year, i would never kept bees before, but national geographic asked me to photograph a story about them, and i decided, to be able to take compelling images, i should start keeping bees myself.\n",
            "Predicted: until last year , i never adopted the bees before , but national geographic asked me to take a story , and i decided to take a picture , and i decided to take the interesting images , i started to keep the bees back .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: walaupun perubahannya radikal, tapi dibangun oleh momentum kultural.\n",
            "Target: it was a radical transformation, but it was built by a cultural momentum.\n",
            "Predicted: despite the radical changes , but it was built by the cultural momentum .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi, anda melihat filmnya transparan di sana, lalu ...\n",
            "Target: so as you see the film go in transparently through there, and then ...\n",
            "Predicted: so , you see a transparent piece of film there , and then ...\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda mempertaruhkan nyawa untuk itu.\n",
            "Target: you risk your life if you do.\n",
            "Predicted: you risk your life for that .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi mari kita mulai. nomor 10. kita kehilangan keinginan untuk bertahan hidup.\n",
            "Target: so let us start. number 10 we lose the will to survive.\n",
            "Predicted: so let us start . number 10 . we lose the desire to survive .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan menarik, saat saya mengajar tentang sejarah afrika-amerika. saya menceritakan perbudakan.\n",
            "Target: and it is interesting, when i teach my students about african-american history, i tell them about slavery.\n",
            "Predicted: and it was interesting , when i teach the history of africa , i was telling slavery .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi menurut saya alat ini kuat, untuk mengubah hubungan kita dengan alam dan pada spesies lain yang kita butuhkan.\n",
            "Target: it is very powerful for, i think, changing our relationship to the natural world and to the other species on whom we depend.\n",
            "Predicted: but i think it is strong , to change our relationship with nature and in other species that we need .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sangat mengharukan ketika melihat balkon dari kayu plywood dengan pegangan di sekitarnya, di mana para keluarga korban meninggalkan pesan.\n",
            "Target: it was devastating to see the simple plywood platform with a rail around it, where the families of the victims had left notes to them.\n",
            "Predicted: the most deeply rooted in the balcony includes restricted wood with mercury around , where families provide victims , where families leave the message .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu saya kembali ke sekolah yang sama di mana saya terbang untuk pertama kalinya dan mengajarkan orang lain untuk terbang,\n",
            "Target: and then i found myself back at that same school where i would gone for that very first flight, teaching other people how to fly ...\n",
            "Predicted: and then i went back to the same school where i flew for the first time and teach others to fly .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: buat 10 variasi lagi dari yang sebuah itu.\n",
            "Target: you create 10 variations on that one.\n",
            "Predicted: make 10 variations more than that one .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: siapa yang tidak dapat tersentuh oleh belas kasih, saat kita melihat hal-hal mengerikan yang diakibatkan perang, atau bencana kelaparan, gempa, dan tsunami?\n",
            "Target: who cannot be touched by compassion when we see the terrible horrors of the results of war, or famine, or earthquakes, or tsunamis?\n",
            "Predicted: who does not move by compassion , when we see terrible things that have been the war that inflict , or a disaster of famine , earthquake and tsunami ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: seks tanpa kondom dan jarum suntik bekas menjadi sebab utama penularan.\n",
            "Target: unprotected sex and contaminated needles are the leading because of transmission.\n",
            "Predicted: sex is not a condom and used into the main substance of transmission .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: melalui jaringan mikoriza, jamur dapat menyalurkan makanan dan memberi isyarat pada molekul antar pohon.\n",
            "Target: through mycorrhizal networks, fungi can pass resources and signaling molecules between trees.\n",
            "Predicted: through the melting of the nodes , fungi can deliver food and give the sign of the tree of trees .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita secara langsung merancang species masa depan dari planet ini.\n",
            "Target: we are directly designing the future of the species of this planet.\n",
            "Predicted: we are directly designing the future of the planet .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sesederhana itu.\n",
            "Target: simple as that.\n",
            "Predicted: that is simple .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan merupakan hal yang sangat mengesankan yang pernah kami alami.\n",
            "Target: but it was still the most exciting thing that has ever happened to me and my sisters.\n",
            "Predicted: and it is a very impressive thing that we have ever experienced .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ketika saya berdiri di teras depan dan merogoh saku celana saya, saya tersadar saya tidak membawa kunci rumah.\n",
            "Target: and as i stood on the front porch fumbling in my pockets, i found i did not have my keys.\n",
            "Predicted: when i stood on the terrace and searching my pants , i realized i did not take the keys .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: berikan terang pada penyiksaan itu dengan membicarakannya dengan anak-anak, rekan kerja, sahabat, dan keluarga anda.\n",
            "Target: show abuse the light of day by talking about it with your children, your coworkers, your friends and family.\n",
            "Predicted: give it light on that diagnosis of it with their children , colleagues , friends and family .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: semua teknologi modern ini mengeluarkan sinyal yang kuat yang bisa menelan cahaya sangat redup yang kami coba deteksi dari alam semesta di luar bumi, yang sesungguhnya mencakup sebagian besar dari alam semesta.\n",
            "Target: all of this modern technology is putting out strong signals that can completely swamp this exceedingly faint light we are trying to detect from the rest of the universe outside earth, which just for the record, is most of the universe.\n",
            "Predicted: all of these modern technologies release a strong signal that could swallow the very , very , very , very , essentially , from the universe outside of the earth , which permeates most of the universe .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya tinggal di new orleans, dan saya suka dengan kota ini.\n",
            "Target: now, i live in new orleans, and i am in love with new orleans.\n",
            "Predicted: i was living in new orleans , and i love with this city .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tragisnya pada 2019 petani kelaparan, padahal mereka yang memberi kita makan.\n",
            "Target: it is crazy that in 2019 farmers that feed us are hungry.\n",
            "Predicted: tragically in 2019 , while they gave us a meal .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dia membuat banyak referensi budaya yang menarik.\n",
            "Target: he made a lot of really interesting cultural references.\n",
            "Predicted: he made a lot of interesting culture references .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: narator ketika para pemburu memamerkan tangkapan mereka, sesuatu yang mengejutkan terjadi.\n",
            "Target: narrator as the hunters display their kills, something surprising happens.\n",
            "Predicted: narrator when the elders hunter , showing them the appearance , something striking was a surprising thing .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan tak seorang pun dapat mengatakan tidak.\n",
            "Target: and nobody can tell me no.\n",
            "Predicted: and nobody could say no .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan ada lebih dari 200 format, tersebar di 50 kota di india.\n",
            "Target: and there are more than 200 formats, across 50 cities and towns of india.\n",
            "Predicted: and there are over 200 camps , spread in 50 cities in india .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka tidak bisa mengatakan volume komunikasi yang mereka disadap di seluruh dunia, karena mengetahuinya berarti melanggar privasi anda.\n",
            "Target: we cannot tell you how many communications we are intercepting around the world, because to tell you that would be to invade your privacy.\n",
            "Predicted: they cannot say that they cannot say the volume of communication that they are being intercepted around the world , because they know that they are breaking your privacy .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dengan kata lain, itu adalah makhluk hidup pertama dalam sejarah yang memiliki orang tua sebuah komputer tidak ada orang tua yang hidup.\n",
            "Target: in other words, that was the first creature in the history of the world that had a computer as its parent it did not have an organic parent.\n",
            "Predicted: in other words , that is the first living organism in the history of a computer that has an old computer no parents .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tiba-tiba, saya menjadi yatim piatu dan tuna wisma.\n",
            "Target: suddenly, i became an orphan and homeless.\n",
            "Predicted: suddenly , i was an orphan and homeless .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan sekarang saya melihat setiap pendukung partai republik seperti trump.\"\n",
            "Target: and now every republican, i can paint with all the things that i think about trump.\"\n",
            "Predicted: and now i am looking at every single party of trump like .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: di asia selatan, jika anda memperbudak seorang yang miskin, anda lebih beresiko tersambar petir daripada di penjara atas kejahatan itu.\n",
            "Target: in south asia, if you enslave a poor person, you are at greater risk of being struck by lightning than ever being sent to jail for that crime.\n",
            "Predicted: in south asia , if you flip between a poor , you are more risky to take a bedtime note for that crime .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi rasanya tidak enak, saya butuh bantuan dalam hal itu.\n",
            "Target: it does not taste good, so i am going to need some help with that.\n",
            "Predicted: but it is not so good , i need help with that .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: di as, rata-rata orang amerika menggunakan tiga persen pendapatannya pada listrik.\n",
            "Target: in the us, the average american spends three percent of their income on energy.\n",
            "Predicted: in the us , the average american average , uses three percent income on electricity .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: untuk menghancurkan penghalang-penghalan yang ada, kita harus belajar untuk berbicara dengan orang lain, meminta orang-orang yang bekerja dalam bidang penerjemahan.\n",
            "Target: in order to break down our barriers, we have to learn to talk to people, to demand that people work on translation.\n",
            "Predicted: to destroy the constraints we have to learn to talk to other people , asking people who work in translation in translation .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: begitulah stetoskop dan auskultasi ditemukan.\n",
            "Target: and that is how stethoscope and auscultation was born.\n",
            "Predicted: that is the stethoscope and the arrival of .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: otak anda tidak tahu. karena keduanya memiliki kemungkinan yang sama.\n",
            "Target: your brain does not know, because both are equally likely.\n",
            "Predicted: your brain does not know . because they have the same possibility .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: apa yang saya maksud?\n",
            "Target: what do i mean by that?\n",
            "Predicted: what do i mean ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka sudah memberi semua insentif yang tepat. semua insentif yang tepat. mereka membayar para profesional untuk menulis dan mengedit ribuan artikel.\n",
            "Target: they had deployed all the right incentives, they paid professionals to write and edit thousands of articles.\n",
            "Predicted: they have given all the right incentives , all the right incentive to pay professional professionals to write and edit thousands of articles .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi apa yang kita lakukan dalam hal itu?\n",
            "Target: so, what do we do about that?\n",
            "Predicted: so what do we do in that ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: semua itu membutuhkan dua hari dari 7 hari dalam seminggu.\n",
            "Target: the whole thing took two days out of the seven-day week.\n",
            "Predicted: it took two days from seven days a week .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sekarang saatnya kamu masuk ke dalam air.\"\n",
            "Target: it is time for you to get in the water.\"\n",
            "Predicted: now it is time you go into the water .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi yang anda lakukan adalah salah satu orang itu tidak menguasai bahasa.\n",
            "Target: so what you do is one of those people has not really acquired language yet.\n",
            "Predicted: so what you do is one of those people do not have the language .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: namun pesannya sangat jelas.\n",
            "Target: but the message was very clear.\n",
            "Predicted: but the message was very clear .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: christopher columbus meyakinkan raja spanyol mengirimnya ke sebuah misi demi menemukan rute yang lebih baik ke india tidak melalui daratan ke arah timur tapi berlayar ke barat memutari dunia\n",
            "Target: christopher columbus convinced the king of spain to send him on a mission to find a better trade route to india, not by going east over land but sailing west around the globe.\n",
            "Predicted: christopher columbus convinced the spanish emperor sent him to discover a better route to india did not through the land but around the west across the world .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ada alasan lain mengapa saya suka tujuan pembangunan ini, dan itu karena tiap-tiap tujuannya terukur.\n",
            "Target: there is a second reason i like these development goals, and that is because each and every one is measured.\n",
            "Predicted: there is another reason why i love this goal , and that is because every single purpose of its understanding .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pada suatu saat ada sebuah bakteri kecil yang hidup bahagia.\n",
            "Target: once upon a time, there is this happy little bacterium.\n",
            "Predicted: at one point there is a happy bacterial life .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ada satu juta orang per tahun yang meninggalkan amerika latin ke amerika serikat.\n",
            "Target: there is a million a year who leave latin america to go to the united states.\n",
            "Predicted: there is one million people per year left latin america to the united states .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: empat adalah biru.\n",
            "Target: four is blue.\n",
            "Predicted: four are blue .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ca apakah berlebihan, aku tak tahu, apa kita punya mik tangan?\n",
            "Target: ca would it be too much, i do not know, do we have a handheld mic?\n",
            "Predicted: ca so , i do not know , do we have a microphone microphone ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda diperbolehkan untuk membenci mereka dengan setiap bagian dari diri anda.\n",
            "Target: you are allowed to just hate them with every fiber of your being.\n",
            "Predicted: you are allowed to hate them to every part of your self .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: beberapa hal yang harus diingat saat melihatnya, gedung ini dibangun dengan tangan, saya rasa mereka mendatangkan derek tahun lalu.\n",
            "Target: a couple of things to keep in mind when you see it, it was built entirely by hand, i think they got a crane the last year.\n",
            "Predicted: some of the things that i have to remember seeing , this building blocks , this building was built by hand , i think they came up with me from one year ago .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: terdengar seperti perjalan melewati alam liar menuju tanah yang dijanjikan, dengan kepemimpinan dipegang oleh para pemimpin.\n",
            "Target: sounds very much like the journey through the wilderness to the promised land, with the commandments held by the leader.\n",
            "Predicted: sounds like through the wild to promised soil , promised to the leadership by leadership .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: inilah gambar dari jembatan golden gate di san francicco, yang tidak jauh dari tempat tinggal saya.\n",
            "Target: here is an image of the golden gate bridge in san francisco, not far from where i live.\n",
            "Predicted: this is a picture of the golden gate bridge in san diego , which is not far from my place .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tidak seperti para khan, temujin mengangkat prajurit berdasarkan prestasi dan membagikan hadiah secara adil.\n",
            "Target: unlike those khans, temujin promoted soldiers based on merit and distributed spoils evenly among them.\n",
            "Predicted: unlike khan ’ s , the deceiver can raise the reward based on the achievement , sharing a fair reward .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: george bernard shaw mengatakannya lain,\n",
            "Target: george bernard shaw said it differently.\n",
            "Predicted: george accused of oliver call it another ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya ingat sekali gerakan iklim september lalu, yang mana adalah momentum yang besar, tidak hanya di new york, namun di seluruh dunia.\n",
            "Target: i recall very much the climate march last september, and that was a huge momentum, not just in new york, but all around the world.\n",
            "Predicted: i remember that in september last year , which is a huge momentum real momentum , not only in new york , but around the world .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: rerumputan ini mengeluarkan zat penghambat pertumbuhan dari akarnya\n",
            "Target: it exudes -like compounds from the roots.\n",
            "Predicted: it is taking a fixed disorder of the roots .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan semua kolam itu terlalu sulit untuk dikarakterisasikan, bahkan dengan metode modern, dan produk yang berwarna coklat, seperti tar ini di sebelah kiri. sebuah senyawa murni ditunjukan di kanan, sebagai perbandingan.\n",
            "Target: and it is a pool that is too difficult to fully characterize, even by modern methods, and the product looks brown, like this tar here on the left. a pure compound is shown on the right, for contrast.\n",
            "Predicted: and all of those pool are too difficult to , even in modern methods , and the product of brown , like this in the left , a pure compounds , indicating that be shown in the right side , as a comparison .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan ke empat adalah kebanyakan orang menyepelekan risiko pada situasi dimana mereka punya kendali dan membesar-besarkan risiko pada situasi dimana mereka tidak berwewenang.\n",
            "Target: and the fourth is people underestimate risks in situations they do control and overestimate them in situations they do not control.\n",
            "Predicted: and the four is most people the risk of risk in the situation where they have control and keep increasing their risk of being broken in the situation where they do not count .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: aku akan keluar untuk mempertahankan kebebasanmu, hidupmu.\n",
            "Target: i am going out to defend your freedom, your lives.\n",
            "Predicted: i am going to go out to keep your , my life .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: baiklah, jadi mari kita ambil empat hal yang sudah jelas berhubungan data besar, tato, keabadian, dan yunani.\n",
            "Target: all right, so let us take four subjects that obviously go together big data, tattoos, immortality and the greeks.\n",
            "Predicted: okay , so let us take four things obviously have a big data related data , immortality , whole and greece .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan kami tahu model kami bekerja.\n",
            "Target: and we know that our model works.\n",
            "Predicted: and we know our model works .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: \"seorang perempuan harus dilihat, bukan didengar.\"\n",
            "Target: shah rukh khan \"a girl should be seen, not heard.\"\n",
            "Predicted: \" a woman has to be seen , not heard .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ok. ini akan jadi sedikit masalah.\n",
            "Target: ok.\n",
            "Predicted: ok . this is a little problem .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bagus sekali. apakah itu? kamu bisa mengulanginya? tunjukan lagi kepada saya seperti apa?\"' dan dia melakukan itu selama dua bulan.\n",
            "Target: what is that? can you do that again? can you show me some more?'\" she did that for two months.\n",
            "Predicted: do that really cool . do you get it over ? show me again , show me what is like and he did it for two months .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: terima kasih.\n",
            "Target: thank you.\n",
            "Predicted: thank you .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mulai. jh pertanyaan saya untuk anda, siapa yang berkuasa di ruang kelas itu?\n",
            "Target: jh my question to you is, who is in charge of that classroom?\n",
            "Predicted: start . jh my question for you , who are in charge of that classroom in the classroom ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: berakhirnya eksekusi publik di peradilan eropa dan amerika sebagian muncul untuk memberi perlakuan yang lebih manusiawi terhadap kriminal, tapi sebagian juga karena massa enggan berperilaku seperti yang seharusnya.\n",
            "Target: the end of torturous public judicial executions in europe and america was partly to do with being more humane towards the criminal, but it was also partly because the crowd obstinately refused to behave in the way that they should.\n",
            "Predicted: the end of the public judicial execution in europe and america has emerged for more human treatment , but some of the time are equally , but also because the mass of the behaviors should be .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dengan kata lain, pikiran di daerah miskin bukanlah pikiran yang miskin\n",
            "Target: in other words, the minds on the margin are not the marginal minds.\n",
            "Predicted: in other words , the mind in the poor areas are not poor minds .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan itulah di mana semua gaya menjadi satu, sebab gravitasi akhirnya cukup kuat bersaing dengan gaya yang lain.\n",
            "Target: and that is where all the forces become unified, because gravity finally is strong enough to compete with all the other forces.\n",
            "Predicted: and that is where all the forces become one , because gravity finally is strong enough to compete with other forces .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda tidak perlu mengambil kesempatan itu untuk membuktikan betapa hebatnya anda atau betapa menderitanya anda.\n",
            "Target: you do not need to take that moment to prove how amazing you are or how much you have suffered.\n",
            "Predicted: you do not need to take that opportunity to prove how great you or how much your is .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita adalah penonton dan komposer dan kita mengambil sepotong-sepotong dari yang kita dapat.\n",
            "Target: we are the audience and we are the composers and we take from these pieces we are given.\n",
            "Predicted: we are the audience and sharing it and compassion and it takes a piece of a piece of stuff that we can .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita punya negara-negara dengan pendapatan tinggi di sini, dengan amerika serikat sebagai pemimpinnya. kita punya negara-negara yang berkembang pesat di tengah, yang menyediakan banyak dana untuk bailout. dan kita juga punya negara-negara dengan pendapatan rendah di sini,\n",
            "Target: we have the high income countries here, with the united states as a leading power we have the emerging economies in the middle, which provide a lot of the funding for the bailout and we have the low income countries here.\n",
            "Predicted: we have countries with high income here , with the united states as the leader of our citizens , we have a high - developed world in the middle , which provide a lot of funding to avoid the countries , and we have low income here .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini diceritakan oleh seorang kwakuitl indian dari alaska selatan ke seorang misionaris tahun 1896, dan inilah puisinya.\n",
            "Target: it was told by an anonymous kwakiutl indian of southern alaska to a missionary in 1896.\n",
            "Predicted: this is told by a indian indian from alaska to a year of ernest ., declan , and this was the poem .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bonobo, bersama dengan simpanse, adalah saudara terdekat anda yang masih ada.\n",
            "Target: bonobos are, together with chimpanzees, your living closest relative.\n",
            "Predicted: bonobo , with chimpanzees , are your closest relatives who is still a nearby sister .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: itu seperti seperti tenaga surya, angin lokal atau perpaduannya dan hal-hal baik yang sejenisnya.\n",
            "Target: it is supposed to be, i do not know, local solar and wind and cogeneration, and good things like that.\n",
            "Predicted: it is like solar , local wind or and things that are okay .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tetapi di negara ini, dimana pemerintah ternyata tidak merasa terdorong untuk memberikan layanan kesehatan umum kepada para warganya, kita memilih pendekatan yang sangat berbeda.\n",
            "Target: but in this country, where the government apparently does not feel compelled to provide health care for citizens, we have taken a very different approach.\n",
            "Predicted: but in this country , where the government was actually meant to be driven to the public health care to the citizens , we chose a very different approach .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: intinya adalah, dengan membuat pilihan kita sendiri, kami mampu mengembangkan ketahanan dalam menghadapi masalah pembangunan.\n",
            "Target: the point is that, by making our own choices, we were able to develop resilience in dealing with development problems.\n",
            "Predicted: the point is , by making our own choices , we can be able to develop resilience into the problem of development .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bagi mereka, tidak penting apakah saya kaya atau miskin, warna kulit saya, apakah saya laki-laki atau perempuan, orientasi seksual saya, tendensi politik saya, apakah saya berpendidikan, apakah saya beragama atau tidak.\n",
            "Target: to them, it did not matter if i was rich or poor, the color of my skin, whether i was male or female, my sexual orientation, who i voted for, whether i was educated, if i had a faith or no faith at all.\n",
            "Predicted: for them , it is not important whether i am rich or poor , my skin color , whether i am a male or a woman , my sexual orientation was my political agency , whether i am a religious or not alive .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya tidak menikmatinya. apa saya punya depresi pasca melahirkan?\"\n",
            "Target: do i have postpartum depression?\"\n",
            "Predicted: i do not enjoy . what do i have post a post - birth depression ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anak-anak satu, dua, tiga, mulai.\n",
            "Target: children one, two, three, go.\n",
            "Predicted: the kids , two , three , started .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka menempatkan keluarga di tempat pertama, merawat anak-anak dan orang tua mereka.\n",
            "Target: they put their families first, take care of their children and their aging parents.\n",
            "Predicted: they put their families in the first place , care for their children and parents .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ayah membuat perhitungan sederhana dalam satu jam ayah bisa membuat 30 dokumen palsu.\n",
            "Target: he had made a simple calculation in one hour he could make 30 forged documents.\n",
            "Predicted: he made simple calculations in one hour , he can make 30 fake documents .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kami melakukan ini secara pasif, melihat apakah mereka pergi ke pelayanan kesehatan universitas.\n",
            "Target: and we did this passively by looking at whether or not they would gone to university health services.\n",
            "Predicted: we did this passive , see if they went to college - university health service .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan jadi, di sini kita memiliki apa yang disebut dengan \"paradigma\"\n",
            "Target: i have here what we call the paradigms.\n",
            "Predicted: and so , here we have what is called \" the paradigm of history .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bg dambisa, terimakasih hadir di ted.\n",
            "Target: bg dambisa, thank you for coming to ted. dm thank you very much.\n",
            "Predicted: bg wendy , thank you for ted .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi, secara ilmiah, ini merupakan suatu peningkatan.\n",
            "Target: so scientifically speaking, this is an improvement.\n",
            "Predicted: so , in scientific , it is a increase .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: aku berusaha bertahan, agar tidak mengangkat kepala dan melolong.\n",
            "Target: it took all of my strength not to raise my head and howl.\n",
            "Predicted: i tried to survive , so i did not raise the head and the pungent .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ketika anda menolong satu orang menjadi lebih aman, suatu bangsa menjadi lebih aman.\n",
            "Target: when you help just one person to be more secure, a nation is more secure.\n",
            "Predicted: when you help one person becomes safer , a nation of state becomes safer .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: db terima kasih. bagus. silakan duduk.\n",
            "Target: db thank you so much. great. good one! take a seat. take a seat.\n",
            "Predicted: db thank you . good .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jika anda menyaksikan kebangkitan fasis kanan di seluruh eropa akhir-akhir ini, anda akan menyaksikan beberapa kejadian yang mempengaruhi politik dalam negeri, namun fenomenanya transnasional.\n",
            "Target: if you look at the rise of far-right fascism across europe of late, you will see some things that are happening that are influencing domestic politics, yet the phenomenon is transnational.\n",
            "Predicted: if you see the rise of the right - of - europe throughout the end of these days , you will see some of the people that influence the country , but the of youth .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan di mana kamu berharap ukuran raksasa kanvas dapat melawan perasaan tersebut, skala kanvas justru menyorot kekejaman berukuran hampir sebesar manusia.\n",
            "Target: and where you might expect the canvas’ massive size to counteract this feeling, its scale only highlights the nearly life-sized atrocities on display.\n",
            "Predicted: and where you expect the giant sized size to counter the feeling , the scale is to highlight a canvas ’ s heavy loads almost as much as humans .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mari kita ajarkan matematika. itu akan membuatnya tenang.\"\n",
            "Target: we will teach her mathematics. that will calm her down.\"\n",
            "Predicted: let us teach math math . that will make it quiet .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya juga risau dengan plastik yang ada di dalam lemari es dan saya risau dengan plastik dan racun dari plastik yang larut dan masuk ke dalam badan kita.\n",
            "Target: i am also concerned about the plastic in the refrigerator, and i am concerned about the plastic and the toxins that leach from plastic into us and into our bodies.\n",
            "Predicted: i am also worrying about plastic in the of the refrigerator and i have some of the plastic and some of the plastic and the toxins from the manure out into our body .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: meski ini hanyalah sebuah kisah kecil, kami harap mampu merepresentasikan sebuah langkah dalam arah pendidikan bagi masa depan masyarakat pedesaan dan bagi masa depan pendidikan masyarakat dan tentunya juga bagi masa depan desain itu sendiri.\n",
            "Target: so while this is a very small story, we hope that it represents a step in the right direction for the future of rural communities and for the future of public education and hopefully also for the future of design.\n",
            "Predicted: although this is just a small story , we hope to represent a step in a direction of education for rural communities and for future community education and of course , for example , is also for the design of the design of the design of self .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sekarang kami punya nitrogen cair.\n",
            "Target: now we have our own liquid nitrogen.\n",
            "Predicted: now we have liquid nitrogen .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan kami bekerja sama dengan pemerintah, jadi tidak akan ada duplikasi sistem penyediaan.\n",
            "Target: and we work in partnership with the government, so there is no creation of a parallel delivery system.\n",
            "Predicted: and we worked with the government , so there was no systems on the runway .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bagi saya, ironi tentang kisah facit adalah saat mendengar tentang para ahli facit, yang telah membeli kalkulator elektronik kecil dan murah di jepang yang mereka gunakan untuk menguji kalkulator mereka.\n",
            "Target: to me, the irony about the facit story is hearing about the facit engineers, who had bought cheap, small electronic calculators in japan that they used to double-check their calculators.\n",
            "Predicted: for me , the irony of the hoodie in the early days were hearing about the experts and as they bought small electric and generous calculators in japan who they use to test their calculators .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan pesannya menurutku sangat jelas.\n",
            "Target: and i think the message of this is very clear.\n",
            "Predicted: and the message i thought was very clear .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: menulis adalah profesi saya, tapi tentunya juga lebih dari itu.\n",
            "Target: writing books is my profession but it is more than that, of course.\n",
            "Predicted: writing is my profession , but of course , it is more than that .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita tahu dari pengalaman, kita bisa berada di, apa yang kita sebut, \"surga dunia\" dan tetap, sangat tidak bahagia di dalam.\n",
            "Target: we know, by experience, that we can be what we call \"a little paradise,\" and yet, be completely unhappy within.\n",
            "Predicted: we know from experience , we can be in , what we call , \" paradise and heaven \" and yes , are really happy in the world .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan seringkali janin itu melakukan lebih\n",
            "Target: and often it does something more.\n",
            "Predicted: and often , they often do more .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan inilah jawaban dari mahasiswa di swedia.\n",
            "Target: and these were the results of the swedish students.\n",
            "Predicted: and this is the answer of sweden in sweden .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: beberapa dari mereka adalah jamur yang sangat bahagia.\n",
            "Target: some of these mushrooms are very happy mushrooms.\n",
            "Predicted: some of them are a very happy mushroom that is very happy .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: apa bedanya?\"\n",
            "Target: what is different about them?\"\n",
            "Predicted: what is different ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dia mengirim bunga ke pesta-pesta pernikahan, membuat taman di rumah-rumah dan membuka bisnis di kota, dan sekarang dia sedang membuat taman rakyat di kota yang pertama di mogadishu dalam 22 tahun.\n",
            "Target: and he began delivering flowers to weddings, creating gardens at homes and businesses around the city, and he is now working on creating mogadishu's first public park in 22 years.\n",
            "Predicted: he sent flowers to the wedding party , built the garden in the house and opens business in the city , and now he is building the citizens in the first year in mogadishu .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pertama, ingat setiap anak yang telah saya sebut.\n",
            "Target: first of all, think of the children i mentioned.\n",
            "Predicted: first , remember every child i have called .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya berbicara dengan banyak orang, dengan teman saya, dengan keluarga saya.\n",
            "Target: i spoke to many people, i spoke to my friends, i spoke to my family.\n",
            "Predicted: i am talking to a lot of people , with my friends , with my family .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: selama bertahun-tahun, banyak buku, dia tidak pernah lelah untuk itu.\n",
            "Target: all those years, all those books, he never got tired of it.\n",
            "Predicted: for years , many books , he never been tired of that .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jangan gunakan alamat email anda,\n",
            "Target: do not use your own email address.\n",
            "Predicted: do not use your email address .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya menjadi cukup dikenal.\n",
            "Target: i have become myself known.\n",
            "Predicted: i became quite known .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: penjahat-penjahat kecil itu jelas lebih baik daripada tidak ada sama sekali namun sulit membayangkan bagaimana penjahat kecil mampu bertahan dengan kinerja seperti itu pada periode waktu tertentu.\n",
            "Target: so canny outlaws are better than nothing, but it is hard to imagine any canny outlaw sustaining that for an indefinite period of time.\n",
            "Predicted: the small criminals are clearly better than nothing at all , but it is hard to imagine how small the performance of the performance of time .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tentu saja nyawa yang diselamatkan meningkat, konsepnya berhasil.\n",
            "Target: and obviously the life-saving is increased, the concepts help.\n",
            "Predicted: of course , life expectancy was increased , the concept , succeeded .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan dalam kelas itu, kami membahas tentang beberapa fakta pertama, pengakuan itu mungkin tidak dapat dipercaya, tapi yang kedua, kami tidak ingin mendorong para polisi untuk terus melakukan ini, terutama karena ini sekarang melanggar hukum.\n",
            "Target: and we talked about, as a class, the fact that number one, the confessions might not be reliable, but number two, we did not want to encourage the police to keep doing this, especially as it was now against the law.\n",
            "Predicted: and in that classroom , we talked about some of the first facts , the recognition may not be trusted , but the second one , we do not want to push the police to keep these police , especially because this laws are breaking the laws .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: semua desa membutuhkan dewan desa.\n",
            "Target: all villages need village councils.\n",
            "Predicted: all the villages need to the village council .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: akhirnya, saya mulai melestarikan cerita melalui alat sketsa gambar dari tembaga dan mesin cetak gambar.\n",
            "Target: but ultimately, i set out to preserve the story through these copper-plate etchings and letterpress descriptions.\n",
            "Predicted: eventually , i began to preserve the story through the photos of copper devices and the printing engine of images .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dia menyadari bahwa mungkin dia lebih punya banyak kesamaan dengan dia daripada orang-orang yang sepenuhnya korea atau jerman.\n",
            "Target: she realizes that she probably has much more in common with him than with anybody entirely of korea or entirely of germany.\n",
            "Predicted: he realized that he was more likely to have a lot of common with him than he was completely north korean or germany .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: katanya, para pegawai senior pada awalnya gusar, dan mereka akan mendatanginya dan berkata, \"apa anda mau saya mempekerjakan kelompok minoritas, atau orang terbaik untuk posisi itu?\"\n",
            "Target: now he says the senior people in the beginning bristled, and they would come to him and say, \"do you want me to hire the minority, or do you want me to hire the best person for the job?\"\n",
            "Predicted: he said , the senior employees at the start , and they will come up to them and say , \" what do you want to employ minority group , or the best people to do ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: misalnya, kamu bisa merubah satu menjadi football, atau yang lainnya menjadi matahari. saya hanya tertarik pada kuantitas.\n",
            "Target: so for example, you could turn one into a football, or another one into a sun. all i am interested in is quantity.\n",
            "Predicted: for example , you can change one in a football game , or others become the sun . i am just interested in quantity .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pemandangannya sungguh luar biasa.\n",
            "Target: the landscape is incredible.\n",
            "Predicted: what it is good , it is amazing .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: situasi saat ini penuh dengan kesulitan, dan kita haruslah naik bersama-sama dengan situasi ini.\"\n",
            "Target: the occasion is piled high with difficulty, and we must rise with the occasion.\"\n",
            "Predicted: the situation is full of adversity , and we have to go together with these situations .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: salah satu sepupumu adalah ezra cornell, pendiri universitas cornell.\n",
            "Target: one of your cousins is ezra cornell, founder of cornell university.\n",
            "Predicted: one of the sisters was 260 , d . m . d . at a decade .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: penyakitnya orang-orang kaya.\n",
            "Target: and rich men are afflicted.\n",
            "Predicted: the disease is rich .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan kecepatan angin rata-rata 40 knot pada sebagian besar pelayaran terkadang mencapai 70 atau 80 knot.\n",
            "Target: and winds averaging about 40 knots for most of the voyage and up to 70 or 80 knots.\n",
            "Predicted: and the average wind of these three pairs of cyclists in most shipping is sometimes going to get 70 or 80 of these guys .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ia merasa frustrasi dan menarik diri serta bertingkah di kelas.\n",
            "Target: she was growing frustrated and kind of withdrawn and acting out in class.\n",
            "Predicted: he felt frustrated and exciting and pulling myself around the classroom .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi saya belajar darinya.\n",
            "Target: but i borrow a lesson that i learned from him.\n",
            "Predicted: but i learned from it .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tapi berita baiknya adalah, karena penderitaan ini adalah buatan, kita bisa mengubahnya.\n",
            "Target: but the good news is, since this brand of suffering is made up, well, we can change it.\n",
            "Predicted: but the good news is , because the suffering is artificial , we can change it .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: sistem ini akan dapat memastikan bahwa para siswa kita mendapat pendidikan yang bagus, menemukan pekerjaan yang memuaskan dan bermanfaat dan mendapat kesempatan untuk mewujudkan mimpi mereka.\n",
            "Target: it would put us on a path to making sure all our students get a great education, find a career that is fulfilling and rewarding, and have a chance to live out their dreams.\n",
            "Predicted: this system will be able to ensure that our students get good education , finding a happy job and benefits to get the chance and get the opportunity to realize their dreams .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah poster perjalanan \"kepler-186f di mana rumput tetangga terlihat lebih merah.\"\n",
            "Target: here is a travel poster \"kepler-186f where the grass is always redder on the other side.\"\n",
            "Predicted: this is a poster trip , kepler - mat where the neighbors look like red .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: nilai yang didapat portia akan berkisar antara 4 karena semua orang sepakat bahwa dia sangat cantik, sedangkan sarah jessica parker menuai opini yang berbeda.\n",
            "Target: so portia's scores would all be clustered around the four because everybody agrees that she is very beautiful, whereas sarah jessica parker completely divides opinion.\n",
            "Predicted: the value of transgression are focused on between four four because everyone agreed that he is very beautiful , whereas sarah jessica cole are greeted with a different opinion .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya yakin lagu kebangsaan swedia diputar dan dinyanyikan lebih lama.\n",
            "Target: i believe swedes play theirs and sing theirs for a little longer.\n",
            "Predicted: i am sure the national swedish songs are played more than a long time .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: untungnya, saya menemukan paten di internet untuk tungku industri yang menggunakan microwave. dan dengan menggunakan tenaga penuh selama 30 menit, saya dapat menyelesaikan proses ini.\n",
            "Target: but luckily, i found a patent online for industrial furnaces that use microwaves, and at 30 minutes at full power, and i was able to finish off the process.\n",
            "Predicted: fortunately , i found patent in the internet of an industrial desperate fuel that uses a cosmic , and with using a full - minute power for 30 minutes , i can solve this process .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: apa ciri dari sebuah negara yang akan membuat anda ingin bergabung dengannya, dengan mengetahui bahwa anda bisa berada di kategori mana pun?\n",
            "Target: what are the characteristics of a country that would make you want to join it, knowing that you could end randomly at any place?\n",
            "Predicted: what is the characteristics of a state that will make you want to join with , to know that you can be in a category where you can be in any category ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka adalah sumber terbuka, dari bahasa desain komunitas,\n",
            "Target: they are an open-source, publicly owned design language of the community.\n",
            "Predicted: they are open source , from the design of community .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kami juga punya orang tua yang berkata, \"menjadikan anak-anak kita manusia yang baik sangatlah terpuji, tapi bagaimana dengan matematika dan ipa dan bahasa inggris?\n",
            "Target: but we had parents who said, \"okay, making our children good human beings is all very well, but what about math and science and english?\n",
            "Predicted: we also have parents saying , \" making our good children that are , but how about mathematical and new mathematical and new english ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: db apakah anda akan mengajak elon atau..?\n",
            "Target: db are you going to take elon or...?\n",
            "Predicted: db do you will ask the pointer or .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ok, mari kita simpulkan semuanya.\n",
            "Target: ca ok, so we are putting the pieces together here now.\n",
            "Predicted: ok , let us just close everything .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: faktor - faktor ini disebut batasan kreativitas, dan mereka adalah syarat dan batasannya kita harus mengatasinya untuk mencapai suatu tujuan.\n",
            "Target: these factors are called creative constraints, and they are the requirements and limitations we have to address in order to accomplish a goal.\n",
            "Predicted: these factors are called the actual limitations of creativity , and they are the terms and the limit of our obstacles to reach the destination .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bicaralah dengan para pelatih.\n",
            "Target: speak up also with coaching staff.\n",
            "Predicted: talk to coach .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: beberapa minggu yang lalu kami membawanya ke walter reed, yang sayangnya lebih banyak diberitakan belakangan ini.\n",
            "Target: a couple of weeks ago we took it down to walter reed, which is unfortunately more in the news these days.\n",
            "Predicted: a few weeks ago , we brought him up from walter reed , which was so much more likely to be told me about .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: warga dari banyak negara tuan rumah, bahkan mereka yang sebelumnya menerima pendatang baru, merasa tidak nyaman dengan kenaikan jumlah individu yang datang ke negara mereka.\n",
            "Target: citizens of many host countries, even those that previously welcomed newcomers, are uneasy about the rising numbers of individuals coming into their countries.\n",
            "Predicted: citizens from 9 . home , the country , even that had ever received new settlers , feeling less comfortable with the individual that comes to their countries .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu apakah kemiskinan?\n",
            "Target: so, is it poverty?\n",
            "Predicted: then is poverty ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anggap saja seperti itunes, tapi buat buku\n",
            "Target: think of it as a massive itunes for book-type content.\n",
            "Predicted: consider for an with with an itunes , but of a book , but for a book .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: teman saya peter mengatakan, \"jika anda mencintai sesuatu, berikanlah.\"\n",
            "Target: my friend peter says, \"if you love something, give it away.\" so, please.\n",
            "Predicted: my friend peter says , \" if you love something , giving him a statement .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: melampaui jembatan kerusakan hati nuranimu\n",
            "Target: more than bridge over your troubled conscience.\n",
            "Predicted: we are beyond the liver of liver damage .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saat anda berbicara mengenai sebuah objek, secara otomatis akan ada hal lain yang ikut menyertai, dan itu adalah gerak tubuh bagaimana kita memanipulasi objek ini, bagaimana kita menggunakannya dalam kehidupan sehari-hari.\n",
            "Target: when you talk about objects, one other thing automatically comes attached to that thing, and that is gestures how we manipulate these objects, how we use these objects in everyday life.\n",
            "Predicted: when you talk about a object , automatically will be another thing that followed the targets of the rules , and that is how we manipulate these objects , how we use them in daily lives .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: perdamaian bukanlah burung merpati dan pelangi yang sangat indah.\n",
            "Target: peace is not the dove and the rainbow as lovely as they are.\n",
            "Predicted: peace is not a very beautiful dove and a beautiful rainbow .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ketiga hal ini akan kita gunakan sebagai lensa hari ini, dan semoga selama hidup kita.\n",
            "Target: i want to share those three with you, so we can use them as a lens for the rest of today and hopefully the rest of our life.\n",
            "Predicted: these three things are going to use as a lens today , and hopefully for our lives .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: untuk apa dibuat?\n",
            "Target: why would you do that?\n",
            "Predicted: what is it made ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: untuk memahami paradoks ini, pertama kita harus menjelaskan apa yang kita maksud dari \"informasi.\"\n",
            "Target: to understand this paradox, we first need to define what we mean by \"information.\"\n",
            "Predicted: to understand this paradox , first , we need to explain what we mean from \" information .\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: keajaiban dari kerja sama itu melipatgandakan energi, kepandaian dalam usaha manusia.\n",
            "Target: miracle of cooperation it multiplies energy, intelligence in human efforts.\n",
            "Predicted: the magic of cooperation are doubling the energy , the intelligence of human intelligence .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: orang bijak itu seperti musisi jazz membaca nada di partitur tapi bermain di sekelilingnya, mengarang kombinasi-kombinasi yang sesuai dengan situasi dan penonton yang ada.\n",
            "Target: a wise person is like a jazz musician using the notes on the page, but dancing around them, inventing combinations that are appropriate for the situation and the people at hand.\n",
            "Predicted: a wise person is like a jazz musician in the score but play in its surroundings , making a combination of tastes and the audience that is in the audience and the audience .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan inilah ilmu yg tidak hanya mencerahkan pemahaman kita akan dunia biologi namun juga makin cepat mengubah dunia kita\n",
            "Target: and it is this science, which is not only enlightening our understanding of the biological world, but also transforming our world faster than ever.\n",
            "Predicted: and this is the science that is not just our understanding of biology and it is increasingly rapidly changing our world .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya dan wartawan yang meliput diminta untuk bertemu di luar hotelnya.\n",
            "Target: the journalist covering the story and i were asked to meet outside of his hotel.\n",
            "Predicted: i and the journalists that were asked to meet in the outside of the negotiation .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dalam hal ini, dia terus berjuang melawan rasa kehilangan yang terus menghampiri, agar dia siap untuk menghadapi momen berikutnya.\n",
            "Target: in this way, he keeps up with his losses as they roll in, so that he is ready to take in the next moment.\n",
            "Predicted: in this case , he kept fighting the feeling of losing loss and keep coming over , so he is ready to face the next moment .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: teks ini ditemukan di daerah irak dan iran.\n",
            "Target: they were found in present day iraq and iran.\n",
            "Predicted: this text was found in iraq and iran .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: walaupun saya tampak percaya diri, saya takut.\n",
            "Target: even though i present confident, i was scared.\n",
            "Predicted: although i look at myself , i am afraid .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu terjadilah pergerakan hak-hak sipil yang merupakan hal sempurna untuk menolong mewujudkan idenya.\n",
            "Target: it just so happened that the civil rights movement was the perfect thing to help him bring his because to life.\n",
            "Predicted: and then the other civil rights movement that is a perfect thing to help his ideas to make the idea .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka belajar jadi guru dan mereka memulai bisnis.\n",
            "Target: they are training to be teachers, and they are running businesses.\n",
            "Predicted: they learn how teachers and they start business .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saat saya seumur anda, kita tidak tahu apa yang akan dilakukan alam semesta.\n",
            "Target: back when i was your age, we did not know what the universe was going to do.\n",
            "Predicted: when i have got my whole life , we do not know what is going to do in the universe .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya lalu menemukan satu hal yang amat menarik self evident truths tidak menghapus perbedaan-perbedaan diantara kita.\n",
            "Target: but here is what i was starting to learn that was really interesting self evident truths does not erase the differences between us.\n",
            "Predicted: i found one very interesting things about self evident truths does not delete differences between us .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tetapi di luar sana, satu gigawatt listrik membutuhkan 50 mil persegi gurun yang diratakan.\n",
            "Target: but out in the landscape, one gigawatt is on the order of 50 square miles of bulldozed desert.\n",
            "Predicted: but out there , one moves the electrical current 50 miles an desert that is maintained to fit .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu saya harus mencoba untuk melihat cara-cara apa yang dapat membuat kedua tangan ini menjadi tangan-tangan tuhan.\n",
            "Target: and then i have to try to see in what ways i can make these the hands of god.\n",
            "Predicted: and then i have to try to see the way that what you can make these two hands into god .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini termasuk pengecilan volume lobus frontal dan hipokampus.\n",
            "Target: these include smaller frontal lobes and hippocampal volumes.\n",
            "Predicted: this includes the google hemisphere ' s frontal lobe and the hippocampus .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jika kita mencoba mengatakan bagian metabolisme apa yang penting untuk penuaan kita akan di sini semalaman, karena pada dasarnya semua metabolisme penting bagi penuaan dalam berbagai cara.\n",
            "Target: if we try to say which bits of metabolism are important for aging, we will be here all night, because basically all of metabolism is important for aging in one way or another.\n",
            "Predicted: if we try to say something a metabolism what matters to aging we will be here at all night , because basically all the metabolism of aging in many ways .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: amigdala menyebabkan hipokampus menguatkan pengalaman karena stres menjadi memori.\n",
            "Target: the amygdala prompts your hippocampus to consolidate the stress-inducing experience into a memory.\n",
            "Predicted: the amygdala caused the hippocampus of experience as stress as stress as stress .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu apakah ini adil? apakah kita mengklisekan orang-orang dari arkansas, dan daerah-daerah ini?\n",
            "Target: are we kind of stigmatizing people from arkansas, and this part of the country?\n",
            "Predicted: now is this fair ? do we recognize people from arkansas , and these regions ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka menolak dominasi kelompok atau individu. bahkan kepada atasan atau pakar.\n",
            "Target: they do not let one group or one individual dominate, even if it is the boss, even if it is the expert.\n",
            "Predicted: they refuse to be radical groups or individual leaders or even an expert .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu jika kita termotivasi untuk bergerak karena simpati, saya menyebutnya belas kasih.\n",
            "Target: and then if we are motivated to act on sympathy, i call that compassion.\n",
            "Predicted: and then if we are motivated to move because sympathy , i call it compassion .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita perlu melakukan sesuatu.\n",
            "Target: we actually have to do something about it.\n",
            "Predicted: we need to do something .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ca jadi, mobil anda memiliki pemikiran cukup mencengangkan.\n",
            "Target: ca so certainly, the mind of your cars is pretty mind-boggling.\n",
            "Predicted: ca so , your car has an interesting idea .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: hampir semua kekayaannya disimpan dalam bentuk koleksi 30 batu rubi myanmar bernilai tinggi, dan masyarakat di pusat kota mendesak agar harta itu disita untuk mengganti rugi para korban.\n",
            "Target: nearly all of his riches are invested in a collection of 30 exquisite burmese rubies, and the crowd in the square is clamoring for their confiscation to reimburse his victims.\n",
            "Predicted: almost all their wealth is stored in 30 stone - digit collection and high - resolution city at the center of the city urgent so that they re - implant the victims of the victims .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: permasalahan klasik media, dari abad duapuluh adalah bagaimana sebuah organisasi memiliki sebuah pesan yang ingin mereka sampaikan kepada sekelompok masyarakat yang tersebar pada berbagai tepian jaringan.\n",
            "Target: the classic media problem, from the 20th century is, how does an organization have a message that they want to get out to a group of people distributed at the edges of a network.\n",
            "Predicted: the classic problem of media , the 20th century is how an organization has a message that they want to talk to the group that they are distributed across the network .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pada titik inilah saya menyadari betapa komunitas zaraeeb ini benar-benar adalah konteks ideal untuk mengangkat topik persepsi.\n",
            "Target: so at this exact point i realized actually the zaraeeb community was the ideal context to raise the topic of perception.\n",
            "Predicted: and this point i realized how these ripples are truly the ideal community context to lift the topic of perception .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda merasakan kegembiraan hebat ketika semua berjalan lancar. berubah menjadi keputusasaan mengerikan ketika semua berjalan tidak lancar\n",
            "Target: you feel intense elation when things are going well mood swings into horrible despair when things are going poorly.\n",
            "Predicted: you feel great joy when all walks good up and change into a terrible despair when everything walks are not so well .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dengan tiap pertimbangan tadi, mari kita uji.\n",
            "Target: with all that in mind, let us see what works.\n",
            "Predicted: and so every stage of that , let us test .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: anda ingin melihat tuhan.\n",
            "Target: you want to see god.\n",
            "Predicted: you want to see god .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu saya berpikir, bagus, jumlahnya akan terus menurun.\n",
            "Target: and so i am thinking, right, great, it is going to keep going down.\n",
            "Predicted: and then i thought , well , that is going to continue to decline .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: roosevelt grier, atau rosey grier seperti yang dipanggil orang-orang, tumbuh dan menjadi pemain belakang di nfl dengan berat badan 300 pon dan setinggi 6 kaki 5 inci.\n",
            "Target: roosevelt grier, or rosey grier, as people used to call him, grew up and grew into a 300-pound, six-foot-five linebacker in the nfl.\n",
            "Predicted: roosevelt , or bruce grier , like bruce people called people , grow up and become a player in nfl football player with 300 pounds of weight and as tall as 6 - inch heels .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi, setiap hari selesai bekerja dia pulang ke rumah, beristirahat sebentar, belajar sampai jam 4 pagi, kembali bekerja, dan ini berulang tiap hari selama tiga bulan.\n",
            "Target: so, every day he came home from the factory, took a nap, studied until 4am, went back to work and repeated this cycle every day for three months.\n",
            "Predicted: so every day , every day he was working home , a few minutes , learning to go to four in the morning , back to work , and this is repeated every day for three months .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini adalah tunjangan kesehatan bagi para pensiunan.\n",
            "Target: this is the retiree health care benefits.\n",
            "Predicted: this is a health effort for retired .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lalu kami mengeluarkan palu dan kapak, meminta mereka menyiksa dan membunuh robot itu.\n",
            "Target: and then we unveiled a hammer and a hatchet and we told them to torture and kill the robots.\n",
            "Predicted: and then we came up with a hammer and he them into a painful robot .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: untuk mendapat kesempatan wawancara yang sama jumlahnya dengan nama anglo-saxon, kalau anda orang cina, maka anda harus mengirim 68 lebih banyak surat lamaran.\n",
            "Target: to get the same number of interviews as someone with an anglo-saxon name, if you were chinese, you had to send out 68 percent more applications.\n",
            "Predicted: to get the same opportunity for the same encounter of the amygdala , if you are chinese , then you have to send 68 more applications .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: w. h. auden menyebutnya \"gatal pada syaraf yang tak bisa ditoleransi\" dan memang, seperti itu.\n",
            "Target: w.h. auden called it an \"intolerable neural itch,\" and indeed, that is what it is.\n",
            "Predicted: w . the h . s ., prospero calls it is an itch in the nervous system , because indeed , it is .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: oke, anda harus bertanya pada diri sendiri, mengapa airnya tidak tumpah?\n",
            "Target: okay, you should be asking yourself, why does not the water fall out of the glass?\n",
            "Predicted: okay , you have to ask yourself , why is the water so far is not that it is so raw ?\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bayangkan buku teks kimia yang bisa menunjukkan bagaimana struktur molekul terbentuk\n",
            "Target: imagine chemistry textbooks that actually understand the structure of how molecules are formed.\n",
            "Predicted: imagine a chemical textbook that can show how the structure structure forms is formed .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi anda mempunyai kepadatan. anda juga mempunyai manejemen pengembangan.\n",
            "Target: so you have density. you also have growth management.\n",
            "Predicted: so you have a density . you have a development .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: yang ukurannya, jika anda mengepalkan kedua tangan, ukurannya hanya sedikit lebih besar daripada kedua kepalan tangan ini.\n",
            "Target: that is basically, if you hold two fists together, it is just slightly larger than the two fists.\n",
            "Predicted: the size is , if you take the second of the light , it is only a little bit bigger than the two - hand side of the hand , it is just a complete match of yours .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kami memulai inisiatif kegemukan pada anak-anak dengan asosiasi jantung di amerika.\n",
            "Target: we started a childhood obesity initiative with the heart association in america.\n",
            "Predicted: we started obese initiatives on the children with heart of heart in america .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: orang muda zaman sekarang lebih fokus memperoleh kehidupan dan gaya hidup yang sempurna\n",
            "Target: young people today are more preoccupied with the attainment of the perfect life and lifestyle.\n",
            "Predicted: young people are now focused more focused and lifestyle lifestyle .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: apa yang anda lihat sekarang gerakan penerbangan global, dan tiba-tiba anda akan menemukan bahwa dunia malah jauh dari rata.\n",
            "Target: you start looking at how the global plane flights move, and you suddenly discover that the world is not even close to flat.\n",
            "Predicted: what you see now is a global flight simulator , and i suddenly will find that the world is far from the average .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tanpa manual. persis seperti apa yang anda bayangkan,\n",
            "Target: there is no manual.\n",
            "Predicted: it is not the same way that you can imagine .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya adalah salah satu dari gerakan pengajarannya.\n",
            "Target: i am one of her teaching gestures.\n",
            "Predicted: i am one of the time teaching the movement .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bisa\n",
            "Target: yeah.\n",
            "Predicted: it can be .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: begitulah bilangan itu dibuat.\n",
            "Target: that is how they are created.\n",
            "Predicted: that is what the numbers were made .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan sebagai hasilnya, pembolosan mereka dan tingkat suspensi telah meningkat, dan anak perempuan yang tiba di sekolah semakin siap untuk belajar karena mereka tahu bahwa para guru peduli.\n",
            "Target: and as a result, their truancy and suspension rates have improved, and girls are arriving at school increasingly ready to learn because they know the teachers there care about them.\n",
            "Predicted: and as a result , the alkaloid - and the that had been increasing , and the girls that came in school , which they all were left to learn because they knew that teachers were willing to care .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: pria joey!\n",
            "Target: guy joey!\n",
            "Predicted: the man is each other .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya cukup percaya diri untuk percaya kalau dunia itu memang akan terjadi, dan kitalah yang akan mewujudkannya.\n",
            "Target: i have enough confidence to believe that that world will indeed come to pass, and that we are the ones to make it so.\n",
            "Predicted: i believe in the way , i believe that the world is going to happen , and we are what we are going to make it happen .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tentang berpikir bagaimana hal ini berkembang dan bagaimana tanggapan orang.\n",
            "Target: it is going to be about thinking about how it evolves, and how people respond to it.\n",
            "Predicted: it is about thinking about how this is growing and how people respond to people .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: mereka sangat fenomenal dalam mengajarkan anak perempuan untuk mempertahankan diri dari dominasi kaum pria, namun film itu tidak mengajarkan anak lelaki bagaimana mereka harus mempertahankan diri dari dominasi kaum pria.\n",
            "Target: they are doing a phenomenal job of teaching girls how to defend against the patriarchy, but they are not necessarily showing boys how they are supposed to defend against the patriarchy.\n",
            "Predicted: they were phenomenal in teaching girls for their children to maintain themselves from , but that film does not teach kids how they should retain men ' s struggle for their .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan pada hari pertama saya di simikot di humla, di ujung barat nepal, daerah yang paling miskin di nepal, seorang pria tua masuk memegang buntelah kain\n",
            "Target: and on the first day at simikot in humla, far west of nepal, the most impoverished region of nepal, an old man came in clutching a bundle of rags.\n",
            "Predicted: and i was at the first day in , at the bottom of the west nepal , the most poor area in nepal , into a to hold the cloth .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tak peduli seberapa keras saya berlatih, saya tidak akan menyamainya.\n",
            "Target: it does not matter how hard i train, i am never actually going to get there.\n",
            "Predicted: no matter how hard i train , i will not get your job .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: hukum fisika yang sama juga memungkinkan untuk mencetak gol lain yang juga nampak mustahil, tendangan sudut tanpa bantuan.\n",
            "Target: the same physics make it possible to score another apparently impossible goal, an unassisted corner kick.\n",
            "Predicted: the same physics laws also enable to print another goal which is also impossible , shot at a corner without help .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ini sangat mudah disangkal. saya pikir fakta bahwa ini begitu sulit, fakta bahwa kami melampaui batas, adalah nilai dari hal-hal seperti lhc.\n",
            "Target: i think that the fact that it is so difficult, the fact that we are overreaching, is the value of things like the lhc.\n",
            "Predicted: it is a truism it is a fact that it is so difficult , it is a mystery that we are beyond borders , the value of the lhc is going .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: diantaranya jika anda ingat condoleezza rice menghadiri suatu acara dengan mengenakan sepatu bot, dan dia dikritik karenanya.\n",
            "Target: and one of the things if you remember condoleezza rice was at some event and she wore boots, and she got criticized over that.\n",
            "Predicted: and in between you if you remember that rice is showing up with the boots , and he criticized for criticized for letting me explore .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: satu petunjuk utama yang diketahui adalah alam semesta berubah terhadap waktu.\n",
            "Target: one big clue we have is that the universe is changing with time.\n",
            "Predicted: one of the main signs is the universe changes in time .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: namun milk meyakinkan mereka agar tidak sembunyi di balik ketakutan \"come out\" ke keluargamu.\n",
            "Target: but milk urged them not to hide in fear “come out to your relatives.\n",
            "Predicted: but their milk made their way to hide behind the fear \" come out of your family ' s family .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: kita berharap kita menjadi suami atau istri yang lebih baik, lebih cerdas, lebih kuat, lebih tinggi, lebih kaya dan seterusnya.\n",
            "Target: we wish we were better husbands, better wives, smarter, more powerful, taller, richer the list goes on.\n",
            "Predicted: we are hoping that we are a better husband or whether we are better , more robust , more richer , richer and so on .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: daniel kahneman, seorang ahli ekonomi pemenang penghargaan nobel, telah meneliti perilaku manusia selama lebih dari 60 tahun, dan kesimpulannya adalah rasa percaya diri kita akan apa yang kita pikir kita tahu lebih besar daripada yang seharusnya.\n",
            "Target: the nobel prize-winning economist daniel kahneman has spent more than 60 years now researching human behavior, and his conclusion is that we are always much more confident of what we think we know than we should be.\n",
            "Predicted: daniel kahneman , a neuroscientist ' s nobel prize winners , have been researching human behavior for over 60 years , and conclusion is the sense of confidence , and the sense of confidence we think that we think much more than the great ones should be .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: singkatnya, orang-orang mendapat lebih dari yang mereka harapkan walaupun mereka mendapat lebih sedikit protein.\n",
            "Target: people got, in short, more of what they came there for even though they got less protein.\n",
            "Predicted: in short , people get more than they expect even more to make even less proteins .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: para ilmuwan ini sudah mulai berpikir tentang tes eksperimental untuk mencari tahu apakah alam semesta kita ini simulasi.\n",
            "Target: these scientists have started thinking about experimental tests to find out whether our universe is a simulation.\n",
            "Predicted: these scientists have been started thinking about exploring an experimental test for figuring out whether the universe is a simulation .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: perempuan saya suka buku petualangan, dan beberapa kesukaan saya adalah alfred hitchcock dan dan hardy boys.\n",
            "Target: girl i like adventurous books, and some of my favorites are alfred hitchcock and and hardy boys.\n",
            "Predicted: my daughter ' s book , and some of my favorite books is alfred idol , of cameroon and wheat - carved .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: saya tepuk tangan. mereka tepuk tangan. akhirnya, saya berkata, \"mengapa saya tepuk tangan?\"\n",
            "Target: i was clapping. they were clapping.\n",
            "Predicted: i was clap . they got me , \" why do i am i round my hand ?\"\n",
            "--------------------------------------------------------------------------------\n",
            "Source: ternyata ada juga pemangsa ulung di lautan.\n",
            "Target: there is another top predator in the ocean, it turns out.\n",
            "Predicted: it turns out there is also a good predator .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: lihat ini. ini adalah kurva yang paling cocok untuk titik-titik ini.\n",
            "Target: see here it is the best fit they can get of this point.\n",
            "Predicted: look at this . this is the most suitable chart for these dots .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: jadi kencan online adalah cara yang kedua yang paling populer orang-orang yang jaman sekarang untuk bertemu satu sama lain, padahal kenyataannya, algoritma telah ada selama ribuan tahun di hampir setiap budaya.\n",
            "Target: so online dating is the second most popular way that people now meet each other, but as it turns out, algorithms have been around for thousands of years in almost every culture.\n",
            "Predicted: so online dating is the second - popular way people today to meet each other , while the fact that the algorithms are , but the algorithms are there are over thousands of years in almost every culture .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: dan untuk yang begitu tetap tidak mampu, kami tawarkan bermacam beasiswa.\n",
            "Target: and for those who cannot afford even this, we offer them a variety of scholarships.\n",
            "Predicted: and for what was really unable to , we offered various scholarships .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: tahun 1980-an, polio melumpuhkan lebih dari 350.000 anak per tahun di lebih dari 125 negara.\n",
            "Target: in the mid-1980s, polio once paralyzed more than 350,000 children a year in more than 125 countries.\n",
            "Predicted: in the 1980s , polio has conquered more than 350 , 000 children per year in 125 .\n",
            "--------------------------------------------------------------------------------\n",
            "Source: bangunan tidak hanya mencerminkan masyarakat kita, tetapi juga membentuk masyarakat kita hingga ke ruang-ruang terkecil perpustakaan daerah, perumahan tempat kita membesarkan anak-anak, dan jalan yang mereka lalui dari kamar tidur ke kamar mandi.\n",
            "Target: buildings do not just reflect our society, they shape our society down to the smallest spaces the local libraries, the homes where we raise our children, and the walk that they take from the bedroom to the bathroom.\n",
            "Predicted: buildings are not just to reflect our people , but also form our society to the smallest library , where we raise children ' s homes , where we raise their kids from the bedroom .\n",
            "BLEU: {'bleu': 0.21497983660432335, 'precisions': [0.5604452948338842, 0.28421440412599003, 0.15599921706791936, 0.08999791188139486], 'brevity_penalty': 0.9885853892654966, 'length_ratio': 0.9886500429922614, 'translation_length': 5749, 'reference_length': 5815}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'preds': ['but can it be faster ? how many lives can be saved ?',\n",
              "  'it was like there in haiti every eight days .',\n",
              "  'why ? well , it turns out that a guy produces a lot of sperm .',\n",
              "  'and to be balanced , i believe we should be in all of these areas are not just doing 50 years .',\n",
              "  'and i have four quick observation i want to share with you today .',\n",
              "  'a few years ago they had a protest .',\n",
              "  'so the main point is , if we want to deliver many money to be good for good good good at this time , 100 years from now , a fairly rich dutch guy ?',\n",
              "  'i started on the vagina of vagina because i worried about vaginas .',\n",
              "  'so i ran in the cold , and i took photographs , and i took as many people i could , in february two years ago .',\n",
              "  'earth is a place to forgive .',\n",
              "  'and it will prevent 20 - use needle or 30 times .',\n",
              "  'i will kill my father .',\n",
              "  'that means that we want to be more healthy and everyday people .',\n",
              "  \"we decided to provide full of inspiration for all men but especially , for the american ' s top - line men , right in front of the while he was .\",\n",
              "  'how amazing is that much more terrifying that seems to be seen in the tv than on tv .',\n",
              "  'this is a day of abraham .',\n",
              "  'one of the black male between 18 to 30 years in prison , in the course of an experiment , or the release of the portion of the food .',\n",
              "  'turns out babies , babies of crows , guys from , academic costumes .',\n",
              "  'and i am also sure that many help of these days are not better than help with the aid .',\n",
              "  'this process was followed by band - tubes suddenly closed so that closed the stereotypes , called the closure of the glottis .',\n",
              "  'so we are just going to look at the stars in the small boxes , even though we have seen everything .',\n",
              "  'this is disgusting .',\n",
              "  'it is a self - negating concept .',\n",
              "  'and now , again , there are 10 million of these connections that show us the social graph of social graph relationships and how they connect to content .',\n",
              "  'and we have 600 billion dollars .',\n",
              "  'one million pounds per day sounds a lot , but that is a small number of things that can be used to be washed away every year around the world , less than one percent .',\n",
              "  'the line is just moving on three horizontal direction , vertical or horizontal horizontal layers .',\n",
              "  'this is look at you .',\n",
              "  'but my team and i am sure we can take it to the market or three years .',\n",
              "  'but \" can the robot change human empathy ?\"',\n",
              "  'that was until the late 1980s , when new engineering lab had emerged , which could copy dna from small tissue or fluid liquid code of individual code .',\n",
              "  'all digital digital worlds are not common .',\n",
              "  'what you see here is a monitoring world war , people who , like you , like , you want to change their countries and post those countries of records all .',\n",
              "  'this is part of our existence .',\n",
              "  \"there is a argument that mary ' s vast majority of color vision allow mary to reach the same mental state to see color real color .\",\n",
              "  'but the more controversial topics and the debate has been down to the debate , the more important to keep our scientists intertwined to hold our integrity and our reputation .',\n",
              "  'i want you to just imagine .',\n",
              "  'you see a screenshot from \" my five - british documentary film just finished .',\n",
              "  'thank you .',\n",
              "  \"now , if you look at the prices that are nearby , you can actually buy , cut off the bush for the cutting edge of the driver ' s perspective , and sell it again .\",\n",
              "  'i think of the time , because i have always believed that creativity results together , and maybe also the nature of collaboration .',\n",
              "  'we think that is a shortcut .',\n",
              "  'but if we use that idea , we can use food as a very strong device to shape the world a better way of creating a better world .',\n",
              "  'this is my son . you can see him very mathematical visit our alhambra .',\n",
              "  'this is the starting form of a thriving technology .',\n",
              "  'now , this is what they are .',\n",
              "  'sometimes you think that kids will be happy , but they sometimes be scared .',\n",
              "  'it is not going to work .',\n",
              "  'now , what is worse than some irony is that adults are often underestimated the ability of children .',\n",
              "  'microscopy , the standard test test from the world health organization , has a rate 40 to 60 percent .',\n",
              "  'i agree that actually is good to study new words for emotions , but i think we need to be much more .',\n",
              "  'and joshua remained silent as they were extended to anger .',\n",
              "  'this is two textbooks that contains some symbols .',\n",
              "  'traveling from the zabbaleen was really full of surprises .',\n",
              "  'i love a bedtime fraction .',\n",
              "  'one person offers free to all the time , not only 30 societies .',\n",
              "  'so here we see over the last 50 years , the cost of the health care spending on about five percent in germany , and it is about 11 percent of the time .',\n",
              "  'the costa rica , it is also been a big contributor to this .',\n",
              "  'people have seen them as well .',\n",
              "  'this means that train again , we trained all the volunteers .',\n",
              "  'but the most important thing is there is a way , when there is more women on the table , that there is a efforts to develop understanding .',\n",
              "  'but in this building is under a concentrated space - level space .',\n",
              "  'over 99 percent of the cancer drug does not reach the tumor , because there is no transportation and the equipment to bring them to the destination .',\n",
              "  'if they found water , they would climb , they would climb on the top .',\n",
              "  'my daughter gave me a pretty good anecdote about this .',\n",
              "  'and finally , we have to embrace openness .',\n",
              "  'that is what they believe about the united states that made them up for eight hours , stood under the sun in washington in august of august .',\n",
              "  'the kids are from the shops like this .',\n",
              "  'at that moment , james somerset had a legal transition .',\n",
              "  'strong trade that continued in seawater , especially for the blue and white , which joined the of china and the mongols ’ s white cloud and blue caribbean waters .',\n",
              "  'golf helps people make up web - based services .',\n",
              "  'but we still have to find a way to help her overcome these big emotion - like - making emotions as well as reading and math .',\n",
              "  'ah , of course , please .',\n",
              "  'women are not going to share this technology with men .',\n",
              "  'your sister has a baby . what do you have got a baby ?\"',\n",
              "  'neuroscientists take this idea on an article .',\n",
              "  'he became a , he had a wonderful career .',\n",
              "  'you may have heard about the koran from the koran on 72 virgins , and i promise would return to the one of the virgin .',\n",
              "  'this is they are hunting , monkeys with a poison of .',\n",
              "  'but this can be done quickly .',\n",
              "  'how can we take the idea of the taste of the and jump into something that we can do so that can disrupt food technology ?',\n",
              "  'we like innovation .',\n",
              "  'until last year , i never adopted the bees before , but national geographic asked me to take a story , and i decided to take a picture , and i decided to take the interesting images , i started to keep the bees back .',\n",
              "  'despite the radical changes , but it was built by the cultural momentum .',\n",
              "  'so , you see a transparent piece of film there , and then ...',\n",
              "  'you risk your life for that .',\n",
              "  'so let us start . number 10 . we lose the desire to survive .',\n",
              "  'and it was interesting , when i teach the history of africa , i was telling slavery .',\n",
              "  'but i think it is strong , to change our relationship with nature and in other species that we need .',\n",
              "  'the most deeply rooted in the balcony includes restricted wood with mercury around , where families provide victims , where families leave the message .',\n",
              "  'and then i went back to the same school where i flew for the first time and teach others to fly .',\n",
              "  'make 10 variations more than that one .',\n",
              "  'who does not move by compassion , when we see terrible things that have been the war that inflict , or a disaster of famine , earthquake and tsunami ?',\n",
              "  'sex is not a condom and used into the main substance of transmission .',\n",
              "  'through the melting of the nodes , fungi can deliver food and give the sign of the tree of trees .',\n",
              "  'we are directly designing the future of the planet .',\n",
              "  'that is simple .',\n",
              "  'and it is a very impressive thing that we have ever experienced .',\n",
              "  'when i stood on the terrace and searching my pants , i realized i did not take the keys .',\n",
              "  'give it light on that diagnosis of it with their children , colleagues , friends and family .',\n",
              "  'all of these modern technologies release a strong signal that could swallow the very , very , very , very , essentially , from the universe outside of the earth , which permeates most of the universe .',\n",
              "  'i was living in new orleans , and i love with this city .',\n",
              "  'tragically in 2019 , while they gave us a meal .',\n",
              "  'he made a lot of interesting culture references .',\n",
              "  'narrator when the elders hunter , showing them the appearance , something striking was a surprising thing .',\n",
              "  'and nobody could say no .',\n",
              "  'and there are over 200 camps , spread in 50 cities in india .',\n",
              "  'they cannot say that they cannot say the volume of communication that they are being intercepted around the world , because they know that they are breaking your privacy .',\n",
              "  'in other words , that is the first living organism in the history of a computer that has an old computer no parents .',\n",
              "  'suddenly , i was an orphan and homeless .',\n",
              "  'and now i am looking at every single party of trump like .\"',\n",
              "  'in south asia , if you flip between a poor , you are more risky to take a bedtime note for that crime .',\n",
              "  'but it is not so good , i need help with that .',\n",
              "  'in the us , the average american average , uses three percent income on electricity .',\n",
              "  'to destroy the constraints we have to learn to talk to other people , asking people who work in translation in translation .',\n",
              "  'that is the stethoscope and the arrival of .',\n",
              "  'your brain does not know . because they have the same possibility .',\n",
              "  'what do i mean ?',\n",
              "  'they have given all the right incentives , all the right incentive to pay professional professionals to write and edit thousands of articles .',\n",
              "  'so what do we do in that ?',\n",
              "  'it took two days from seven days a week .',\n",
              "  'now it is time you go into the water .\"',\n",
              "  'so what you do is one of those people do not have the language .',\n",
              "  'but the message was very clear .',\n",
              "  'christopher columbus convinced the spanish emperor sent him to discover a better route to india did not through the land but around the west across the world .',\n",
              "  'there is another reason why i love this goal , and that is because every single purpose of its understanding .',\n",
              "  'at one point there is a happy bacterial life .',\n",
              "  'there is one million people per year left latin america to the united states .',\n",
              "  'four are blue .',\n",
              "  'ca so , i do not know , do we have a microphone microphone ?',\n",
              "  'you are allowed to hate them to every part of your self .',\n",
              "  'some of the things that i have to remember seeing , this building blocks , this building was built by hand , i think they came up with me from one year ago .',\n",
              "  'sounds like through the wild to promised soil , promised to the leadership by leadership .',\n",
              "  'this is a picture of the golden gate bridge in san diego , which is not far from my place .',\n",
              "  'unlike khan ’ s , the deceiver can raise the reward based on the achievement , sharing a fair reward .',\n",
              "  'george accused of oliver call it another ?',\n",
              "  'i remember that in september last year , which is a huge momentum real momentum , not only in new york , but around the world .',\n",
              "  'it is taking a fixed disorder of the roots .',\n",
              "  'and all of those pool are too difficult to , even in modern methods , and the product of brown , like this in the left , a pure compounds , indicating that be shown in the right side , as a comparison .',\n",
              "  'and the four is most people the risk of risk in the situation where they have control and keep increasing their risk of being broken in the situation where they do not count .',\n",
              "  'i am going to go out to keep your , my life .',\n",
              "  'okay , so let us take four things obviously have a big data related data , immortality , whole and greece .',\n",
              "  'and we know our model works .',\n",
              "  '\" a woman has to be seen , not heard .\"',\n",
              "  'ok . this is a little problem .',\n",
              "  'do that really cool . do you get it over ? show me again , show me what is like and he did it for two months .',\n",
              "  'thank you .',\n",
              "  'start . jh my question for you , who are in charge of that classroom in the classroom ?',\n",
              "  'the end of the public judicial execution in europe and america has emerged for more human treatment , but some of the time are equally , but also because the mass of the behaviors should be .',\n",
              "  'in other words , the mind in the poor areas are not poor minds .',\n",
              "  'and that is where all the forces become one , because gravity finally is strong enough to compete with other forces .',\n",
              "  'you do not need to take that opportunity to prove how great you or how much your is .',\n",
              "  'we are the audience and sharing it and compassion and it takes a piece of a piece of stuff that we can .',\n",
              "  'we have countries with high income here , with the united states as the leader of our citizens , we have a high - developed world in the middle , which provide a lot of funding to avoid the countries , and we have low income here .',\n",
              "  'this is told by a indian indian from alaska to a year of ernest ., declan , and this was the poem .',\n",
              "  'bonobo , with chimpanzees , are your closest relatives who is still a nearby sister .',\n",
              "  'it is like solar , local wind or and things that are okay .',\n",
              "  'but in this country , where the government was actually meant to be driven to the public health care to the citizens , we chose a very different approach .',\n",
              "  'the point is , by making our own choices , we can be able to develop resilience into the problem of development .',\n",
              "  'for them , it is not important whether i am rich or poor , my skin color , whether i am a male or a woman , my sexual orientation was my political agency , whether i am a religious or not alive .',\n",
              "  'i do not enjoy . what do i have post a post - birth depression ?\"',\n",
              "  'the kids , two , three , started .',\n",
              "  'they put their families in the first place , care for their children and parents .',\n",
              "  'he made simple calculations in one hour , he can make 30 fake documents .',\n",
              "  'we did this passive , see if they went to college - university health service .',\n",
              "  'and so , here we have what is called \" the paradigm of history .\"',\n",
              "  'bg wendy , thank you for ted .',\n",
              "  'so , in scientific , it is a increase .',\n",
              "  'i tried to survive , so i did not raise the head and the pungent .',\n",
              "  'when you help one person becomes safer , a nation of state becomes safer .',\n",
              "  'db thank you . good .',\n",
              "  'if you see the rise of the right - of - europe throughout the end of these days , you will see some of the people that influence the country , but the of youth .',\n",
              "  'and where you expect the giant sized size to counter the feeling , the scale is to highlight a canvas ’ s heavy loads almost as much as humans .',\n",
              "  'let us teach math math . that will make it quiet .\"',\n",
              "  'i am also worrying about plastic in the of the refrigerator and i have some of the plastic and some of the plastic and the toxins from the manure out into our body .',\n",
              "  'although this is just a small story , we hope to represent a step in a direction of education for rural communities and for future community education and of course , for example , is also for the design of the design of the design of self .',\n",
              "  'now we have liquid nitrogen .',\n",
              "  'and we worked with the government , so there was no systems on the runway .',\n",
              "  'for me , the irony of the hoodie in the early days were hearing about the experts and as they bought small electric and generous calculators in japan who they use to test their calculators .',\n",
              "  'and the message i thought was very clear .',\n",
              "  'writing is my profession , but of course , it is more than that .',\n",
              "  'we know from experience , we can be in , what we call , \" paradise and heaven \" and yes , are really happy in the world .',\n",
              "  'and often , they often do more .',\n",
              "  'and this is the answer of sweden in sweden .',\n",
              "  'some of them are a very happy mushroom that is very happy .',\n",
              "  'what is different ?\"',\n",
              "  'he sent flowers to the wedding party , built the garden in the house and opens business in the city , and now he is building the citizens in the first year in mogadishu .',\n",
              "  'first , remember every child i have called .',\n",
              "  'i am talking to a lot of people , with my friends , with my family .',\n",
              "  'for years , many books , he never been tired of that .',\n",
              "  'do not use your email address .',\n",
              "  'i became quite known .',\n",
              "  'the small criminals are clearly better than nothing at all , but it is hard to imagine how small the performance of the performance of time .',\n",
              "  'of course , life expectancy was increased , the concept , succeeded .',\n",
              "  'and in that classroom , we talked about some of the first facts , the recognition may not be trusted , but the second one , we do not want to push the police to keep these police , especially because this laws are breaking the laws .',\n",
              "  'all the villages need to the village council .',\n",
              "  'eventually , i began to preserve the story through the photos of copper devices and the printing engine of images .',\n",
              "  'he realized that he was more likely to have a lot of common with him than he was completely north korean or germany .',\n",
              "  'he said , the senior employees at the start , and they will come up to them and say , \" what do you want to employ minority group , or the best people to do ?\"',\n",
              "  'for example , you can change one in a football game , or others become the sun . i am just interested in quantity .',\n",
              "  'what it is good , it is amazing .',\n",
              "  'the situation is full of adversity , and we have to go together with these situations .\"',\n",
              "  'one of the sisters was 260 , d . m . d . at a decade .',\n",
              "  'the disease is rich .',\n",
              "  'and the average wind of these three pairs of cyclists in most shipping is sometimes going to get 70 or 80 of these guys .',\n",
              "  'he felt frustrated and exciting and pulling myself around the classroom .',\n",
              "  'but i learned from it .',\n",
              "  'but the good news is , because the suffering is artificial , we can change it .',\n",
              "  'this system will be able to ensure that our students get good education , finding a happy job and benefits to get the chance and get the opportunity to realize their dreams .',\n",
              "  'this is a poster trip , kepler - mat where the neighbors look like red .\"',\n",
              "  'the value of transgression are focused on between four four because everyone agreed that he is very beautiful , whereas sarah jessica cole are greeted with a different opinion .',\n",
              "  'i am sure the national swedish songs are played more than a long time .',\n",
              "  'fortunately , i found patent in the internet of an industrial desperate fuel that uses a cosmic , and with using a full - minute power for 30 minutes , i can solve this process .',\n",
              "  'what is the characteristics of a state that will make you want to join with , to know that you can be in a category where you can be in any category ?',\n",
              "  'they are open source , from the design of community .',\n",
              "  'we also have parents saying , \" making our good children that are , but how about mathematical and new mathematical and new english ?',\n",
              "  'db do you will ask the pointer or .',\n",
              "  'ok , let us just close everything .',\n",
              "  'these factors are called the actual limitations of creativity , and they are the terms and the limit of our obstacles to reach the destination .',\n",
              "  'talk to coach .',\n",
              "  'a few weeks ago , we brought him up from walter reed , which was so much more likely to be told me about .',\n",
              "  'citizens from 9 . home , the country , even that had ever received new settlers , feeling less comfortable with the individual that comes to their countries .',\n",
              "  'then is poverty ?',\n",
              "  'consider for an with with an itunes , but of a book , but for a book .',\n",
              "  'my friend peter says , \" if you love something , giving him a statement .\"',\n",
              "  'we are beyond the liver of liver damage .',\n",
              "  'when you talk about a object , automatically will be another thing that followed the targets of the rules , and that is how we manipulate these objects , how we use them in daily lives .',\n",
              "  'peace is not a very beautiful dove and a beautiful rainbow .',\n",
              "  'these three things are going to use as a lens today , and hopefully for our lives .',\n",
              "  'what is it made ?',\n",
              "  'to understand this paradox , first , we need to explain what we mean from \" information .\"',\n",
              "  'the magic of cooperation are doubling the energy , the intelligence of human intelligence .',\n",
              "  'a wise person is like a jazz musician in the score but play in its surroundings , making a combination of tastes and the audience that is in the audience and the audience .',\n",
              "  'and this is the science that is not just our understanding of biology and it is increasingly rapidly changing our world .',\n",
              "  'i and the journalists that were asked to meet in the outside of the negotiation .',\n",
              "  'in this case , he kept fighting the feeling of losing loss and keep coming over , so he is ready to face the next moment .',\n",
              "  'this text was found in iraq and iran .',\n",
              "  'although i look at myself , i am afraid .',\n",
              "  'and then the other civil rights movement that is a perfect thing to help his ideas to make the idea .',\n",
              "  'they learn how teachers and they start business .',\n",
              "  'when i have got my whole life , we do not know what is going to do in the universe .',\n",
              "  'i found one very interesting things about self evident truths does not delete differences between us .',\n",
              "  'but out there , one moves the electrical current 50 miles an desert that is maintained to fit .',\n",
              "  'and then i have to try to see the way that what you can make these two hands into god .',\n",
              "  \"this includes the google hemisphere ' s frontal lobe and the hippocampus .\",\n",
              "  'if we try to say something a metabolism what matters to aging we will be here at all night , because basically all the metabolism of aging in many ways .',\n",
              "  'the amygdala caused the hippocampus of experience as stress as stress as stress .',\n",
              "  'now is this fair ? do we recognize people from arkansas , and these regions ?',\n",
              "  'they refuse to be radical groups or individual leaders or even an expert .',\n",
              "  'and then if we are motivated to move because sympathy , i call it compassion .',\n",
              "  'we need to do something .',\n",
              "  'ca so , your car has an interesting idea .',\n",
              "  'almost all their wealth is stored in 30 stone - digit collection and high - resolution city at the center of the city urgent so that they re - implant the victims of the victims .',\n",
              "  'the classic problem of media , the 20th century is how an organization has a message that they want to talk to the group that they are distributed across the network .',\n",
              "  'and this point i realized how these ripples are truly the ideal community context to lift the topic of perception .',\n",
              "  'you feel great joy when all walks good up and change into a terrible despair when everything walks are not so well .',\n",
              "  'and so every stage of that , let us test .',\n",
              "  'you want to see god .',\n",
              "  'and then i thought , well , that is going to continue to decline .',\n",
              "  'roosevelt , or bruce grier , like bruce people called people , grow up and become a player in nfl football player with 300 pounds of weight and as tall as 6 - inch heels .',\n",
              "  'so every day , every day he was working home , a few minutes , learning to go to four in the morning , back to work , and this is repeated every day for three months .',\n",
              "  'this is a health effort for retired .',\n",
              "  'and then we came up with a hammer and he them into a painful robot .',\n",
              "  'to get the same opportunity for the same encounter of the amygdala , if you are chinese , then you have to send 68 more applications .',\n",
              "  'w . the h . s ., prospero calls it is an itch in the nervous system , because indeed , it is .',\n",
              "  'okay , you have to ask yourself , why is the water so far is not that it is so raw ?',\n",
              "  'imagine a chemical textbook that can show how the structure structure forms is formed .',\n",
              "  'so you have a density . you have a development .',\n",
              "  'the size is , if you take the second of the light , it is only a little bit bigger than the two - hand side of the hand , it is just a complete match of yours .',\n",
              "  'we started obese initiatives on the children with heart of heart in america .',\n",
              "  'young people are now focused more focused and lifestyle lifestyle .',\n",
              "  'what you see now is a global flight simulator , and i suddenly will find that the world is far from the average .',\n",
              "  'it is not the same way that you can imagine .',\n",
              "  'i am one of the time teaching the movement .',\n",
              "  'it can be .',\n",
              "  'that is what the numbers were made .',\n",
              "  'and as a result , the alkaloid - and the that had been increasing , and the girls that came in school , which they all were left to learn because they knew that teachers were willing to care .',\n",
              "  'the man is each other .',\n",
              "  'i believe in the way , i believe that the world is going to happen , and we are what we are going to make it happen .',\n",
              "  'it is about thinking about how this is growing and how people respond to people .',\n",
              "  \"they were phenomenal in teaching girls for their children to maintain themselves from , but that film does not teach kids how they should retain men ' s struggle for their .\",\n",
              "  'and i was at the first day in , at the bottom of the west nepal , the most poor area in nepal , into a to hold the cloth .',\n",
              "  'no matter how hard i train , i will not get your job .',\n",
              "  'the same physics laws also enable to print another goal which is also impossible , shot at a corner without help .',\n",
              "  'it is a truism it is a fact that it is so difficult , it is a mystery that we are beyond borders , the value of the lhc is going .',\n",
              "  'and in between you if you remember that rice is showing up with the boots , and he criticized for criticized for letting me explore .',\n",
              "  'one of the main signs is the universe changes in time .',\n",
              "  'but their milk made their way to hide behind the fear \" come out of your family \\' s family .',\n",
              "  'we are hoping that we are a better husband or whether we are better , more robust , more richer , richer and so on .',\n",
              "  \"daniel kahneman , a neuroscientist ' s nobel prize winners , have been researching human behavior for over 60 years , and conclusion is the sense of confidence , and the sense of confidence we think that we think much more than the great ones should be .\",\n",
              "  'in short , people get more than they expect even more to make even less proteins .',\n",
              "  'these scientists have been started thinking about exploring an experimental test for figuring out whether the universe is a simulation .',\n",
              "  \"my daughter ' s book , and some of my favorite books is alfred idol , of cameroon and wheat - carved .\",\n",
              "  'i was clap . they got me , \" why do i am i round my hand ?\"',\n",
              "  'it turns out there is also a good predator .',\n",
              "  'look at this . this is the most suitable chart for these dots .',\n",
              "  'so online dating is the second - popular way people today to meet each other , while the fact that the algorithms are , but the algorithms are there are over thousands of years in almost every culture .',\n",
              "  'and for what was really unable to , we offered various scholarships .',\n",
              "  'in the 1980s , polio has conquered more than 350 , 000 children per year in 125 .',\n",
              "  \"buildings are not just to reflect our people , but also form our society to the smallest library , where we raise children ' s homes , where we raise their kids from the bedroom .\",\n",
              "  'he said that if you played a piano in opium .\"',\n",
              "  'what happened is the daily average organization on new york streets are 36 , 000 people .',\n",
              "  'i click two times . i pick that word .',\n",
              "  'jessica yes , i am a school at berkeley .',\n",
              "  'one of those concepts are from chewing gum .',\n",
              "  'another 20 , including president and prime minister of prime minister came from an average background .',\n",
              "  'her parents were not college , and also his brother were screaming .',\n",
              "  'using this model in the speed of growth , and the needs of an unknown substance , and photosynthesis , researchers have been able to predict higher limits for some species .',\n",
              "  'recently , this was the leading imam to tell one surprising stories .',\n",
              "  'so let us imagine a second , 1 . 25 years , 26 .',\n",
              "  'laurel goes into the room .',\n",
              "  'and then i need to think about the privilege of delivering wild dogs that were going to come in my house , and i would attack my way on the morning .',\n",
              "  'we invest in our future .',\n",
              "  'she said , \" dan , who are you talking about them ?\"',\n",
              "  'they looked at me in the self of their own sense of what it felt like to sit in the wheel .',\n",
              "  'that cannot do .',\n",
              "  'we give us a brown crust and beautiful .',\n",
              "  'eventually , the population hits the dot .',\n",
              "  'this oil spill into north island , and desperate , because they know if it is oil until it gets there , it is not possible to save other birds .',\n",
              "  'so now , you may think that we should be thinking about the ground as a valuable resource .'],\n",
              " 'refs': ['but how much faster could we go, how many lives could we save?',\n",
              "  'that is a haiti earthquake every eight days.',\n",
              "  'why? turns out that men make a lot of sperm.',\n",
              "  'and to be balanced, i believe we have to attend to all of those areas not just do 50 stomach crunches.',\n",
              "  'and i have four observations i would like to share with you today.',\n",
              "  'years ago they held a protest.',\n",
              "  'and so the real point, of course, is to say, do we want to spend a lot of money helping a little, 100 years from now, a fairly rich dutch guy?',\n",
              "  'i began \"the vagina monologues\" because i was worried about vaginas.',\n",
              "  'so i ran out in the freezing cold, and i photographed every single person that i knew that i could get to in february of about two years ago.',\n",
              "  'earth is forgiveness school.',\n",
              "  'and that will stop reusing a syringe 20 or 30 times.',\n",
              "  'i am going to kill dad.',\n",
              "  'and what that means is we want to have more people who are healthy and educated.',\n",
              "  \"we decided to provide vasectomy to all men, but in particular, american men to the front of the queue, right up to the ambassador's residence during his vin d'honneur.\",\n",
              "  'and it was amazing how much harder it was to believe in real life than it was on tv.',\n",
              "  'it was abraham path day.',\n",
              "  'one out of three black men between the ages of 18 and 30 is in jail, in prison, on probation or parole.',\n",
              "  'well it turns out that the babies, the new caledonian crow babies, are fledglings.',\n",
              "  'i am also absolutely certain that a lot of aid today is not better than giving directly to the poor.',\n",
              "  'this is followed almost immediately by the sudden closure of the vocal chords and the opening between them, which is called the glottis.',\n",
              "  'so, we are only going to look at the stars inside that small square, although we have looked at all of them.',\n",
              "  'it is disgusting.',\n",
              "  'that seems like a pretty counterintuitive thought.',\n",
              "  'and there are, again, now tens of millions of these links that give us the connective tissue of social graphs and how they relate to content.',\n",
              "  'and we have got 600 billion dollars.',\n",
              "  'now a million pounds a day sounds like a lot of stuff, but it is a tiny drop of the durable goods that are disposed each and every year around the world well less than one percent.',\n",
              "  'the lines only go in three directions they are horizontal, they are vertical, or they are 45 degrees.',\n",
              "  'this is nadir.',\n",
              "  'but my team and i are confident that we can take this to market within the next two to three years.',\n",
              "  'it is \"can robots change people\\'s empathy?\"',\n",
              "  'that was until the late 1980s, when a new laboratory technique came on the scene, which could copy dna from a small tissue or fluid sample and decode the genetics of individuals.',\n",
              "  'everything digital is not just automatically public.',\n",
              "  'and what you see there is the state following individuals, people that, like you, wanted to change their country, and they jotted everything down.',\n",
              "  'these are the terms of our existence.',\n",
              "  'some argue that her extensive knowledge of color vision would have allowed her to create the same mental state produced by actually seeing the color.',\n",
              "  'but the more controversial the subject and the more frustrating the debate, the more critical it is for scientists to preserve our objectivity and our reputation for integrity.',\n",
              "  'i want you to imagine, for a moment, two children.',\n",
              "  'you are watching snippets from \"sputnik,\" my fifth documentary feature, which is just about completed.',\n",
              "  'thank you.',\n",
              "  'now, if you look at what that adjacent property is worth, you could actually buy the property, cut down the shrubbery to improve the sight line, and then sell it off again.',\n",
              "  'i think it is always been wrong, because i think always creativity has been highly collaborative, and it is probably been largely interactive.',\n",
              "  'we think it is shortcut.',\n",
              "  'but if we take that idea, we can use food as a really powerful tool to shape the world better.',\n",
              "  'this is my son tamer. you can see he is really enjoying our mathematical trip to the alhambra.',\n",
              "  'it is one of our earliest forms of connective technology.',\n",
              "  'well, this is what they are.',\n",
              "  'sometimes you would think that maybe kids would enjoy it, but sometimes they get a little freaked out.',\n",
              "  'it does not work.',\n",
              "  \"now, what is even worse than restriction, is that adults often underestimate kids' abilities.\",\n",
              "  'microscopy, the standard who procedure, reaches from 40 to 60 percent reliability.',\n",
              "  'so i agree absolutely that it does us good to learn new words for emotions, but i think we need to go further.',\n",
              "  'and joshua remains silent as they vented their rage against him.',\n",
              "  'here are two texts that contain some symbols on them.',\n",
              "  'visiting the homes of the zabbaleen is also full of surprises.',\n",
              "  'i would love to operate on her.',\n",
              "  'one guy offered free secondary school education to all, not just 30 percent.',\n",
              "  'so here we see that over the last 50 years, health care expense has grown from about five percent in germany to about 11 percent now.',\n",
              "  'the oak foundation and national geographic have been big funders of this as well.',\n",
              "  'the perpetrators saw them too.',\n",
              "  'this means, certainly, to retrain all health staff.',\n",
              "  'but the bottom line is that there is a way, when there are more women at the table, that there is an attempt to develop some understanding.',\n",
              "  'but it goes down below ground many stories.',\n",
              "  'over 99 percent of cancer drugs never make it to the tumor because they lack transportation and tools to take them to the location they are aiming for.',\n",
              "  'if they come to water, they will climb in, swim across it.',\n",
              "  'my daughter gave me a rather nice anecdote on this.',\n",
              "  'and ultimately, we have to embrace transparency.',\n",
              "  'it is what they believed about america that got them to travel in a bus for eight hours to stand in the sun in washington in the middle of august.',\n",
              "  'keep kids out of stores that look like this.',\n",
              "  'at that moment, james somerset underwent a legal transubstantiation.',\n",
              "  'robust trade continued at sea, especially in blue-and-white porcelain, which combined white pottery from mongol china with blue dye from mongol iran.',\n",
              "  'golf helps people bond.',\n",
              "  'but yet we had to figure out a way to help him with these big emotions all while teaching him core skills of reading and math.',\n",
              "  'ah sure, please.',\n",
              "  'this technology, the women will not share with the men.',\n",
              "  'what about you?\"',\n",
              "  'the neuroscientist was debunking this idea in the article.',\n",
              "  'she was eventually auditioned for the royal ballet school.',\n",
              "  \"you may have heard about the koran's idea of paradise being 72 virgins, and i promise i will come back to those virgins.\",\n",
              "  'this was on a monkey hunt, hunting with curare-tipped darts.',\n",
              "  'but if you do this, it is quick.',\n",
              "  'how can we take this idea of tricking your tastebuds and leapfrog it into something that we can do today that could be a disruptive food technology?',\n",
              "  'we love innovation.',\n",
              "  'until last year, i would never kept bees before, but national geographic asked me to photograph a story about them, and i decided, to be able to take compelling images, i should start keeping bees myself.',\n",
              "  'it was a radical transformation, but it was built by a cultural momentum.',\n",
              "  'so as you see the film go in transparently through there, and then ...',\n",
              "  'you risk your life if you do.',\n",
              "  'so let us start. number 10 we lose the will to survive.',\n",
              "  'and it is interesting, when i teach my students about african-american history, i tell them about slavery.',\n",
              "  'it is very powerful for, i think, changing our relationship to the natural world and to the other species on whom we depend.',\n",
              "  'it was devastating to see the simple plywood platform with a rail around it, where the families of the victims had left notes to them.',\n",
              "  'and then i found myself back at that same school where i would gone for that very first flight, teaching other people how to fly ...',\n",
              "  'you create 10 variations on that one.',\n",
              "  'who cannot be touched by compassion when we see the terrible horrors of the results of war, or famine, or earthquakes, or tsunamis?',\n",
              "  'unprotected sex and contaminated needles are the leading because of transmission.',\n",
              "  'through mycorrhizal networks, fungi can pass resources and signaling molecules between trees.',\n",
              "  'we are directly designing the future of the species of this planet.',\n",
              "  'simple as that.',\n",
              "  'but it was still the most exciting thing that has ever happened to me and my sisters.',\n",
              "  'and as i stood on the front porch fumbling in my pockets, i found i did not have my keys.',\n",
              "  'show abuse the light of day by talking about it with your children, your coworkers, your friends and family.',\n",
              "  'all of this modern technology is putting out strong signals that can completely swamp this exceedingly faint light we are trying to detect from the rest of the universe outside earth, which just for the record, is most of the universe.',\n",
              "  'now, i live in new orleans, and i am in love with new orleans.',\n",
              "  'it is crazy that in 2019 farmers that feed us are hungry.',\n",
              "  'he made a lot of really interesting cultural references.',\n",
              "  'narrator as the hunters display their kills, something surprising happens.',\n",
              "  'and nobody can tell me no.',\n",
              "  'and there are more than 200 formats, across 50 cities and towns of india.',\n",
              "  'we cannot tell you how many communications we are intercepting around the world, because to tell you that would be to invade your privacy.',\n",
              "  'in other words, that was the first creature in the history of the world that had a computer as its parent it did not have an organic parent.',\n",
              "  'suddenly, i became an orphan and homeless.',\n",
              "  'and now every republican, i can paint with all the things that i think about trump.\"',\n",
              "  'in south asia, if you enslave a poor person, you are at greater risk of being struck by lightning than ever being sent to jail for that crime.',\n",
              "  'it does not taste good, so i am going to need some help with that.',\n",
              "  'in the us, the average american spends three percent of their income on energy.',\n",
              "  'in order to break down our barriers, we have to learn to talk to people, to demand that people work on translation.',\n",
              "  'and that is how stethoscope and auscultation was born.',\n",
              "  'your brain does not know, because both are equally likely.',\n",
              "  'what do i mean by that?',\n",
              "  'they had deployed all the right incentives, they paid professionals to write and edit thousands of articles.',\n",
              "  'so, what do we do about that?',\n",
              "  'the whole thing took two days out of the seven-day week.',\n",
              "  'it is time for you to get in the water.\"',\n",
              "  'so what you do is one of those people has not really acquired language yet.',\n",
              "  'but the message was very clear.',\n",
              "  'christopher columbus convinced the king of spain to send him on a mission to find a better trade route to india, not by going east over land but sailing west around the globe.',\n",
              "  'there is a second reason i like these development goals, and that is because each and every one is measured.',\n",
              "  'once upon a time, there is this happy little bacterium.',\n",
              "  'there is a million a year who leave latin america to go to the united states.',\n",
              "  'four is blue.',\n",
              "  'ca would it be too much, i do not know, do we have a handheld mic?',\n",
              "  'you are allowed to just hate them with every fiber of your being.',\n",
              "  'a couple of things to keep in mind when you see it, it was built entirely by hand, i think they got a crane the last year.',\n",
              "  'sounds very much like the journey through the wilderness to the promised land, with the commandments held by the leader.',\n",
              "  'here is an image of the golden gate bridge in san francisco, not far from where i live.',\n",
              "  'unlike those khans, temujin promoted soldiers based on merit and distributed spoils evenly among them.',\n",
              "  'george bernard shaw said it differently.',\n",
              "  'i recall very much the climate march last september, and that was a huge momentum, not just in new york, but all around the world.',\n",
              "  'it exudes -like compounds from the roots.',\n",
              "  'and it is a pool that is too difficult to fully characterize, even by modern methods, and the product looks brown, like this tar here on the left. a pure compound is shown on the right, for contrast.',\n",
              "  'and the fourth is people underestimate risks in situations they do control and overestimate them in situations they do not control.',\n",
              "  'i am going out to defend your freedom, your lives.',\n",
              "  'all right, so let us take four subjects that obviously go together big data, tattoos, immortality and the greeks.',\n",
              "  'and we know that our model works.',\n",
              "  'shah rukh khan \"a girl should be seen, not heard.\"',\n",
              "  'ok.',\n",
              "  'what is that? can you do that again? can you show me some more?\\'\" she did that for two months.',\n",
              "  'thank you.',\n",
              "  'jh my question to you is, who is in charge of that classroom?',\n",
              "  'the end of torturous public judicial executions in europe and america was partly to do with being more humane towards the criminal, but it was also partly because the crowd obstinately refused to behave in the way that they should.',\n",
              "  'in other words, the minds on the margin are not the marginal minds.',\n",
              "  'and that is where all the forces become unified, because gravity finally is strong enough to compete with all the other forces.',\n",
              "  'you do not need to take that moment to prove how amazing you are or how much you have suffered.',\n",
              "  'we are the audience and we are the composers and we take from these pieces we are given.',\n",
              "  'we have the high income countries here, with the united states as a leading power we have the emerging economies in the middle, which provide a lot of the funding for the bailout and we have the low income countries here.',\n",
              "  'it was told by an anonymous kwakiutl indian of southern alaska to a missionary in 1896.',\n",
              "  'bonobos are, together with chimpanzees, your living closest relative.',\n",
              "  'it is supposed to be, i do not know, local solar and wind and cogeneration, and good things like that.',\n",
              "  'but in this country, where the government apparently does not feel compelled to provide health care for citizens, we have taken a very different approach.',\n",
              "  'the point is that, by making our own choices, we were able to develop resilience in dealing with development problems.',\n",
              "  'to them, it did not matter if i was rich or poor, the color of my skin, whether i was male or female, my sexual orientation, who i voted for, whether i was educated, if i had a faith or no faith at all.',\n",
              "  'do i have postpartum depression?\"',\n",
              "  'children one, two, three, go.',\n",
              "  'they put their families first, take care of their children and their aging parents.',\n",
              "  'he had made a simple calculation in one hour he could make 30 forged documents.',\n",
              "  'and we did this passively by looking at whether or not they would gone to university health services.',\n",
              "  'i have here what we call the paradigms.',\n",
              "  'bg dambisa, thank you for coming to ted. dm thank you very much.',\n",
              "  'so scientifically speaking, this is an improvement.',\n",
              "  'it took all of my strength not to raise my head and howl.',\n",
              "  'when you help just one person to be more secure, a nation is more secure.',\n",
              "  'db thank you so much. great. good one! take a seat. take a seat.',\n",
              "  'if you look at the rise of far-right fascism across europe of late, you will see some things that are happening that are influencing domestic politics, yet the phenomenon is transnational.',\n",
              "  'and where you might expect the canvas’ massive size to counteract this feeling, its scale only highlights the nearly life-sized atrocities on display.',\n",
              "  'we will teach her mathematics. that will calm her down.\"',\n",
              "  'i am also concerned about the plastic in the refrigerator, and i am concerned about the plastic and the toxins that leach from plastic into us and into our bodies.',\n",
              "  'so while this is a very small story, we hope that it represents a step in the right direction for the future of rural communities and for the future of public education and hopefully also for the future of design.',\n",
              "  'now we have our own liquid nitrogen.',\n",
              "  'and we work in partnership with the government, so there is no creation of a parallel delivery system.',\n",
              "  'to me, the irony about the facit story is hearing about the facit engineers, who had bought cheap, small electronic calculators in japan that they used to double-check their calculators.',\n",
              "  'and i think the message of this is very clear.',\n",
              "  'writing books is my profession but it is more than that, of course.',\n",
              "  'we know, by experience, that we can be what we call \"a little paradise,\" and yet, be completely unhappy within.',\n",
              "  'and often it does something more.',\n",
              "  'and these were the results of the swedish students.',\n",
              "  'some of these mushrooms are very happy mushrooms.',\n",
              "  'what is different about them?\"',\n",
              "  \"and he began delivering flowers to weddings, creating gardens at homes and businesses around the city, and he is now working on creating mogadishu's first public park in 22 years.\",\n",
              "  'first of all, think of the children i mentioned.',\n",
              "  'i spoke to many people, i spoke to my friends, i spoke to my family.',\n",
              "  'all those years, all those books, he never got tired of it.',\n",
              "  'do not use your own email address.',\n",
              "  'i have become myself known.',\n",
              "  'so canny outlaws are better than nothing, but it is hard to imagine any canny outlaw sustaining that for an indefinite period of time.',\n",
              "  'and obviously the life-saving is increased, the concepts help.',\n",
              "  'and we talked about, as a class, the fact that number one, the confessions might not be reliable, but number two, we did not want to encourage the police to keep doing this, especially as it was now against the law.',\n",
              "  'all villages need village councils.',\n",
              "  'but ultimately, i set out to preserve the story through these copper-plate etchings and letterpress descriptions.',\n",
              "  'she realizes that she probably has much more in common with him than with anybody entirely of korea or entirely of germany.',\n",
              "  'now he says the senior people in the beginning bristled, and they would come to him and say, \"do you want me to hire the minority, or do you want me to hire the best person for the job?\"',\n",
              "  'so for example, you could turn one into a football, or another one into a sun. all i am interested in is quantity.',\n",
              "  'the landscape is incredible.',\n",
              "  'the occasion is piled high with difficulty, and we must rise with the occasion.\"',\n",
              "  'one of your cousins is ezra cornell, founder of cornell university.',\n",
              "  'and rich men are afflicted.',\n",
              "  'and winds averaging about 40 knots for most of the voyage and up to 70 or 80 knots.',\n",
              "  'she was growing frustrated and kind of withdrawn and acting out in class.',\n",
              "  'but i borrow a lesson that i learned from him.',\n",
              "  'but the good news is, since this brand of suffering is made up, well, we can change it.',\n",
              "  'it would put us on a path to making sure all our students get a great education, find a career that is fulfilling and rewarding, and have a chance to live out their dreams.',\n",
              "  'here is a travel poster \"kepler-186f where the grass is always redder on the other side.\"',\n",
              "  \"so portia's scores would all be clustered around the four because everybody agrees that she is very beautiful, whereas sarah jessica parker completely divides opinion.\",\n",
              "  'i believe swedes play theirs and sing theirs for a little longer.',\n",
              "  'but luckily, i found a patent online for industrial furnaces that use microwaves, and at 30 minutes at full power, and i was able to finish off the process.',\n",
              "  'what are the characteristics of a country that would make you want to join it, knowing that you could end randomly at any place?',\n",
              "  'they are an open-source, publicly owned design language of the community.',\n",
              "  'but we had parents who said, \"okay, making our children good human beings is all very well, but what about math and science and english?',\n",
              "  'db are you going to take elon or...?',\n",
              "  'ca ok, so we are putting the pieces together here now.',\n",
              "  'these factors are called creative constraints, and they are the requirements and limitations we have to address in order to accomplish a goal.',\n",
              "  'speak up also with coaching staff.',\n",
              "  'a couple of weeks ago we took it down to walter reed, which is unfortunately more in the news these days.',\n",
              "  'citizens of many host countries, even those that previously welcomed newcomers, are uneasy about the rising numbers of individuals coming into their countries.',\n",
              "  'so, is it poverty?',\n",
              "  'think of it as a massive itunes for book-type content.',\n",
              "  'my friend peter says, \"if you love something, give it away.\" so, please.',\n",
              "  'more than bridge over your troubled conscience.',\n",
              "  'when you talk about objects, one other thing automatically comes attached to that thing, and that is gestures how we manipulate these objects, how we use these objects in everyday life.',\n",
              "  'peace is not the dove and the rainbow as lovely as they are.',\n",
              "  'i want to share those three with you, so we can use them as a lens for the rest of today and hopefully the rest of our life.',\n",
              "  'why would you do that?',\n",
              "  'to understand this paradox, we first need to define what we mean by \"information.\"',\n",
              "  'miracle of cooperation it multiplies energy, intelligence in human efforts.',\n",
              "  'a wise person is like a jazz musician using the notes on the page, but dancing around them, inventing combinations that are appropriate for the situation and the people at hand.',\n",
              "  'and it is this science, which is not only enlightening our understanding of the biological world, but also transforming our world faster than ever.',\n",
              "  'the journalist covering the story and i were asked to meet outside of his hotel.',\n",
              "  'in this way, he keeps up with his losses as they roll in, so that he is ready to take in the next moment.',\n",
              "  'they were found in present day iraq and iran.',\n",
              "  'even though i present confident, i was scared.',\n",
              "  'it just so happened that the civil rights movement was the perfect thing to help him bring his because to life.',\n",
              "  'they are training to be teachers, and they are running businesses.',\n",
              "  'back when i was your age, we did not know what the universe was going to do.',\n",
              "  'but here is what i was starting to learn that was really interesting self evident truths does not erase the differences between us.',\n",
              "  'but out in the landscape, one gigawatt is on the order of 50 square miles of bulldozed desert.',\n",
              "  'and then i have to try to see in what ways i can make these the hands of god.',\n",
              "  'these include smaller frontal lobes and hippocampal volumes.',\n",
              "  'if we try to say which bits of metabolism are important for aging, we will be here all night, because basically all of metabolism is important for aging in one way or another.',\n",
              "  'the amygdala prompts your hippocampus to consolidate the stress-inducing experience into a memory.',\n",
              "  'are we kind of stigmatizing people from arkansas, and this part of the country?',\n",
              "  'they do not let one group or one individual dominate, even if it is the boss, even if it is the expert.',\n",
              "  'and then if we are motivated to act on sympathy, i call that compassion.',\n",
              "  'we actually have to do something about it.',\n",
              "  'ca so certainly, the mind of your cars is pretty mind-boggling.',\n",
              "  'nearly all of his riches are invested in a collection of 30 exquisite burmese rubies, and the crowd in the square is clamoring for their confiscation to reimburse his victims.',\n",
              "  'the classic media problem, from the 20th century is, how does an organization have a message that they want to get out to a group of people distributed at the edges of a network.',\n",
              "  'so at this exact point i realized actually the zaraeeb community was the ideal context to raise the topic of perception.',\n",
              "  'you feel intense elation when things are going well mood swings into horrible despair when things are going poorly.',\n",
              "  'with all that in mind, let us see what works.',\n",
              "  'you want to see god.',\n",
              "  'and so i am thinking, right, great, it is going to keep going down.',\n",
              "  'roosevelt grier, or rosey grier, as people used to call him, grew up and grew into a 300-pound, six-foot-five linebacker in the nfl.',\n",
              "  'so, every day he came home from the factory, took a nap, studied until 4am, went back to work and repeated this cycle every day for three months.',\n",
              "  'this is the retiree health care benefits.',\n",
              "  'and then we unveiled a hammer and a hatchet and we told them to torture and kill the robots.',\n",
              "  'to get the same number of interviews as someone with an anglo-saxon name, if you were chinese, you had to send out 68 percent more applications.',\n",
              "  'w.h. auden called it an \"intolerable neural itch,\" and indeed, that is what it is.',\n",
              "  'okay, you should be asking yourself, why does not the water fall out of the glass?',\n",
              "  'imagine chemistry textbooks that actually understand the structure of how molecules are formed.',\n",
              "  'so you have density. you also have growth management.',\n",
              "  'that is basically, if you hold two fists together, it is just slightly larger than the two fists.',\n",
              "  'we started a childhood obesity initiative with the heart association in america.',\n",
              "  'young people today are more preoccupied with the attainment of the perfect life and lifestyle.',\n",
              "  'you start looking at how the global plane flights move, and you suddenly discover that the world is not even close to flat.',\n",
              "  'there is no manual.',\n",
              "  'i am one of her teaching gestures.',\n",
              "  'yeah.',\n",
              "  'that is how they are created.',\n",
              "  'and as a result, their truancy and suspension rates have improved, and girls are arriving at school increasingly ready to learn because they know the teachers there care about them.',\n",
              "  'guy joey!',\n",
              "  'i have enough confidence to believe that that world will indeed come to pass, and that we are the ones to make it so.',\n",
              "  'it is going to be about thinking about how it evolves, and how people respond to it.',\n",
              "  'they are doing a phenomenal job of teaching girls how to defend against the patriarchy, but they are not necessarily showing boys how they are supposed to defend against the patriarchy.',\n",
              "  'and on the first day at simikot in humla, far west of nepal, the most impoverished region of nepal, an old man came in clutching a bundle of rags.',\n",
              "  'it does not matter how hard i train, i am never actually going to get there.',\n",
              "  'the same physics make it possible to score another apparently impossible goal, an unassisted corner kick.',\n",
              "  'i think that the fact that it is so difficult, the fact that we are overreaching, is the value of things like the lhc.',\n",
              "  'and one of the things if you remember condoleezza rice was at some event and she wore boots, and she got criticized over that.',\n",
              "  'one big clue we have is that the universe is changing with time.',\n",
              "  'but milk urged them not to hide in fear “come out to your relatives.',\n",
              "  'we wish we were better husbands, better wives, smarter, more powerful, taller, richer the list goes on.',\n",
              "  'the nobel prize-winning economist daniel kahneman has spent more than 60 years now researching human behavior, and his conclusion is that we are always much more confident of what we think we know than we should be.',\n",
              "  'people got, in short, more of what they came there for even though they got less protein.',\n",
              "  'these scientists have started thinking about experimental tests to find out whether our universe is a simulation.',\n",
              "  'girl i like adventurous books, and some of my favorites are alfred hitchcock and and hardy boys.',\n",
              "  'i was clapping. they were clapping.',\n",
              "  'there is another top predator in the ocean, it turns out.',\n",
              "  'see here it is the best fit they can get of this point.',\n",
              "  'so online dating is the second most popular way that people now meet each other, but as it turns out, algorithms have been around for thousands of years in almost every culture.',\n",
              "  'and for those who cannot afford even this, we offer them a variety of scholarships.',\n",
              "  'in the mid-1980s, polio once paralyzed more than 350,000 children a year in more than 125 countries.',\n",
              "  'buildings do not just reflect our society, they shape our society down to the smallest spaces the local libraries, the homes where we raise our children, and the walk that they take from the bedroom to the bathroom.',\n",
              "  'just heard that he claimed that you play the piano in an opium den.\"',\n",
              "  'what has happened is the average daily ridership on the streets of new york is 36,000 people.',\n",
              "  'watch \"200\" i go double-click, it neatly selects just that word.',\n",
              "  'jessica i went to berkeley, yes. stop doing this!',\n",
              "  'and one idea comes from lessons from chewing crabs.',\n",
              "  'the other 20, including the president and the premier, came from entirely ordinary backgrounds.',\n",
              "  'her parents did not go to college, and neither did any of her siblings.',\n",
              "  'and using this model alongside growth rates and known needs for nutrients and photosynthesis, researchers have been able to propose height limits for specific species.',\n",
              "  'recently, a prominent imam told me a story that really took me aback.',\n",
              "  'think about that for a minute 1.1 billion dollars, 26 years old.',\n",
              "  'soren enters the room. pop! he goes invisible.',\n",
              "  'and then i needed some sort of way to be able to get back to all the wild dogs that surround my house, and attacked me during my morning walks.',\n",
              "  'we are investing in our future.',\n",
              "  'and he would say, \"ruby, what are you saying?\"',\n",
              "  'they seemed to see me in terms of their assumptions of what it must be like to be in a wheelchair.',\n",
              "  'and it cannot be done.',\n",
              "  'they give us that beautiful brown crust.',\n",
              "  'and eventually, you saturate the population.',\n",
              "  'the oil slick was now moving north towards dassen island, and the rescuers despaired, because they knew if the oil hit, it would not be possible to rescue any more oiled birds.',\n",
              "  'so at this point, you would assume that we should be treating soil like the precious resource that it is.']}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config[\"seq_len\"], device, lambda msg: print(msg), 0, None, num_examples=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Majority vote"
      ],
      "metadata": {
        "id": "WD-CvudVOJhG"
      },
      "id": "WD-CvudVOJhG"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def majority_vote(models, validation_ds, tokenizer_src, tokenizer_tgt,\n",
        "                  max_len, device, print_msg, global_state, writer,\n",
        "                  num_examples=None):\n",
        "    \"\"\"\n",
        "    models: dict name -> model\n",
        "    validation_ds: iterable of batches (batch may have batch_size > 1)\n",
        "    tokenizer_tgt: tokenizer target (harus punya token_to_id & decode/batch_decode)\n",
        "    max_len: max decode length\n",
        "    num_examples: jika bukan None -> batasi pemrosesan ke N contoh (contoh, bukan batch)\n",
        "    \"\"\"\n",
        "\n",
        "    predictions = {\"majority_vote\": []}\n",
        "    for model_name in models.keys():\n",
        "        predictions[model_name] = []\n",
        "\n",
        "    references = []\n",
        "\n",
        "    sos_idx = tokenizer_tgt.token_to_id(\"[SOS]\")\n",
        "    eos_idx = tokenizer_tgt.token_to_id(\"[EOS]\")\n",
        "\n",
        "    processed = 0  # jumlah contoh yang sudah diproses\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_iterator = tqdm(validation_ds, desc=f\"Processing validation\")\n",
        "        for batch in batch_iterator:\n",
        "            # stop kalau sudah mencapai batas contoh\n",
        "            if num_examples is not None and processed >= num_examples:\n",
        "                break\n",
        "\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "            batch_size = encoder_input.size(0)\n",
        "\n",
        "            # Jika sisa quota contoh lebih sedikit dari batch_size, slice batch\n",
        "            if num_examples is not None and processed + batch_size > num_examples:\n",
        "                take = num_examples - processed  # >0\n",
        "                encoder_input = encoder_input[:take]\n",
        "                encoder_mask = encoder_mask[:take]\n",
        "                src_texts = batch[\"src_text\"][:take]\n",
        "                tgt_texts = batch[\"tgt_text\"][:take]\n",
        "                batch_size = take\n",
        "            else:\n",
        "                src_texts = batch[\"src_text\"]\n",
        "                tgt_texts = batch[\"tgt_text\"]\n",
        "\n",
        "            # append references (per contoh)\n",
        "            for t in tgt_texts:\n",
        "                references.append(t)\n",
        "\n",
        "            # untuk tiap model, lakukan decode batch\n",
        "            for model_name, model in models.items():\n",
        "                model.eval()\n",
        "                # jalankan greedy decode batch (asumsi fungsi tersedia di scope)\n",
        "                model_out = greedy_decode_batch(model, encoder_input, encoder_mask,\n",
        "                                                tokenizer_src, tokenizer_tgt,\n",
        "                                                max_len, device)\n",
        "                # model_out: (batch_size, seq_len) tensor of token ids\n",
        "\n",
        "                # ubah jadi list of token-id lists, lalu bersihin SOS/EOS\n",
        "                ids_batch = model_out.detach().cpu().tolist()\n",
        "                cleaned_batch = []\n",
        "                for ids in ids_batch:\n",
        "                    # drop leading SOS kalau ada\n",
        "                    if len(ids) > 0 and ids[0] == sos_idx:\n",
        "                        ids = ids[1:]\n",
        "                    # crop at EOS (exclude EOS)\n",
        "                    if eos_idx in ids:\n",
        "                        ids = ids[:ids.index(eos_idx)]\n",
        "                    cleaned_batch.append(ids)\n",
        "\n",
        "                # decode to text\n",
        "                if hasattr(tokenizer_tgt, \"batch_decode\"):\n",
        "                    try:\n",
        "                        pred_texts = tokenizer_tgt.batch_decode(cleaned_batch, skip_special_tokens=True)\n",
        "                    except TypeError:\n",
        "                        # some tokenizers expect different args\n",
        "                        pred_texts = [tokenizer_tgt.decode(ids, skip_special_tokens=True) for ids in cleaned_batch]\n",
        "                else:\n",
        "                    pred_texts = [tokenizer_tgt.decode(ids, skip_special_tokens=True) for ids in cleaned_batch]\n",
        "\n",
        "                # simpan prediksi per contoh\n",
        "                for pt in pred_texts:\n",
        "                    predictions[model_name].append(pt)\n",
        "\n",
        "            processed += batch_size\n",
        "\n",
        "            # optional: print progress message (jika print_msg dipakai)\n",
        "            if print_msg:\n",
        "                print_msg(f\"Processed {processed} examples\")\n",
        "\n",
        "            # break if reached target\n",
        "            if num_examples is not None and processed >= num_examples:\n",
        "                break\n",
        "\n",
        "    # Pastikan minimal contoh yang tersedia di semua model & references\n",
        "    if len(models) == 0:\n",
        "        return predictions, references\n",
        "\n",
        "    n_preds_per_model = [len(predictions[m]) for m in models.keys()]\n",
        "    n_examples = min(len(references), min(n_preds_per_model))\n",
        "\n",
        "    if n_examples == 0:\n",
        "        return predictions, references\n",
        "\n",
        "    # lakukan majority voting per posisi kata untuk tiap contoh\n",
        "    for idx in range(n_examples):\n",
        "        list_of_predictions = []\n",
        "        max_pred_len = 0\n",
        "        for model_name in models.keys():\n",
        "            pred_tokens = predictions[model_name][idx].split()\n",
        "            list_of_predictions.append(pred_tokens)\n",
        "            if len(pred_tokens) > max_pred_len:\n",
        "                max_pred_len = len(pred_tokens)\n",
        "\n",
        "        voted_words = []\n",
        "        for pos in range(max_pred_len):\n",
        "            word_count = {}\n",
        "            for pred in list_of_predictions:\n",
        "                if pos < len(pred):\n",
        "                    w = pred[pos]\n",
        "                    if w:\n",
        "                        word_count[w] = word_count.get(w, 0) + 1\n",
        "            if word_count:\n",
        "                majority_word = max(word_count, key=word_count.get)\n",
        "                voted_words.append(majority_word)\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        majority_sentence = \" \".join(voted_words)\n",
        "        predictions[\"majority_vote\"].append(majority_sentence)\n",
        "\n",
        "    return predictions, references\n"
      ],
      "metadata": {
        "id": "uJyhtHiirH7D"
      },
      "id": "uJyhtHiirH7D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_vote(models, validation_ds, tokenizer_src, tokenizer_tgt,\n",
        "                  max_len, device, print_msg, global_state, writer,\n",
        "                  num_examples=None):\n",
        "    \"\"\"\n",
        "    models: dict name -> model\n",
        "    validation_ds: iterable of batches (expects batch size 1)\n",
        "    tokenizer_tgt: tokeni<zer target\n",
        "    max_len: max decode length (dipass dari caller)\n",
        "    num_examples: jika bukan None -> batasi pemrosesan ke N contoh\n",
        "    \"\"\"\n",
        "\n",
        "    import torch\n",
        "\n",
        "    predictions = {\"majority_vote\": []}\n",
        "    for model_name in models.keys():\n",
        "        predictions[model_name] = []\n",
        "\n",
        "    references = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        batch_iterator = tqdm(validation_ds, desc=f\"Processing validation\")\n",
        "        for i, batch in enumerate(batch_iterator):\n",
        "            if num_examples is not None and i >= num_examples:\n",
        "                break\n",
        "\n",
        "            # asumsi batch size 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device)\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "\n",
        "            target_text = batch[\"tgt_text\"][0]\n",
        "            references.append(target_text)\n",
        "\n",
        "            for model_name, model in models.items():\n",
        "                model.eval()\n",
        "                model_out = greedy_decode(model, encoder_input, encoder_mask,\n",
        "                                          tokenizer_src, tokenizer_tgt,\n",
        "                                          max_len, device)\n",
        "                # Pastikan model_out jadi list of ids sebelum decode\n",
        "                try:\n",
        "                    if isinstance(model_out, torch.Tensor):\n",
        "                        token_ids = model_out.squeeze().detach().cpu().tolist()\n",
        "                    else:\n",
        "                        token_ids = list(model_out)  # fallback\n",
        "                except Exception:\n",
        "                    # fallback aman: coba convert via numpy\n",
        "                    token_ids = model_out.detach().cpu().numpy().squeeze().tolist()\n",
        "\n",
        "                # decode jadi string -- skip special tokens agar bersih\n",
        "                pred_text = tokenizer_tgt.decode(token_ids, skip_special_tokens=True)\n",
        "                # pred_text = detokenize_whitespace(pred_text)\n",
        "                predictions[model_name].append(pred_text)\n",
        "\n",
        "    # Tentukan berapa banyak contoh yang valid (semua model punya prediksi)\n",
        "    if len(models) == 0:\n",
        "        return predictions, references\n",
        "\n",
        "    # pastikan kita hanya iterasi sampai jumlah prediksi minimum antar model & references\n",
        "    n_preds_per_model = [len(predictions[m]) for m in models.keys()]\n",
        "    n_examples = min(len(references), min(n_preds_per_model))\n",
        "\n",
        "    if n_examples == 0:\n",
        "        return predictions, references\n",
        "\n",
        "    # lakukan majority voting per posisi kata untuk tiap contoh\n",
        "    for idx in range(n_examples):\n",
        "        list_of_predictions = []\n",
        "        max_pred_len = 0\n",
        "        for model_name in models.keys():\n",
        "            # tokenisasi split pada spasi (sederhana); kalau tokenisasi berbeda, sesuaikan\n",
        "            pred_tokens = predictions[model_name][idx].split()\n",
        "            list_of_predictions.append(pred_tokens)\n",
        "            if len(pred_tokens) > max_pred_len:\n",
        "                max_pred_len = len(pred_tokens)\n",
        "\n",
        "        # bangun kata hasil majority untuk posisi 0..max_pred_len-1\n",
        "        voted_words = []\n",
        "        for pos in range(max_pred_len):\n",
        "            word_count = {}\n",
        "            for pred in list_of_predictions:\n",
        "                if pos < len(pred):\n",
        "                    w = pred[pos]\n",
        "                    if w:\n",
        "                        word_count[w] = word_count.get(w, 0) + 1\n",
        "            if word_count:\n",
        "                # pilih kata dengan hit terbesar; tie -> pilih yang muncul pertama oleh max()\n",
        "                majority_word = max(word_count, key=word_count.get)\n",
        "                voted_words.append(majority_word)\n",
        "            else:\n",
        "                # tidak ada kata baki pada posisi ini (semua model pendek) -> stop\n",
        "                break\n",
        "\n",
        "        majority_sentence = \" \".join(voted_words)\n",
        "        predictions[\"majority_vote\"].append(majority_sentence)\n",
        "\n",
        "    return predictions, references\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CPJbdf3NFLut"
      },
      "id": "CPJbdf3NFLut",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71fab27",
      "metadata": {
        "id": "b71fab27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b2542a-9b3e-4c6d-b0bb-fc1f477af87a",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing validation:   0%|          | 1/984 [00:00<11:16,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 32 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   0%|          | 2/984 [00:01<10:57,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 64 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   0%|          | 3/984 [00:01<10:03,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 96 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   0%|          | 4/984 [00:02<08:55,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 5/984 [00:02<09:00,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 6/984 [00:03<09:23,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 7/984 [00:04<09:14,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 8/984 [00:04<09:23,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 9/984 [00:05<09:15,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 10/984 [00:05<09:38,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 11/984 [00:06<10:02,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|          | 12/984 [00:07<10:31,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|▏         | 13/984 [00:08<10:59,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   1%|▏         | 14/984 [00:08<11:01,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 15/984 [00:09<10:30,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 16/984 [00:09<10:11,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 17/984 [00:10<09:29,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 18/984 [00:10<09:35,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 19/984 [00:11<09:13,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 20/984 [00:12<09:21,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 21/984 [00:12<09:19,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 22/984 [00:13<09:12,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 23/984 [00:13<09:14,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   2%|▏         | 24/984 [00:14<08:57,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 25/984 [00:14<09:04,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 26/984 [00:15<09:08,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 27/984 [00:16<09:00,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 28/984 [00:16<09:19,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 29/984 [00:17<08:42,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 30/984 [00:17<08:37,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 31/984 [00:18<08:31,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 32/984 [00:18<08:34,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 33/984 [00:19<09:25,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   3%|▎         | 34/984 [00:20<10:11,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▎         | 35/984 [00:20<10:25,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▎         | 36/984 [00:21<10:57,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 37/984 [00:22<11:08,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 38/984 [00:22<10:27,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 39/984 [00:23<09:50,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 40/984 [00:24<09:55,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 41/984 [00:24<09:13,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 42/984 [00:25<08:52,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 43/984 [00:25<08:55,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   4%|▍         | 44/984 [00:26<08:18,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▍         | 45/984 [00:26<08:40,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▍         | 46/984 [00:27<08:03,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▍         | 47/984 [00:27<07:38,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▍         | 48/984 [00:28<07:54,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▍         | 49/984 [00:28<08:09,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▌         | 50/984 [00:29<07:46,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▌         | 51/984 [00:29<07:51,  1.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▌         | 52/984 [00:30<08:10,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▌         | 53/984 [00:30<08:34,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   5%|▌         | 54/984 [00:31<08:26,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 55/984 [00:32<08:45,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 56/984 [00:32<09:10,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 57/984 [00:33<10:09,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 58/984 [00:34<09:50,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 59/984 [00:34<10:30,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 60/984 [00:35<10:49,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▌         | 61/984 [00:36<10:07,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▋         | 62/984 [00:36<09:42,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   6%|▋         | 63/984 [00:37<10:18,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 64/984 [00:38<10:01,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 65/984 [00:38<09:33,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 66/984 [00:39<09:44,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 67/984 [00:39<08:41,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 68/984 [00:40<08:08,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 69/984 [00:40<08:24,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 70/984 [00:41<08:39,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 71/984 [00:41<08:30,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 72/984 [00:42<08:31,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   7%|▋         | 73/984 [00:43<08:33,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 74/984 [00:43<08:28,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 75/984 [00:44<08:23,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 76/984 [00:44<08:08,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 77/984 [00:45<08:24,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 78/984 [00:46<09:23,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 79/984 [00:46<09:36,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 80/984 [00:47<10:01,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 81/984 [00:48<10:49,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 82/984 [00:49<11:01,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   8%|▊         | 83/984 [00:49<10:27,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▊         | 84/984 [00:50<09:46,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▊         | 85/984 [00:50<09:32,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▊         | 86/984 [00:51<09:25,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 87/984 [00:52<09:04,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 88/984 [00:52<08:24,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 89/984 [00:53<08:37,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 90/984 [00:53<08:58,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 91/984 [00:54<09:03,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 92/984 [00:54<08:48,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:   9%|▉         | 93/984 [00:55<08:43,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|▉         | 94/984 [00:56<08:39,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|▉         | 95/984 [00:56<08:45,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|▉         | 96/984 [00:57<08:15,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|▉         | 97/984 [00:57<08:19,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|▉         | 98/984 [00:58<08:20,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|█         | 99/984 [00:58<08:27,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|█         | 100/984 [00:59<09:01,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|█         | 101/984 [01:00<09:50,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|█         | 102/984 [01:01<09:45,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  10%|█         | 103/984 [01:01<10:26,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 104/984 [01:02<10:10,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 105/984 [01:03<09:26,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 106/984 [01:03<09:07,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 107/984 [01:04<08:48,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 108/984 [01:04<08:35,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 109/984 [01:05<08:30,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█         | 110/984 [01:05<08:35,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█▏        | 111/984 [01:06<08:33,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█▏        | 112/984 [01:07<08:35,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  11%|█▏        | 113/984 [01:07<08:10,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 114/984 [01:08<08:22,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 115/984 [01:08<08:10,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 116/984 [01:09<08:06,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 117/984 [01:09<08:11,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 118/984 [01:10<08:09,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 119/984 [01:11<08:17,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 120/984 [01:11<08:16,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 121/984 [01:12<08:35,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▏        | 122/984 [01:13<09:18,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  12%|█▎        | 123/984 [01:13<10:07,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 124/984 [01:14<10:10,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 125/984 [01:15<10:28,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 126/984 [01:15<09:54,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 127/984 [01:16<09:30,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 128/984 [01:17<08:57,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 129/984 [01:17<08:51,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 130/984 [01:18<08:38,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 131/984 [01:18<08:02,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  13%|█▎        | 132/984 [01:19<07:40,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▎        | 133/984 [01:19<07:21,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▎        | 134/984 [01:20<07:51,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▎        | 135/984 [01:20<07:56,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 136/984 [01:21<08:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 137/984 [01:22<07:59,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 138/984 [01:22<07:42,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 139/984 [01:23<07:53,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 140/984 [01:23<07:49,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 141/984 [01:24<07:58,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  14%|█▍        | 142/984 [01:24<07:56,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▍        | 143/984 [01:25<07:58,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▍        | 144/984 [01:26<08:17,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▍        | 145/984 [01:26<08:16,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▍        | 146/984 [01:27<09:01,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▍        | 147/984 [01:28<09:40,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▌        | 148/984 [01:28<09:33,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▌        | 149/984 [01:29<08:56,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▌        | 150/984 [01:30<08:36,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▌        | 151/984 [01:30<08:15,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  15%|█▌        | 152/984 [01:31<08:12,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 153/984 [01:31<08:05,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 154/984 [01:32<08:07,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 155/984 [01:32<08:08,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 156/984 [01:33<08:14,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 157/984 [01:34<07:56,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 158/984 [01:34<07:35,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▌        | 159/984 [01:35<07:31,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▋        | 160/984 [01:35<07:12,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▋        | 161/984 [01:36<07:22,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  16%|█▋        | 162/984 [01:36<07:05,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 163/984 [01:37<07:06,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 164/984 [01:37<07:19,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 165/984 [01:38<07:05,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 166/984 [01:38<07:16,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 167/984 [01:39<07:36,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 168/984 [01:39<07:45,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 169/984 [01:40<08:30,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 170/984 [01:41<08:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 171/984 [01:42<09:42,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  17%|█▋        | 172/984 [01:42<08:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 173/984 [01:43<08:11,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 174/984 [01:43<07:52,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 175/984 [01:44<07:55,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 176/984 [01:44<07:55,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 177/984 [01:45<07:17,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 178/984 [01:46<07:36,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 179/984 [01:46<07:37,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 180/984 [01:47<07:47,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 181/984 [01:47<07:53,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  18%|█▊        | 182/984 [01:48<07:01,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▊        | 183/984 [01:48<07:12,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▊        | 184/984 [01:49<07:20,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 185/984 [01:49<07:30,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 186/984 [01:50<07:48,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 187/984 [01:51<07:48,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 5984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 188/984 [01:51<07:19,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 189/984 [01:52<07:11,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 190/984 [01:52<07:24,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  19%|█▉        | 191/984 [01:53<08:11,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|█▉        | 192/984 [01:54<08:29,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|█▉        | 193/984 [01:55<09:27,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|█▉        | 194/984 [01:55<09:31,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|█▉        | 195/984 [01:56<08:54,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|█▉        | 196/984 [01:56<08:23,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|██        | 197/984 [01:57<08:16,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|██        | 198/984 [01:58<07:55,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|██        | 199/984 [01:58<07:48,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|██        | 200/984 [01:59<07:36,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  20%|██        | 201/984 [01:59<07:09,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 202/984 [02:00<07:24,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 203/984 [02:00<06:32,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 204/984 [02:01<06:38,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 205/984 [02:01<06:59,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 206/984 [02:02<07:16,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 207/984 [02:03<07:30,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 208/984 [02:03<07:27,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██        | 209/984 [02:04<07:21,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██▏       | 210/984 [02:04<07:19,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  21%|██▏       | 211/984 [02:05<07:03,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 212/984 [02:05<07:35,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 213/984 [02:06<08:35,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 214/984 [02:07<09:39,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 215/984 [02:08<10:05,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 216/984 [02:09<09:39,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 217/984 [02:10<10:20,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 218/984 [02:11<10:33,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 6976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 219/984 [02:11<10:10,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 220/984 [02:12<09:19,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  22%|██▏       | 221/984 [02:12<08:32,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 222/984 [02:13<08:08,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 223/984 [02:14<08:06,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 224/984 [02:14<07:53,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 225/984 [02:15<07:57,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 226/984 [02:16<07:59,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 227/984 [02:16<07:43,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 228/984 [02:17<07:36,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 229/984 [02:17<07:12,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 230/984 [02:18<07:14,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  23%|██▎       | 231/984 [02:18<07:13,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▎       | 232/984 [02:19<06:50,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▎       | 233/984 [02:19<06:54,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 234/984 [02:20<06:19,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 235/984 [02:21<07:20,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 236/984 [02:21<08:09,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 237/984 [02:22<08:21,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 238/984 [02:23<08:42,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 239/984 [02:24<09:32,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 240/984 [02:24<08:43,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  24%|██▍       | 241/984 [02:25<08:07,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▍       | 242/984 [02:25<07:55,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▍       | 243/984 [02:26<08:01,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▍       | 244/984 [02:27<07:37,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▍       | 245/984 [02:27<07:37,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▌       | 246/984 [02:28<07:22,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▌       | 247/984 [02:28<06:45,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▌       | 248/984 [02:29<06:34,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▌       | 249/984 [02:29<06:29,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 7968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  25%|██▌       | 250/984 [02:30<07:11,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 251/984 [02:31<07:07,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 252/984 [02:31<07:33,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 253/984 [02:32<07:17,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 254/984 [02:32<07:09,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 255/984 [02:33<07:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 256/984 [02:33<06:41,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 257/984 [02:34<07:34,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▌       | 258/984 [02:35<07:51,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▋       | 259/984 [02:36<08:26,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  26%|██▋       | 260/984 [02:37<09:12,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 261/984 [02:37<08:32,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 262/984 [02:38<08:11,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 263/984 [02:38<07:52,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 264/984 [02:39<07:22,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 265/984 [02:39<06:23,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 266/984 [02:40<06:12,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 267/984 [02:40<06:19,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 268/984 [02:41<06:07,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 269/984 [02:41<06:14,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  27%|██▋       | 270/984 [02:42<06:38,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 271/984 [02:43<06:30,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 272/984 [02:43<06:27,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 273/984 [02:44<06:06,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 274/984 [02:44<06:26,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 275/984 [02:45<06:18,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 276/984 [02:45<06:27,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 277/984 [02:46<06:47,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 278/984 [02:46<06:35,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 279/984 [02:47<06:45,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  28%|██▊       | 280/984 [02:48<07:32,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▊       | 281/984 [02:49<07:49,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 8992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▊       | 282/984 [02:49<08:20,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 283/984 [02:50<08:25,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 284/984 [02:51<07:50,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 285/984 [02:51<07:25,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 286/984 [02:52<07:16,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 287/984 [02:52<06:39,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 288/984 [02:53<06:15,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 289/984 [02:53<06:19,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  29%|██▉       | 290/984 [02:54<06:24,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|██▉       | 291/984 [02:54<06:29,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|██▉       | 292/984 [02:55<06:03,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|██▉       | 293/984 [02:55<06:14,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|██▉       | 294/984 [02:56<06:28,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|██▉       | 295/984 [02:57<06:31,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|███       | 296/984 [02:57<06:07,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|███       | 297/984 [02:58<06:14,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|███       | 298/984 [02:58<06:25,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|███       | 299/984 [02:59<06:34,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  30%|███       | 300/984 [02:59<06:29,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 301/984 [03:00<06:46,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 302/984 [03:01<07:27,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 303/984 [03:02<07:33,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 304/984 [03:02<08:01,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 305/984 [03:03<08:46,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 306/984 [03:04<08:12,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███       | 307/984 [03:05<07:37,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███▏      | 308/984 [03:05<07:03,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  31%|███▏      | 309/984 [03:06<06:43,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 310/984 [03:06<06:39,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 311/984 [03:07<06:32,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 312/984 [03:07<06:35,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 9984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 313/984 [03:08<06:27,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 314/984 [03:08<06:13,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 315/984 [03:09<05:56,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 316/984 [03:09<05:55,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 317/984 [03:10<05:48,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 318/984 [03:10<05:34,  1.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  32%|███▏      | 319/984 [03:11<05:43,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 320/984 [03:11<06:01,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 321/984 [03:12<05:44,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 322/984 [03:12<05:43,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 323/984 [03:13<05:30,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 324/984 [03:14<05:57,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 325/984 [03:14<06:21,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 326/984 [03:15<06:52,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 327/984 [03:16<07:23,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 328/984 [03:17<07:56,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  33%|███▎      | 329/984 [03:17<08:05,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▎      | 330/984 [03:18<07:38,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▎      | 331/984 [03:19<07:11,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▎      | 332/984 [03:19<06:46,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 333/984 [03:20<06:11,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 334/984 [03:20<06:09,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 335/984 [03:20<05:33,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 336/984 [03:21<05:50,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 337/984 [03:22<05:44,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 338/984 [03:22<05:55,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  34%|███▍      | 339/984 [03:23<06:07,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▍      | 340/984 [03:23<05:49,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▍      | 341/984 [03:24<06:05,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▍      | 342/984 [03:24<05:59,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▍      | 343/984 [03:25<06:11,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 10976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▍      | 344/984 [03:26<06:04,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▌      | 345/984 [03:26<06:06,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▌      | 346/984 [03:27<06:16,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▌      | 347/984 [03:28<06:59,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▌      | 348/984 [03:28<07:07,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  35%|███▌      | 349/984 [03:29<07:08,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 350/984 [03:30<07:37,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 351/984 [03:30<07:12,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 352/984 [03:31<06:22,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 353/984 [03:31<06:05,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 354/984 [03:32<06:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 355/984 [03:33<06:00,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▌      | 356/984 [03:33<06:07,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▋      | 357/984 [03:34<05:51,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▋      | 358/984 [03:34<05:52,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  36%|███▋      | 359/984 [03:35<05:42,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 360/984 [03:35<05:50,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 361/984 [03:36<05:24,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 362/984 [03:36<05:40,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 363/984 [03:37<05:42,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 364/984 [03:37<05:44,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 365/984 [03:38<05:42,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 366/984 [03:39<05:40,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 367/984 [03:39<05:17,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  37%|███▋      | 368/984 [03:40<05:40,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 369/984 [03:40<05:53,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 370/984 [03:41<06:21,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 371/984 [03:42<06:58,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 372/984 [03:43<07:06,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 373/984 [03:43<07:12,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 374/984 [03:44<06:48,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 11968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 375/984 [03:44<06:30,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 376/984 [03:45<06:09,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 377/984 [03:46<05:51,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  38%|███▊      | 378/984 [03:46<05:53,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▊      | 379/984 [03:47<05:43,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▊      | 380/984 [03:47<05:47,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▊      | 381/984 [03:48<05:26,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 382/984 [03:48<05:17,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 383/984 [03:49<05:09,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 384/984 [03:49<05:21,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 385/984 [03:50<05:24,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 386/984 [03:50<05:25,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 387/984 [03:51<04:58,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  39%|███▉      | 388/984 [03:51<04:52,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|███▉      | 389/984 [03:52<04:46,  2.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|███▉      | 390/984 [03:52<05:13,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|███▉      | 391/984 [03:53<05:07,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|███▉      | 392/984 [03:53<05:19,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|███▉      | 393/984 [03:54<06:06,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|████      | 394/984 [03:55<06:34,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|████      | 395/984 [03:56<06:53,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|████      | 396/984 [03:57<07:30,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|████      | 397/984 [03:57<07:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  40%|████      | 398/984 [03:58<06:45,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 399/984 [03:59<06:25,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 400/984 [03:59<05:52,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 401/984 [04:00<05:42,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 402/984 [04:00<05:33,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 403/984 [04:01<05:33,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 404/984 [04:01<05:27,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████      | 405/984 [04:02<05:43,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████▏     | 406/984 [04:02<05:39,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 12992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████▏     | 407/984 [04:03<05:36,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  41%|████▏     | 408/984 [04:03<05:06,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 409/984 [04:04<05:12,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 410/984 [04:05<05:16,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 411/984 [04:05<05:25,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 412/984 [04:06<05:38,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 413/984 [04:06<05:40,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 414/984 [04:07<05:59,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 415/984 [04:08<06:31,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 416/984 [04:09<06:34,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 417/984 [04:09<06:33,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  42%|████▏     | 418/984 [04:10<06:51,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 419/984 [04:11<06:06,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 420/984 [04:11<05:32,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 421/984 [04:12<05:28,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 422/984 [04:12<05:24,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 423/984 [04:13<05:35,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 424/984 [04:13<05:36,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 425/984 [04:14<05:59,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 426/984 [04:15<05:37,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 427/984 [04:15<05:18,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  43%|████▎     | 428/984 [04:16<05:19,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▎     | 429/984 [04:16<05:12,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▎     | 430/984 [04:17<05:15,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 431/984 [04:17<05:02,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 432/984 [04:18<04:47,  1.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 433/984 [04:18<04:49,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 434/984 [04:19<04:56,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 435/984 [04:20<04:59,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 436/984 [04:20<05:12,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  44%|████▍     | 437/984 [04:21<05:32,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 13984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▍     | 438/984 [04:22<06:06,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▍     | 439/984 [04:22<06:29,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▍     | 440/984 [04:23<06:55,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▍     | 441/984 [04:24<06:26,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▍     | 442/984 [04:24<05:46,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▌     | 443/984 [04:25<05:42,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▌     | 444/984 [04:26<05:35,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▌     | 445/984 [04:26<05:24,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▌     | 446/984 [04:27<05:27,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  45%|████▌     | 447/984 [04:27<05:20,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 448/984 [04:28<05:15,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 449/984 [04:29<05:19,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 450/984 [04:29<05:07,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 451/984 [04:30<04:57,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 452/984 [04:30<04:54,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 453/984 [04:31<04:41,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 454/984 [04:31<04:29,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▌     | 455/984 [04:32<04:33,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▋     | 456/984 [04:32<04:42,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  46%|████▋     | 457/984 [04:33<04:53,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 458/984 [04:33<05:09,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 459/984 [04:34<05:38,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 460/984 [04:35<05:43,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 461/984 [04:36<05:55,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 462/984 [04:36<05:56,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 463/984 [04:37<05:56,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 464/984 [04:38<05:39,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 465/984 [04:38<05:33,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 466/984 [04:39<05:12,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  47%|████▋     | 467/984 [04:39<05:05,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 468/984 [04:40<05:08,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 14976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 469/984 [04:41<05:10,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 470/984 [04:41<05:07,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 471/984 [04:42<04:57,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 472/984 [04:42<04:46,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 473/984 [04:43<04:57,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 474/984 [04:43<05:02,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 475/984 [04:44<05:00,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 476/984 [04:45<05:40,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  48%|████▊     | 477/984 [04:46<05:59,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▊     | 478/984 [04:46<06:03,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▊     | 479/984 [04:47<06:38,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 480/984 [04:48<06:51,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 481/984 [04:49<06:20,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 482/984 [04:50<06:08,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 483/984 [04:50<06:24,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 484/984 [04:51<06:13,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 485/984 [04:52<05:38,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 486/984 [04:52<05:20,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  49%|████▉     | 487/984 [04:53<04:52,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|████▉     | 488/984 [04:53<04:55,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|████▉     | 489/984 [04:54<05:23,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|████▉     | 490/984 [04:54<04:51,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|████▉     | 491/984 [04:55<04:48,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|█████     | 492/984 [04:56<04:43,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|█████     | 493/984 [04:56<04:46,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|█████     | 494/984 [04:57<04:44,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|█████     | 495/984 [04:57<04:34,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  50%|█████     | 496/984 [04:58<04:41,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 497/984 [04:59<04:49,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 498/984 [04:59<04:49,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 499/984 [05:00<04:55,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 500/984 [05:00<04:45,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 501/984 [05:01<04:47,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 502/984 [05:02<05:15,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 503/984 [05:02<05:31,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████     | 504/984 [05:03<05:35,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████▏    | 505/984 [05:04<05:56,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  51%|█████▏    | 506/984 [05:04<05:10,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 507/984 [05:05<05:05,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 508/984 [05:06<04:51,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 509/984 [05:06<04:32,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 510/984 [05:07<04:35,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 511/984 [05:07<04:26,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 512/984 [05:08<04:24,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 513/984 [05:08<04:27,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 514/984 [05:09<04:29,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 515/984 [05:10<04:23,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  52%|█████▏    | 516/984 [05:10<04:30,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 517/984 [05:11<04:13,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 518/984 [05:11<04:13,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 519/984 [05:12<04:15,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 520/984 [05:12<04:08,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 521/984 [05:13<04:09,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 522/984 [05:13<04:08,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 523/984 [05:14<04:05,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 524/984 [05:15<04:30,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 525/984 [05:15<05:09,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  53%|█████▎    | 526/984 [05:16<05:25,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▎    | 527/984 [05:17<05:40,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▎    | 528/984 [05:18<05:33,  1.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 529/984 [05:18<05:03,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 530/984 [05:19<04:38,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 531/984 [05:19<04:32,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 16992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 532/984 [05:20<04:10,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 533/984 [05:20<04:15,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 534/984 [05:21<04:08,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 535/984 [05:21<04:09,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  54%|█████▍    | 536/984 [05:22<04:04,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▍    | 537/984 [05:23<04:16,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▍    | 538/984 [05:23<04:02,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▍    | 539/984 [05:24<04:14,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▍    | 540/984 [05:24<04:03,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▍    | 541/984 [05:25<04:05,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▌    | 542/984 [05:25<04:06,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▌    | 543/984 [05:26<04:06,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▌    | 544/984 [05:26<04:06,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▌    | 545/984 [05:27<04:10,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  55%|█████▌    | 546/984 [05:28<04:09,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 547/984 [05:28<04:26,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 548/984 [05:29<04:57,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 549/984 [05:30<05:12,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 550/984 [05:31<05:29,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 551/984 [05:31<05:02,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 552/984 [05:32<04:55,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▌    | 553/984 [05:33<04:42,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▋    | 554/984 [05:33<04:32,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  56%|█████▋    | 555/984 [05:34<04:21,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 556/984 [05:34<04:15,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 557/984 [05:35<04:19,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 558/984 [05:36<04:12,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 559/984 [05:36<04:07,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 560/984 [05:37<04:06,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 561/984 [05:37<04:03,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 562/984 [05:38<03:51,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 17984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 563/984 [05:38<03:51,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 564/984 [05:39<03:52,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  57%|█████▋    | 565/984 [05:39<04:02,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 566/984 [05:40<03:53,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 567/984 [05:40<03:42,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 568/984 [05:41<03:53,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 569/984 [05:42<04:23,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 570/984 [05:43<04:32,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 571/984 [05:43<04:33,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 572/984 [05:44<04:56,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 573/984 [05:45<04:30,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 574/984 [05:45<04:07,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  58%|█████▊    | 575/984 [05:46<04:08,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▊    | 576/984 [05:46<03:56,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▊    | 577/984 [05:47<04:01,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▊    | 578/984 [05:47<03:49,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 579/984 [05:48<03:47,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 580/984 [05:48<03:37,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 581/984 [05:49<03:47,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 582/984 [05:50<03:52,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 583/984 [05:50<03:52,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 584/984 [05:51<03:42,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  59%|█████▉    | 585/984 [05:51<03:46,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|█████▉    | 586/984 [05:52<03:47,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|█████▉    | 587/984 [05:52<03:37,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|█████▉    | 588/984 [05:53<03:48,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|█████▉    | 589/984 [05:54<03:52,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|█████▉    | 590/984 [05:54<04:09,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|██████    | 591/984 [05:55<04:22,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|██████    | 592/984 [05:56<04:39,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|██████    | 593/984 [05:57<04:31,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 18976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|██████    | 594/984 [05:57<04:18,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  60%|██████    | 595/984 [05:58<04:20,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 596/984 [05:58<04:13,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 597/984 [05:59<04:07,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 598/984 [06:00<04:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 599/984 [06:00<03:49,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 600/984 [06:01<03:38,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 601/984 [06:01<03:25,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████    | 602/984 [06:02<03:26,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████▏   | 603/984 [06:02<03:28,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████▏   | 604/984 [06:03<03:30,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  61%|██████▏   | 605/984 [06:03<03:31,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 606/984 [06:04<03:18,  1.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 607/984 [06:04<03:23,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 608/984 [06:05<03:43,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 609/984 [06:06<03:33,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 610/984 [06:06<03:32,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 611/984 [06:07<03:27,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 612/984 [06:07<03:16,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 613/984 [06:08<03:16,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▏   | 614/984 [06:09<03:44,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  62%|██████▎   | 615/984 [06:09<03:49,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 616/984 [06:10<03:57,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 617/984 [06:11<04:24,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 618/984 [06:11<04:06,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 619/984 [06:12<03:49,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 620/984 [06:12<03:38,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 621/984 [06:13<03:40,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 622/984 [06:14<03:39,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 623/984 [06:14<03:36,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  63%|██████▎   | 624/984 [06:15<03:23,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 19968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▎   | 625/984 [06:15<03:23,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▎   | 626/984 [06:16<03:14,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▎   | 627/984 [06:16<03:14,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 628/984 [06:17<03:28,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 629/984 [06:18<03:19,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 630/984 [06:18<03:13,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 631/984 [06:19<03:15,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 632/984 [06:19<03:11,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 633/984 [06:20<03:15,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  64%|██████▍   | 634/984 [06:20<03:06,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▍   | 635/984 [06:21<03:11,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▍   | 636/984 [06:22<03:38,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▍   | 637/984 [06:22<03:56,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▍   | 638/984 [06:23<03:48,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▍   | 639/984 [06:24<03:54,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▌   | 640/984 [06:24<04:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▌   | 641/984 [06:25<03:45,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▌   | 642/984 [06:26<03:31,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▌   | 643/984 [06:26<03:19,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  65%|██████▌   | 644/984 [06:27<03:10,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 645/984 [06:27<03:17,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 646/984 [06:28<03:16,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 647/984 [06:28<03:13,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 648/984 [06:29<03:14,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 649/984 [06:30<03:19,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 650/984 [06:30<03:04,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▌   | 651/984 [06:31<03:08,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▋   | 652/984 [06:31<03:03,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▋   | 653/984 [06:32<03:03,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  66%|██████▋   | 654/984 [06:32<03:09,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 655/984 [06:33<03:13,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 656/984 [06:33<03:07,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 20992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 657/984 [06:34<03:17,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 658/984 [06:35<03:46,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 659/984 [06:36<03:51,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 660/984 [06:37<03:54,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 661/984 [06:37<04:06,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 662/984 [06:38<04:00,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 663/984 [06:39<03:39,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  67%|██████▋   | 664/984 [06:39<03:27,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 665/984 [06:40<03:10,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 666/984 [06:40<03:07,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 667/984 [06:41<02:59,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 668/984 [06:41<03:03,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 669/984 [06:42<02:55,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 670/984 [06:42<02:55,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 671/984 [06:43<02:52,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 672/984 [06:44<02:51,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 673/984 [06:44<03:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  68%|██████▊   | 674/984 [06:45<02:58,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▊   | 675/984 [06:45<02:57,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▊   | 676/984 [06:46<02:53,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 677/984 [06:46<02:52,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 678/984 [06:47<02:59,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 679/984 [06:48<03:06,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 680/984 [06:49<03:21,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 681/984 [06:49<03:27,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 682/984 [06:50<03:22,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  69%|██████▉   | 683/984 [06:51<03:35,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|██████▉   | 684/984 [06:51<03:23,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|██████▉   | 685/984 [06:52<03:17,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|██████▉   | 686/984 [06:53<03:09,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|██████▉   | 687/984 [06:53<02:56,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 21984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|██████▉   | 688/984 [06:54<02:49,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|███████   | 689/984 [06:54<02:50,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|███████   | 690/984 [06:55<02:59,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|███████   | 691/984 [06:55<02:56,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|███████   | 692/984 [06:56<02:43,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  70%|███████   | 693/984 [06:56<02:47,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 694/984 [06:57<02:48,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 695/984 [06:58<02:45,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 696/984 [06:58<02:51,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 697/984 [06:59<02:50,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 698/984 [06:59<02:45,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 699/984 [07:00<02:46,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 700/984 [07:00<02:36,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████   | 701/984 [07:01<02:53,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████▏  | 702/984 [07:02<03:01,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  71%|███████▏  | 703/984 [07:03<03:09,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 704/984 [07:03<03:05,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 705/984 [07:04<03:27,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 706/984 [07:05<03:15,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 707/984 [07:05<03:03,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 708/984 [07:06<02:54,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 709/984 [07:07<02:50,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 710/984 [07:07<02:46,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 711/984 [07:08<02:39,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 712/984 [07:08<02:35,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  72%|███████▏  | 713/984 [07:09<02:37,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 714/984 [07:09<02:31,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 715/984 [07:10<02:28,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 716/984 [07:10<02:26,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 717/984 [07:11<02:29,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 718/984 [07:11<02:20,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 22976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 719/984 [07:12<02:22,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 720/984 [07:13<02:20,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 721/984 [07:13<02:25,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 722/984 [07:14<02:28,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  73%|███████▎  | 723/984 [07:14<02:40,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▎  | 724/984 [07:15<02:59,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▎  | 725/984 [07:16<03:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 726/984 [07:17<02:59,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 727/984 [07:18<03:05,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 728/984 [07:18<02:58,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 729/984 [07:19<02:44,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 730/984 [07:19<02:41,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 731/984 [07:20<02:39,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 732/984 [07:20<02:29,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  74%|███████▍  | 733/984 [07:21<02:21,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▍  | 734/984 [07:22<02:22,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▍  | 735/984 [07:22<02:16,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▍  | 736/984 [07:23<02:13,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▍  | 737/984 [07:23<02:10,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▌  | 738/984 [07:24<02:17,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▌  | 739/984 [07:24<02:19,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▌  | 740/984 [07:25<02:24,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▌  | 741/984 [07:26<02:29,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  75%|███████▌  | 742/984 [07:26<02:22,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 743/984 [07:27<02:16,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 744/984 [07:27<02:15,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 745/984 [07:28<02:22,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 746/984 [07:29<02:39,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 747/984 [07:29<02:48,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 748/984 [07:30<02:57,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 749/984 [07:31<03:01,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 23968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▌  | 750/984 [07:32<03:09,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▋  | 751/984 [07:33<03:14,  1.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  76%|███████▋  | 752/984 [07:34<03:08,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 753/984 [07:34<02:53,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 754/984 [07:35<02:45,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 755/984 [07:36<02:32,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 756/984 [07:36<02:17,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 757/984 [07:37<02:16,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 758/984 [07:37<02:15,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 759/984 [07:38<02:05,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 760/984 [07:38<02:02,  1.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 761/984 [07:39<02:02,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  77%|███████▋  | 762/984 [07:39<01:56,  1.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 763/984 [07:40<01:58,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 764/984 [07:40<01:53,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 765/984 [07:41<01:47,  2.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 766/984 [07:41<01:50,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 767/984 [07:42<01:50,  1.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 768/984 [07:42<01:56,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 769/984 [07:43<01:58,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 770/984 [07:43<01:58,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 771/984 [07:44<01:58,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  78%|███████▊  | 772/984 [07:45<02:14,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▊  | 773/984 [07:46<02:27,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▊  | 774/984 [07:46<02:32,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 775/984 [07:47<02:39,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 776/984 [07:48<02:28,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 777/984 [07:48<02:21,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 778/984 [07:49<02:17,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 779/984 [07:50<02:11,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 780/984 [07:50<02:05,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 781/984 [07:51<02:03,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 24992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  79%|███████▉  | 782/984 [07:51<02:03,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|███████▉  | 783/984 [07:52<01:59,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|███████▉  | 784/984 [07:53<01:54,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|███████▉  | 785/984 [07:53<01:54,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|███████▉  | 786/984 [07:54<02:02,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|███████▉  | 787/984 [07:54<02:01,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|████████  | 788/984 [07:55<01:59,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|████████  | 789/984 [07:56<01:55,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|████████  | 790/984 [07:56<01:55,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|████████  | 791/984 [07:57<01:50,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  80%|████████  | 792/984 [07:57<01:55,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 793/984 [07:58<02:03,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 794/984 [07:59<02:07,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 795/984 [08:00<02:14,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 796/984 [08:00<02:13,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 797/984 [08:01<02:08,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 798/984 [08:02<01:57,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████  | 799/984 [08:02<01:53,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████▏ | 800/984 [08:03<01:48,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  81%|████████▏ | 801/984 [08:03<01:46,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 802/984 [08:04<01:38,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 803/984 [08:04<01:39,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 804/984 [08:05<01:40,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 805/984 [08:05<01:35,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 806/984 [08:06<01:34,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 807/984 [08:06<01:34,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 808/984 [08:07<01:33,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 809/984 [08:07<01:27,  2.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 810/984 [08:08<01:26,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  82%|████████▏ | 811/984 [08:08<01:27,  1.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 812/984 [08:09<01:30,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 25984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 813/984 [08:09<01:32,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 814/984 [08:10<01:42,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 815/984 [08:11<01:48,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 816/984 [08:12<02:03,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 817/984 [08:13<01:58,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 818/984 [08:13<01:53,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 819/984 [08:14<01:55,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 820/984 [08:14<01:48,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  83%|████████▎ | 821/984 [08:15<01:46,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▎ | 822/984 [08:16<01:42,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▎ | 823/984 [08:16<01:35,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▎ | 824/984 [08:17<01:33,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 825/984 [08:17<01:33,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 826/984 [08:18<01:30,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 827/984 [08:19<01:33,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 828/984 [08:19<01:30,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 829/984 [08:20<01:25,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 830/984 [08:20<01:26,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  84%|████████▍ | 831/984 [08:21<01:27,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▍ | 832/984 [08:21<01:26,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▍ | 833/984 [08:22<01:28,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▍ | 834/984 [08:22<01:24,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▍ | 835/984 [08:23<01:25,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▍ | 836/984 [08:24<01:23,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▌ | 837/984 [08:24<01:25,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▌ | 838/984 [08:25<01:36,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▌ | 839/984 [08:26<01:41,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▌ | 840/984 [08:27<01:42,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  85%|████████▌ | 841/984 [08:27<01:43,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 842/984 [08:28<01:33,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 843/984 [08:28<01:28,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 26976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 844/984 [08:29<01:21,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 845/984 [08:29<01:22,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 846/984 [08:30<01:19,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 847/984 [08:31<01:20,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▌ | 848/984 [08:31<01:20,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▋ | 849/984 [08:32<01:20,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▋ | 850/984 [08:32<01:18,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  86%|████████▋ | 851/984 [08:33<01:17,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 852/984 [08:34<01:16,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 853/984 [08:34<01:14,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 854/984 [08:35<01:15,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 855/984 [08:35<01:12,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 856/984 [08:36<01:12,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 857/984 [08:36<01:11,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 858/984 [08:37<01:14,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 859/984 [08:38<01:17,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27488 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  87%|████████▋ | 860/984 [08:38<01:18,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27520 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 861/984 [08:39<01:22,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27552 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 862/984 [08:40<01:26,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27584 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 863/984 [08:41<01:27,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27616 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 864/984 [08:41<01:22,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27648 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 865/984 [08:42<01:14,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27680 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 866/984 [08:42<01:11,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27712 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 867/984 [08:43<01:08,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27744 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 868/984 [08:43<01:06,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27776 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 869/984 [08:44<01:07,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27808 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  88%|████████▊ | 870/984 [08:45<01:08,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27840 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▊ | 871/984 [08:45<01:06,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27872 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▊ | 872/984 [08:46<01:06,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27904 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▊ | 873/984 [08:47<01:10,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27936 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 874/984 [08:47<01:06,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 27968 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 875/984 [08:48<01:04,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28000 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 876/984 [08:48<01:00,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28032 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 877/984 [08:49<01:03,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28064 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 878/984 [08:49<00:59,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28096 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 879/984 [08:50<00:57,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28128 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  89%|████████▉ | 880/984 [08:50<00:56,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28160 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|████████▉ | 881/984 [08:51<01:03,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28192 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|████████▉ | 882/984 [08:52<01:09,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28224 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|████████▉ | 883/984 [08:53<01:09,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28256 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|████████▉ | 884/984 [08:54<01:12,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28288 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|████████▉ | 885/984 [08:54<01:09,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28320 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|█████████ | 886/984 [08:55<01:00,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28352 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|█████████ | 887/984 [08:55<00:58,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28384 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|█████████ | 888/984 [08:56<00:58,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28416 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|█████████ | 889/984 [08:56<00:54,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28448 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  90%|█████████ | 890/984 [08:57<00:54,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28480 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 891/984 [08:57<00:50,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28512 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 892/984 [08:58<00:54,  1.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28544 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 893/984 [08:59<00:51,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28576 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 894/984 [08:59<00:48,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28608 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 895/984 [09:00<00:50,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28640 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 896/984 [09:00<00:49,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28672 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████ | 897/984 [09:01<00:49,  1.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28704 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████▏| 898/984 [09:01<00:49,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28736 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████▏| 899/984 [09:02<00:47,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28768 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  91%|█████████▏| 900/984 [09:02<00:47,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28800 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 901/984 [09:03<00:46,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28832 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 902/984 [09:04<00:47,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28864 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 903/984 [09:04<00:50,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28896 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 904/984 [09:05<00:53,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28928 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 905/984 [09:06<00:54,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28960 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 906/984 [09:07<00:57,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 28992 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 907/984 [09:07<00:57,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29024 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 908/984 [09:08<00:52,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29056 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 909/984 [09:09<00:47,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29088 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  92%|█████████▏| 910/984 [09:09<00:46,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29120 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 911/984 [09:10<00:42,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29152 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 912/984 [09:10<00:41,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29184 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 913/984 [09:11<00:42,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29216 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 914/984 [09:11<00:42,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29248 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 915/984 [09:12<00:41,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29280 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 916/984 [09:13<00:40,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29312 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 917/984 [09:13<00:41,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29344 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 918/984 [09:14<00:39,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29376 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 919/984 [09:14<00:38,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29408 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  93%|█████████▎| 920/984 [09:15<00:37,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29440 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▎| 921/984 [09:16<00:36,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29472 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▎| 922/984 [09:16<00:35,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29504 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 923/984 [09:17<00:35,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29536 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 924/984 [09:17<00:36,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29568 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 925/984 [09:18<00:39,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29600 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 926/984 [09:19<00:41,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29632 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 927/984 [09:20<00:40,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29664 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 928/984 [09:21<00:42,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29696 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  94%|█████████▍| 929/984 [09:21<00:39,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29728 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▍| 930/984 [09:22<00:36,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29760 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▍| 931/984 [09:22<00:34,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29792 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▍| 932/984 [09:23<00:32,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29824 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▍| 933/984 [09:24<00:30,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29856 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▍| 934/984 [09:24<00:30,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29888 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▌| 935/984 [09:25<00:29,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29920 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▌| 936/984 [09:25<00:28,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29952 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▌| 937/984 [09:26<00:29,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 29984 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▌| 938/984 [09:27<00:28,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30016 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  95%|█████████▌| 939/984 [09:27<00:27,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30048 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 940/984 [09:28<00:26,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30080 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 941/984 [09:28<00:25,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30112 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 942/984 [09:29<00:24,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30144 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 943/984 [09:29<00:23,  1.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30176 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 944/984 [09:30<00:22,  1.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30208 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 945/984 [09:31<00:21,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30240 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 946/984 [09:31<00:23,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30272 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▌| 947/984 [09:32<00:23,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30304 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▋| 948/984 [09:33<00:24,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30336 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  96%|█████████▋| 949/984 [09:33<00:23,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30368 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 950/984 [09:34<00:23,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30400 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 951/984 [09:35<00:22,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30432 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 952/984 [09:35<00:20,  1.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30464 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 953/984 [09:36<00:19,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30496 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 954/984 [09:36<00:17,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30528 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 955/984 [09:37<00:16,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30560 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 956/984 [09:38<00:16,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30592 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 957/984 [09:38<00:14,  1.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30624 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 958/984 [09:39<00:14,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30656 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  97%|█████████▋| 959/984 [09:39<00:14,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30688 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 960/984 [09:40<00:13,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30720 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 961/984 [09:40<00:13,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30752 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 962/984 [09:41<00:12,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30784 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 963/984 [09:41<00:11,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30816 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 964/984 [09:42<00:11,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30848 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 965/984 [09:43<00:11,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30880 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 966/984 [09:43<00:10,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30912 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 967/984 [09:44<00:09,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30944 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 968/984 [09:45<00:10,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 30976 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  98%|█████████▊| 969/984 [09:45<00:10,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31008 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▊| 970/984 [09:46<00:10,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31040 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▊| 971/984 [09:47<00:09,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31072 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 972/984 [09:48<00:08,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31104 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 973/984 [09:48<00:07,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31136 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 974/984 [09:49<00:06,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31168 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 975/984 [09:49<00:05,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31200 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 976/984 [09:50<00:04,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31232 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 977/984 [09:51<00:04,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31264 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 978/984 [09:51<00:03,  1.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31296 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation:  99%|█████████▉| 979/984 [09:52<00:02,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31328 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation: 100%|█████████▉| 980/984 [09:52<00:02,  1.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31360 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation: 100%|█████████▉| 981/984 [09:53<00:01,  1.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31392 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation: 100%|█████████▉| 982/984 [09:53<00:01,  1.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31424 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing validation: 100%|█████████▉| 983/984 [09:54<00:00,  1.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31456 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing validation: 100%|██████████| 984/984 [09:54<00:00,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 31471 examples\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "preds, refs = majority_vote(models, val_dataloader, tokenizer_src, tokenizer_tgt, config[\"seq_len\"], device, lambda msg: print(msg), 0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bleu Score"
      ],
      "metadata": {
        "id": "rpa9e726OScj"
      },
      "id": "rpa9e726OScj"
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocessing(text):\n",
        "  text = text.replace(\" '\", \"'\")\n",
        "  text = text.replace(\" ,\", \",\")\n",
        "  text = text.replace(\" ?\", \"?\")\n",
        "  text = text.replace(\" .\", \".\")\n",
        "  text = text.replace(\" !\", \"!\")\n",
        "  return text\n"
      ],
      "metadata": {
        "id": "dwNVurQrmMKO"
      },
      "id": "dwNVurQrmMKO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c8d64ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "0c8d64ba",
        "outputId": "934700d7-7793-42fa-8df9-017cb47b0c14"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'postprocessing' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2386457232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbleu_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bleu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpreds_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"BLEU scores for {model}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Loop through n-grams from 1 to 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'postprocessing' is not defined"
          ]
        }
      ],
      "source": [
        "bleu_metric = load(\"bleu\")\n",
        "for model, v in preds.items():\n",
        "  preds_cleaned = [postprocessing(pred) for pred in v]\n",
        "  print(f\"BLEU scores for {model}:\")\n",
        "  for n in range(1, 5): # Loop through n-grams from 1 to 4\n",
        "    result = bleu_metric.compute(predictions=preds_cleaned, references=refs, max_ngram=n)\n",
        "    # Extract and print only the BLEU score for the current n-gram\n",
        "    print(f\"  {n}-gram BLEU: {result.get('bleu', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a7c2539",
      "metadata": {
        "id": "6a7c2539",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c500ce-f66a-4709-9929-1c44171f3bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score for majority_vote :  {'bleu': 0.20646577988732337, 'precisions': [0.5261613556494353, 0.2659106052383929, 0.14947653531185498, 0.08688897915026401], 'brevity_penalty': 1.0, 'length_ratio': 1.076139631110176, 'translation_length': 613787, 'reference_length': 570360}\n",
            "BLEU score for model_1 :  {'bleu': 0.22313249914463085, 'precisions': [0.5643404584258777, 0.2877850150573993, 0.16531563247858105, 0.09838262239498605], 'brevity_penalty': 0.9842431694547438, 'length_ratio': 0.9843660144470159, 'translation_length': 561443, 'reference_length': 570360}\n",
            "BLEU score for model_2 :  {'bleu': 0.22317363097469922, 'precisions': [0.563926319737359, 0.2877662759215397, 0.16515395622979856, 0.09781450519415351], 'brevity_penalty': 0.9862891444153414, 'length_ratio': 0.986382284872712, 'translation_length': 562593, 'reference_length': 570360}\n",
            "BLEU score for model_3 :  {'bleu': 0.22330272866130063, 'precisions': [0.5622795533580522, 0.286496637949149, 0.16460602580436773, 0.09775911972557351], 'brevity_penalty': 0.9896356274669412, 'length_ratio': 0.9896889683708535, 'translation_length': 564479, 'reference_length': 570360}\n"
          ]
        }
      ],
      "source": [
        "bleu_metric = load(\"bleu\")\n",
        "for model, v in preds.items():\n",
        "  # preds_cleaned = [postprocessing(pred) for pred in v]\n",
        "  result = bleu_metric.compute(predictions=v, references=refs)\n",
        "  print(f\"BLEU score for {model} : \", result)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d3fd4df"
      },
      "source": [
        "# Example using NLTK for Corpus BLEU\n",
        "# Make sure you have nltk installed: !pip install nltk\n",
        "\n",
        "import nltk\n",
        "# nltk.download('punkt') # Uncomment and run this line if you get a resource error\n",
        "\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Assuming you have your predictions and references as lists of sentences\n",
        "# predictions = [\"This is the predicted sentence 1\", \"This is predicted sentence 2\"]\n",
        "# references = [[\"This is the reference sentence 1\"], [\"This is reference sentence 2\"]] # References should be a list of lists\n",
        "\n",
        "# The 'refs' and 'preds_cleaned' variables should already be available from your previous code\n",
        "# You might need to ensure 'refs' is a list of lists, where each inner list contains one reference translation\n",
        "# For example:\n",
        "# refs_for_nltk = [[ref] for ref in refs]\n",
        "\n",
        "# Calculate Corpus BLEU\n",
        "# score = corpus_bleu(refs_for_nltk, preds_cleaned)\n",
        "\n",
        "# print(f\"Corpus BLEU score (NLTK): {score}\")\n",
        "\n",
        "# If you want to see scores for different n-grams with NLTK:\n",
        "# score_1_gram = corpus_bleu(refs_for_nltk, preds_cleaned, weights=(1, 0, 0, 0))\n",
        "# score_2_gram = corpus_bleu(refs_for_nltk, preds_cleaned, weights=(0.5, 0.5, 0, 0))\n",
        "# score_3_gram = corpus_bleu(refs_for_nltk, preds_cleaned, weights=(1/3, 1/3, 1/3, 0))\n",
        "# score_4_gram = corpus_bleu(refs_for_nltk, preds_cleaned, weights=(0.25, 0.25, 0.25, 0.25)) # This is the default\n",
        "\n",
        "# print(f\"Corpus BLEU (NLTK) 1-gram: {score_1_gram}\")\n",
        "# print(f\"Corpus BLEU (NLTK) 2-gram: {score_2_gram}\")\n",
        "# print(f\"Corpus BLEU (NLTK) 3-gram: {score_3_gram}\")\n",
        "# print(f\"Corpus BLEU (NLTK) 4-gram: {score_4_gram}\")\n",
        "\n",
        "# Using the existing 'preds_cleaned' and 'refs' variables\n",
        "# Note: The 'references' argument for corpus_bleu in nltk expects a list of lists of reference translations.\n",
        "# If you only have one reference per prediction, you need to format it like this:\n",
        "refs_for_nltk = [[ref] for ref in refs]\n",
        "\n",
        "# Calculate and print Corpus BLEU for different n-grams using NLTK\n",
        "print(\"Corpus BLEU scores (NLTK):\")\n",
        "for n in range(1, 5):\n",
        "    weights = tuple([1/n] * n + [0] * (4-n))\n",
        "    score = corpus_bleu(refs_for_nltk, preds_cleaned, weights=weights)\n",
        "    print(f\"  {n}-gram BLEU: {score}\")"
      ],
      "id": "0d3fd4df",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iP9GcpsEpo7E"
      },
      "id": "iP9GcpsEpo7E",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "95a96133-9965-4f34-bcec-86c88c436e17"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "941f465fb52d4b5eb8064069d7b3f9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9e06bde7c79406ba24787fd5eae800b",
              "IPY_MODEL_9d46513ce3f54085ae1f8ea8cf7b1778",
              "IPY_MODEL_14d96473e8b044cc8f5385fd945025e1"
            ],
            "layout": "IPY_MODEL_49ac0f5e57ca45478ecac8b573340fc6"
          }
        },
        "c9e06bde7c79406ba24787fd5eae800b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38b2bd1d5f4420ebfe370a1d4e20b8d",
            "placeholder": "​",
            "style": "IPY_MODEL_2e2a10b35e9a4bd59de5e1228ee50032",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "9d46513ce3f54085ae1f8ea8cf7b1778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91cfabe1ac544c7ba69afddabb5e42e",
            "max": 157355,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96c1e0aa430243a18f482abe3aefceea",
            "value": 157355
          }
        },
        "14d96473e8b044cc8f5385fd945025e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219b6dd80f044de9adef5babc717b837",
            "placeholder": "​",
            "style": "IPY_MODEL_4b718acda65248e9b1e63f54c0108ea2",
            "value": " 157355/157355 [00:02&lt;00:00, 64193.73 examples/s]"
          }
        },
        "49ac0f5e57ca45478ecac8b573340fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38b2bd1d5f4420ebfe370a1d4e20b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2a10b35e9a4bd59de5e1228ee50032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d91cfabe1ac544c7ba69afddabb5e42e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c1e0aa430243a18f482abe3aefceea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "219b6dd80f044de9adef5babc717b837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b718acda65248e9b1e63f54c0108ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6c07d5cec9244ca92a0b478e8d3871a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b3d185029b1436daf6a6e67252bd7ad",
              "IPY_MODEL_6e02ee085e754a9c8e7815d398977616",
              "IPY_MODEL_4505d6f989b24c02b1ea4f38b99d808b"
            ],
            "layout": "IPY_MODEL_7d2a47fa3d29426396d001f7a7d57b38"
          }
        },
        "9b3d185029b1436daf6a6e67252bd7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_946e5278e0e74094b7fce3f0a6c186ab",
            "placeholder": "​",
            "style": "IPY_MODEL_19066ef69c14429596a8c6c7ab731d93",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "6e02ee085e754a9c8e7815d398977616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6be4784c209428987fe9cf5c6ce3605",
            "max": 125884,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_341fbc17c2524c9f8dd9dbec0572d63d",
            "value": 125884
          }
        },
        "4505d6f989b24c02b1ea4f38b99d808b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77485e6f7bea41d58837bcf78c369de9",
            "placeholder": "​",
            "style": "IPY_MODEL_cb65d884ec5a449f8ee87c6d56faf4be",
            "value": " 125884/125884 [00:00&lt;00:00, 174887.92 examples/s]"
          }
        },
        "7d2a47fa3d29426396d001f7a7d57b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "946e5278e0e74094b7fce3f0a6c186ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19066ef69c14429596a8c6c7ab731d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6be4784c209428987fe9cf5c6ce3605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "341fbc17c2524c9f8dd9dbec0572d63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77485e6f7bea41d58837bcf78c369de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb65d884ec5a449f8ee87c6d56faf4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ed3fa28c8144f3fa70723b4ae80cc32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bd8bd8965eb4be1bddbd1f103830743",
              "IPY_MODEL_b6e9fbe0e5fc4efbbb87bdb35a49d845",
              "IPY_MODEL_7bd40ff1b3d04924ad626c7df0557b9c"
            ],
            "layout": "IPY_MODEL_1f8f7d1fa0064e9f96616930b0df4850"
          }
        },
        "2bd8bd8965eb4be1bddbd1f103830743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704ddb1d77024f128b16c81c54b2992e",
            "placeholder": "​",
            "style": "IPY_MODEL_06d73ed400804ed0b34e9ccf5f48264e",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "b6e9fbe0e5fc4efbbb87bdb35a49d845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea4b8239e8424c0c8f066968eca7f776",
            "max": 31471,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17a40afbe4fc400889c83382b4247bff",
            "value": 31471
          }
        },
        "7bd40ff1b3d04924ad626c7df0557b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_149eb6874c45413298ae84fe91132cef",
            "placeholder": "​",
            "style": "IPY_MODEL_5e6dcbd0d8d34dafb7cc5fee10ab235d",
            "value": " 31471/31471 [00:00&lt;00:00, 157175.55 examples/s]"
          }
        },
        "1f8f7d1fa0064e9f96616930b0df4850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704ddb1d77024f128b16c81c54b2992e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d73ed400804ed0b34e9ccf5f48264e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4b8239e8424c0c8f066968eca7f776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a40afbe4fc400889c83382b4247bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "149eb6874c45413298ae84fe91132cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6dcbd0d8d34dafb7cc5fee10ab235d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efa3ddc00d7c4325a409bb409ffc3c12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d84d81f798f45dba65f0bcca9a54bbf",
              "IPY_MODEL_dc739d7360824d44908d95d794d27b86",
              "IPY_MODEL_451f48c1d47148ababfca818b199e69a"
            ],
            "layout": "IPY_MODEL_50fe10a1a07f46078f7115b0c1142d96"
          }
        },
        "2d84d81f798f45dba65f0bcca9a54bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d46c2497b84a400aa2888bdc3ae54681",
            "placeholder": "​",
            "style": "IPY_MODEL_e53ed29f94a04e998c9ff3c313ac82f3",
            "value": "Downloading builder script: "
          }
        },
        "dc739d7360824d44908d95d794d27b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec588b6e405a4f5bb25a325d3e99e104",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_574d2ec3bf124e5291985294d8ca1146",
            "value": 1
          }
        },
        "451f48c1d47148ababfca818b199e69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3976d62e12f427da50f00d62a74df2a",
            "placeholder": "​",
            "style": "IPY_MODEL_face92b06fc346aaa70ce74051fa696e",
            "value": " 5.94k/? [00:00&lt;00:00, 325kB/s]"
          }
        },
        "50fe10a1a07f46078f7115b0c1142d96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d46c2497b84a400aa2888bdc3ae54681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e53ed29f94a04e998c9ff3c313ac82f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec588b6e405a4f5bb25a325d3e99e104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "574d2ec3bf124e5291985294d8ca1146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3976d62e12f427da50f00d62a74df2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "face92b06fc346aaa70ce74051fa696e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df971cc326f84c8a822df91a28956423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0b7aeb52d554cc7a6cb820c60d4b288",
              "IPY_MODEL_9aff6177ccf74b90a99f3093bbbcf2a8",
              "IPY_MODEL_daf7cd7b82474946b0e6cfdd9321be64"
            ],
            "layout": "IPY_MODEL_fb4bbfd263d64ae282e91cd32ad2f779"
          }
        },
        "b0b7aeb52d554cc7a6cb820c60d4b288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5374945b401340eb9c1cbefcdb0fd2dd",
            "placeholder": "​",
            "style": "IPY_MODEL_d590737f28d044faa1a0854af3a0c8f7",
            "value": "Downloading extra modules: "
          }
        },
        "9aff6177ccf74b90a99f3093bbbcf2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2014b7620bb48a5a79990f9ca9632bd",
            "max": 1554,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a979acbc9bb4e019c1d9725cb077d4d",
            "value": 1554
          }
        },
        "daf7cd7b82474946b0e6cfdd9321be64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e02bd36533449efbd6caa5f39ad7a57",
            "placeholder": "​",
            "style": "IPY_MODEL_0c3f1fc2112f472e9b8f13f28eb30608",
            "value": " 4.07k/? [00:00&lt;00:00, 229kB/s]"
          }
        },
        "fb4bbfd263d64ae282e91cd32ad2f779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5374945b401340eb9c1cbefcdb0fd2dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d590737f28d044faa1a0854af3a0c8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2014b7620bb48a5a79990f9ca9632bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a979acbc9bb4e019c1d9725cb077d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e02bd36533449efbd6caa5f39ad7a57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3f1fc2112f472e9b8f13f28eb30608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04b0ee43fd214d2ebaf048188dc44cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ad6e80ffda1434082dd65475d0c3163",
              "IPY_MODEL_449275bb4b314f3c90dafd07a4a1782c",
              "IPY_MODEL_b0ab696e79e24492a4d8a40ece46f606"
            ],
            "layout": "IPY_MODEL_d7dc3fa7b7a84b928e54d26b7912054e"
          }
        },
        "1ad6e80ffda1434082dd65475d0c3163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca1a67dc1524115b41269232407bda7",
            "placeholder": "​",
            "style": "IPY_MODEL_9707a2c99c65486db4c51c14078b6920",
            "value": "Downloading extra modules: "
          }
        },
        "449275bb4b314f3c90dafd07a4a1782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f43aac02414a4f8c80c95149b29cf55f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d44f1b0643d44ca99f5146b7927588cb",
            "value": 1
          }
        },
        "b0ab696e79e24492a4d8a40ece46f606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_096d4aac5c024b3cafe82d9418293293",
            "placeholder": "​",
            "style": "IPY_MODEL_d9b900d677664d4ea8b7ecc2b20476ce",
            "value": " 3.34k/? [00:00&lt;00:00, 338kB/s]"
          }
        },
        "d7dc3fa7b7a84b928e54d26b7912054e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca1a67dc1524115b41269232407bda7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9707a2c99c65486db4c51c14078b6920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f43aac02414a4f8c80c95149b29cf55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d44f1b0643d44ca99f5146b7927588cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "096d4aac5c024b3cafe82d9418293293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b900d677664d4ea8b7ecc2b20476ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}